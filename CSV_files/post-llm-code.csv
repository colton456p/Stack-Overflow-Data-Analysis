Start Date,End Date,QuestionBody,AnswerScore,AnswerBody,QuestionTags
Dec-22,Dec-22,"<p>I am using NumPy 1.24.0.</p>
<p>On running this sample code line,</p>
<pre class=""lang-py prettyprint-override""><code>import numpy as np
num = np.float(3)
</code></pre>
<p>I am getting this error:</p>
<pre class=""lang-none prettyprint-override""><code>Traceback (most recent call last):   File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;   File &quot;/home/ubuntu/.local/lib/python3.8/site-packages/numpy/__init__.py&quot;, line 284, in __getattr__
    raise AttributeError(&quot;module {!r} has no attribute &quot; AttributeError: module 'numpy' has no attribute 'float'
</code></pre>
<p>How can I fix it?</p>
",62,"<p>The answer is already provided in the comments by <a href=""https://stackoverflow.com/questions/74844262/how-to-solve-error-numpy-has-no-attribute-float-in-python#comment132085333_74844262"">@mattdmo</a> and <a href=""https://stackoverflow.com/questions/74844262/how-to-solve-error-numpy-has-no-attribute-float-in-python/74844295#comment132085640_74844262"">@tdelaney</a>:</p>
<ul>
<li><p>NumPy <strong>1.20</strong> <a href=""https://numpy.org/doc/stable/release/1.20.0-notes.html#deprecations"" rel=""noreferrer"">(release notes)</a> deprecated <code>numpy.float</code>, <code>numpy.int</code>, and similar aliases, causing them to issue a deprecation warning</p>
</li>
<li><p>NumPy <strong>1.24</strong> <a href=""https://numpy.org/doc/stable/release/1.24.0-notes.html#expired-deprecations"" rel=""noreferrer"">(release notes)</a> removed these aliases altogether, causing an <em><strong>error</strong></em> when they are used</p>
</li>
</ul>
<p>In many cases you can simply replace the deprecated NumPy types by the equivalent Python built-in type, e.g., <code>numpy.float</code> becomes a &quot;plain&quot; Python <code>float</code>.</p>
<p>For detailed guidelines on how to deal with various deprecated types, have a closer look at the table and guideline in the <a href=""https://numpy.org/doc/stable/release/1.20.0-notes.html#deprecations"" rel=""noreferrer"">release notes for 1.20</a>:</p>
<blockquote>
<p>...</p>
<p>To give a clear guideline for the vast majority of cases, for the types <code>bool</code>, <code>object</code>, <code>str</code> (and <code>unicode</code>) using the plain version is shorter and clear, and generally a good replacement. For <code>float</code> and <code>complex</code> you can use <code>float64</code> and <code>complex128</code> if you wish to be more explicit about the precision.</p>
<p>For <code>np.int</code> a direct replacement with <code>np.int_</code> or <code>int</code> is also good and will not change behavior, but the precision will continue to depend on the computer and operating system. If you want to be more explicit and review the current use, you have the following alternatives:</p>
<ul>
<li><code>np.int64</code> or <code>np.int32</code> to specify the precision exactly. This ensures that results cannot depend on the computer or operating system.</li>
<li><code>np.int_</code> or <code>int</code> (the default), but be aware that it depends on the computer and operating system.</li>
<li>The C types: <code>np.cint</code> (<code>int</code>), <code>np.int_</code> (<code>long</code>), <code>np.longlong</code>.</li>
<li><code>np.intp</code> which is 32bit on 32bit machines 64bit on 64bit machines. This can be the best type to use for indexing.</li>
</ul>
<p>...</p>
</blockquote>
<p>If you have dependencies that use the deprecated types, a quick workaround would be to roll back your NumPy  version to 1.24 or less (as suggested in some of the other answers), while waiting for the dependency to catch up. Alternatively, you could create a patch yourself and open a pull request, or monkey patch the dependency in your own code.</p>
","python, numpy"
Dec-22,Dec-22,"<p>I'm trying to add swagger-ui (OpenAPI 3.0) to a Spring Boot v3 application.</p>
<p>I've added the openapi-ui maven dependency, and it should work as per the documentation.</p>
<pre class=""lang-xml prettyprint-override""><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springdoc&lt;/groupId&gt;
    &lt;artifactId&gt;springdoc-openapi-ui&lt;/artifactId&gt;
    &lt;version&gt;1.6.11&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p>But apparently, it still doesn't work and localhost:8080/swagger-ui.html returns a 404 error.</p>
<p>What am I missing?</p>
<p><a href=""https://i.sstatic.net/hAeIX.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/hAeIX.png"" alt=""enter image description here"" /></a></p>
",141,"<p>According to the documentation:</p>
<blockquote>
<p>For <strong>spring-boot 3</strong> support, make sure you use <strong>springdoc-openapi v2</strong></p>
</blockquote>
<p><a href=""https://springdoc.org/#what-is-the-compatibility-matrix-of-springdoc-openapi-with-spring-boot"" rel=""noreferrer"">What is the compatibility matrix of springdoc-openapi with spring-boot?</a></p>
<blockquote>
<p>For the integration between spring-boot and swagger-ui, add the
library to the list of your project dependencies (No additional
configuration is needed)</p>
</blockquote>
<pre class=""lang-xml prettyprint-override""><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springdoc&lt;/groupId&gt;
    &lt;artifactId&gt;springdoc-openapi-starter-webmvc-ui&lt;/artifactId&gt;
    &lt;version&gt;2.0.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<blockquote>
<p>This will automatically deploy swagger-ui to a spring-boot
application:</p>
<p>Documentation will be available in HTML format, using the official
swagger-ui jars</p>
<p>The Swagger UI page will then be available at
<code>http://server:port/context-path/swagger-ui.html</code> and the OpenAPI
description will be available at the following url for json format:
<code>http://server:port/context-path/v3/api-docs</code></p>
</blockquote>
<pre><code>server: The server name or IP

port: The server port

context-path: The context path of the application

Documentation can be available in yaml format as well, on the following path : /v3/api-docs.yaml
</code></pre>
<hr />
<h3>Please note that modules have been renamed:</h3>
<p><a href=""https://springdoc.org/#migrating-from-springdoc-v1"" rel=""noreferrer"">https://springdoc.org/#migrating-from-springdoc-v1</a></p>
<p><a href=""https://i.sstatic.net/EevN8.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/EevN8.png"" alt=""enter image description here"" /></a></p>
","java, spring, swagger-ui, spring-boot"
Dec-22,Dec-22,"<p>I'm trying to upgrade to Spring Boot 3.0.0 and Spring Security 6.0.</p>
<p>I've found that method for securing requests <code>authorizeRequests()</code> has been deprecated. And also method <code>antMatchers()</code> and <code>@EnableGlobalMethodSecurity</code> annotation has removed. How can I upgrade my security configuration?</p>
<p><em>My code:</em></p>
<pre class=""lang-java prettyprint-override""><code>package org.sid.securityservice.config;

import com.nimbusds.jose.jwk.JWK;
import com.nimbusds.jose.jwk.JWKSet;
import com.nimbusds.jose.jwk.RSAKey;
import com.nimbusds.jose.jwk.source.ImmutableJWKSet;
import com.nimbusds.jose.jwk.source.JWKSource;
import com.nimbusds.jose.proc.SecurityContext;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.security.authentication.AuthenticationManager;
import org.springframework.security.authentication.ProviderManager;
import org.springframework.security.authentication.dao.DaoAuthenticationProvider;
import org.springframework.security.config.Customizer;
import org.springframework.security.config.annotation.authentication.configuration.AuthenticationConfiguration;
import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;
import org.springframework.security.config.annotation.web.builders.HttpSecurity;
import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;
import org.springframework.security.config.annotation.web.configurers.oauth2.server.resource.OAuth2ResourceServerConfigurer;
import org.springframework.security.config.http.SessionCreationPolicy;
import org.springframework.security.core.userdetails.User;
import org.springframework.security.core.userdetails.UserDetailsService;
import org.springframework.security.crypto.password.PasswordEncoder;
import org.springframework.security.oauth2.jwt.JwtDecoder;
import org.springframework.security.oauth2.jwt.JwtEncoder;
import org.springframework.security.oauth2.jwt.NimbusJwtDecoder;
import org.springframework.security.oauth2.jwt.NimbusJwtEncoder;
import org.springframework.security.provisioning.InMemoryUserDetailsManager;
import org.springframework.security.web.SecurityFilterChain;

@Configuration
@EnableWebSecurity
@EnableGlobalMethodSecurity(prePostEnabled = true)
public class SecurityConfig {
    private RsakeysConfig rsakeysConfig;
    private PasswordEncoder passwordEncoder;

    public SecurityConfig(RsakeysConfig rsakeysConfig, PasswordEncoder passwordEncoder) {
        this.rsakeysConfig = rsakeysConfig;
        this.passwordEncoder = passwordEncoder;
    }

    //@Bean
    public AuthenticationManager authenticationManager(AuthenticationConfiguration authenticationConfiguration) throws Exception {
        return authenticationConfiguration.getAuthenticationManager();
    }
    @Bean
    public AuthenticationManager authenticationManager(UserDetailsService userDetailsService){
        var authProvider = new DaoAuthenticationProvider();
        authProvider.setPasswordEncoder(passwordEncoder);
        authProvider.setUserDetailsService(userDetailsService);
        return new ProviderManager(authProvider);
    }

    @Bean
    public UserDetailsService inMemoryUserDetailsManager(){
        return new InMemoryUserDetailsManager(
                User.withUsername(&quot;user1&quot;).password(passwordEncoder.encode(&quot;1234&quot;)).authorities(&quot;USER&quot;).build(),
                User.withUsername(&quot;user2&quot;).password(passwordEncoder.encode(&quot;1234&quot;)).authorities(&quot;USER&quot;).build(),
                User.withUsername(&quot;admin&quot;).password(passwordEncoder.encode(&quot;1234&quot;)).authorities(&quot;USER&quot;,&quot;ADMIN&quot;).build()
        );
    }
    @Bean
    public SecurityFilterChain filterChain(HttpSecurity httpSecurity) throws Exception {
        return httpSecurity
                .csrf(csrf-&gt;csrf.disable())
                .authorizeRequests(auth-&gt;auth.antMatchers(&quot;/token/**&quot;).permitAll())
                .authorizeRequests(auth-&gt;auth.anyRequest().authenticated())
                .sessionManagement(sess-&gt;sess.sessionCreationPolicy(SessionCreationPolicy.STATELESS))
                .oauth2ResourceServer(OAuth2ResourceServerConfigurer::jwt)
                .httpBasic(Customizer.withDefaults())
                .build();
    }
    @Bean
    JwtDecoder jwtDecoder(){
        return NimbusJwtDecoder.withPublicKey(rsakeysConfig.publicKey()).build();
    }
    @Bean
    JwtEncoder jwtEncoder(){
        JWK jwk= new RSAKey.Builder(rsakeysConfig.publicKey()).privateKey(rsakeysConfig.privateKey()).build();
        JWKSource&lt;SecurityContext&gt; jwkSource= new ImmutableJWKSet&lt;&gt;(new JWKSet(jwk));
        return new NimbusJwtEncoder(jwkSource);
    }

}
</code></pre>
<p>Here's what IDE shows me (<em>struck out</em> <code>authorizeRequests()</code> <em>and missing</em> <code>antMatchers()</code> <em>highlighted in red</em>):</p>
<p><a href=""https://i.sstatic.net/OBj6E.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/OBj6E.png"" alt=""enter image description here"" /></a></p>
",188,"<p>In Spring Security 6.0,
<code>antMatchers()</code> as well as other configuration methods for securing requests
(<em>namely</em> <code>mvcMatchers()</code> <em>and</em> <code>regexMatchers()</code>) have been <strong>removed</strong> from the API.</p>
<p>An overloaded method <a href=""https://docs.spring.io/spring-security/site/docs/current/api/org/springframework/security/config/annotation/web/AbstractRequestMatcherRegistry.html#requestMatchers(java.lang.String...)"" rel=""noreferrer""><code>requestMatchers()</code></a> was introduced as a uniform mean for securing requests. The flavors of <code>requestMatchers()</code> facilitate all the ways of restricting requests that were supported by the removed methods.</p>
<p>Also, method <del><code>authorizeRequests()</code></del> has been <strong>deprecated</strong> and shouldn't be used anymore. A recommended replacement - <a href=""https://docs.spring.io/spring-security/site/docs/current/api/org/springframework/security/config/annotation/web/builders/HttpSecurity.html#authorizeHttpRequests(org.springframework.security.config.Customizer)"" rel=""noreferrer""><code>authorizeHttpRequests()</code></a> (<em>you can find more information regarding these changes <a href=""https://stackoverflow.com/a/74633151/17949945""><strong>here</strong></a></em>).</p>
<p>That's how your <code>SecurityFilterChain</code> might be defined in Spring Security 6.0:</p>
<pre><code>public SecurityFilterChain filterChain(HttpSecurity httpSecurity) throws Exception {
    return httpSecurity
        .csrf(csrf -&gt; csrf.disable())
        .authorizeHttpRequests(auth -&gt; auth
            .requestMatchers(&quot;/token/**&quot;).permitAll()
            .anyRequest().authenticated()
        )
        .sessionManagement(sess -&gt; sess.sessionCreationPolicy(SessionCreationPolicy.STATELESS))
        .oauth2ResourceServer(OAuth2ResourceServerConfigurer::jwt)
        .httpBasic(Customizer.withDefaults())
        .build();
}
</code></pre>
<p>Regarding deprecated annotation <del><code>@EnableGlobalMethodSecurity</code></del> it was replaced with <a href=""https://docs.spring.io/spring-security/site/docs/5.7.0/api/org/springframework/security/config/annotation/method/configuration/EnableMethodSecurity.html"" rel=""noreferrer""><code>@EnableMethodSecurity</code></a>. The rationale behind this change is that with <code>@EnableMethodSecurity</code> property <code>prePostEnabled</code> needed to enable use of <code>@PreAuthorize/@PostAuthorize</code> and <code>@PreFilter/@PostFilter</code> is by default set to <code>true</code>.</p>
<p>So you no longer need to write <code>prePostEnabled = true</code>, just annotating your configuration class with <code>@EnableMethodSecurity</code> would be enough.</p>
","java, spring, spring-security, spring-boot"
Dec-22,Dec-22,"<p>I'm working with <a href=""https://en.wikipedia.org/wiki/Apache_Maven"" rel=""noreferrer"">Maven</a> with Java 11 and Maven on <a href=""https://en.wikipedia.org/wiki/IntelliJ_IDEA"" rel=""noreferrer"">IntelliJ IDEA</a>. I'm trying create a JsonTset class as follows:</p>
<pre class=""lang-java prettyprint-override""><code>import org.junit.BeforeClass;
import org.junit.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.autoconfigure.json.JsonTest;
import org.springframework.boot.test.json.JacksonTester;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

import java.io.IOException;
import java.nio.file.Paths;

@JsonTest
public class JacksonInjectExample {

    private static final String filePath = &quot;test.json&quot;;

    private static final String JSON = String.format(String.valueOf(Paths.get(filePath)));

    @Autowired
    private JacksonTester&lt;OHStepTrackingNotification&gt; jacksonTester;

    @Configuration
    public static class TestConfiguration {...}

    @BeforeClass
    static public void setSystemProperties() throws IOException {...}

    @Test
    public void test() throws IOException {...}
}
</code></pre>
<p>But the build is failing on the below imports:</p>
<pre class=""lang-java prettyprint-override""><code>import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.autoconfigure.json.JsonTest;
import org.springframework.boot.test.json.JacksonTester;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
</code></pre>
<p>It fails with the error:</p>
<pre class=""lang-none prettyprint-override""><code>java: cannot access org.springframework.beans.factory.annotation.Autowired
  bad class file: /C:/Users/&lt;username&gt;/.m2/repository/org/springframework/spring-beans/6.0.2/spring-beans-6.0.2.jar!/org/springframework/beans/factory/annotation/Autowired.class
    **class file has wrong version 61.0, should be 55.0**
    Please remove or make sure it appears in the correct subdirectory of the classpath.
</code></pre>
<p>I understand this problem is related to Java versions, but I can't find any working solution.</p>
<p>Using Java 11 which is set in JAVA_HOME.</p>
<p>What I have tried:</p>
<ol>
<li>Update JDK to Java 11.</li>
<li><code>java -version</code> gives: <code>openjdk version &quot;11.0.17&quot; 2022-10-18 LTS</code></li>
<li>Update the project in IntelliJ to work with Java 11.</li>
<li>Remove <code>.idea</code> folder.</li>
<li>Invalidate caches</li>
</ol>
<p>How can I fix the confusing version?</p>
",132,"<p>You're using Spring Framework 6, and since Spring 6, the minimum supported Java version is Java 17 (the class version 61 is the class version of Java 17).</p>
<p>As documented in the <a href=""https://docs.spring.io/spring-framework/docs/current/reference/html/overview.html#overview"" rel=""noreferrer"">Spring Framework Overview</a> for Spring 6:</p>
<blockquote>
<p>As of Spring Framework 6.0, Spring requires Java 17+.</p>
</blockquote>
<p>So, if you want to use Spring 6, you need to upgrade to Java 17. If you want to continue using Java 11, you need to downgrade to Spring 5.3.</p>
<p>Given Spring Boot 3 is built on Spring Framework 6, the same applies to Spring Boot 3: you need to upgrade to Java 17, or you need to downgrade to Spring Boot 2.7.</p>
","java, spring"
Dec-22,Dec-22,"<p>The simple below component is throwing the following error in Next.js's <code>app</code> directory when I use <code>useState</code>:</p>
<blockquote>
<p>You're importing a component that needs useState. It only works in a Client Component, but none of its parents are marked with &quot;use client&quot;, so they're Server Components by default.</p>
</blockquote>
<pre class=""lang-js prettyprint-override""><code>import { useState } from &quot;react&quot;;

export default function Card() {
  const [state, setState] = useState(&quot;&quot;);

  return &lt;&gt;&lt;/&gt;;
}
</code></pre>
",225,"<p>In the new <a href=""https://nextjs.org/docs/getting-started/project-structure"" rel=""noreferrer""><code>app</code></a> directory, by default, Next.js uses <a href=""https://nextjs.org/docs/getting-started/react-essentials#server-components"" rel=""noreferrer"">Server Components</a>, where the JSX gets compiled to &quot;pure HTML&quot; and sent to the browser. Like any traditional Backend with a templating engine, such as Express with EJS or Laravel with Blade.  This is for better performance, as you can read on the <a href=""https://nextjs.org/docs/getting-started/react-essentials#why-server-components"" rel=""noreferrer"">doc</a>:</p>
<blockquote>
<p>Server Components allow developers to better leverage server infrastructure. For example, large dependencies that previously would impact the JavaScript bundle size on the client can instead <strong>remain entirely on the server</strong>, leading to improved performance. They make writing a React application feel similar to PHP or Ruby on Rails, but with the power and flexibility of React for templating UI.</p>
</blockquote>
<p>And a Server Component shouldn't contain browser-specific things like click handlers or hooks such as <code>useState</code>. If you need that, you should add <code>&quot;use client&quot;</code> at the top to tell Next.js to send the JavaScript needed for that component, making it a <a href=""https://nextjs.org/docs/getting-started/react-essentials#client-components"" rel=""noreferrer"">Client Component</a>:</p>
<pre class=""lang-js prettyprint-override""><code>&quot;use client&quot;; // This is a client component üëàüèΩ

import { useState } from &quot;react&quot;;

export default function Card() {
  const [state, setState] = useState(&quot;&quot;); // I can use client hooks üëàüèΩ

  return &lt;&gt;&lt;/&gt;;
}
</code></pre>
<hr />
<p>Now, say you are importing a client-specific library that's not yet marked <code>&quot;use client&quot;</code> by the maintainers. It will work in your Client Components as-is. But to import it into a Server one, you could, for example, create a <code>lib</code> folder at the same level as <code>app</code> in which you add:</p>
<pre class=""lang-js prettyprint-override""><code>// lib/mui.js

&quot;use client&quot;;

export * from &quot;@mui/material&quot;;
</code></pre>
<p>And import it from there (this way, other parts of the page are still Server Components):</p>
<pre class=""lang-js prettyprint-override""><code>// app/page.js

import { Button } from &quot;../lib/mui&quot;;

export default function Page() {
  return (
    &lt;div&gt;
      &lt;Button variant=&quot;contained&quot;&gt;Hello World&lt;/Button&gt;
    &lt;/div&gt;
  );
}
</code></pre>
<hr />
<p>If you are getting a similar error while setting up a <a href=""https://react.dev/learn/passing-data-deeply-with-context"" rel=""noreferrer"">context</a>, the <a href=""https://nextjs.org/docs/getting-started/react-essentials#context"" rel=""noreferrer"">guideline</a> is to add it in its own <code>&quot;use client&quot;</code> marked file:</p>
<pre><code>// app/theme-provider.tsx

&quot;use client&quot;;

import { createContext } from &quot;react&quot;;

export const ThemeContext = createContext(&quot;&quot;);

export default function ThemeProvider({ children }) {
  return (
    &lt;ThemeContext.Provider value=&quot;dark&quot;&gt;
      {children}
    &lt;/ThemeContext.Provider&gt;
  );
}
</code></pre>
<p>And import it from there in your Sever Component:</p>
<pre><code>// app/layout.js

import ThemeProvider from './theme-provider';
 
export default function RootLayout({ children }) {
  return (
    &lt;html&gt;
      &lt;body&gt;
        &lt;ThemeProvider&gt;{children}&lt;/ThemeProvider&gt;
      &lt;/body&gt;
    &lt;/html&gt;
  );
}
</code></pre>
<hr />
<p>Also, you may get a similar error while trying to populate a store. This means your store uses client logic, so you need to move it to a <code>&quot;use client&quot;</code> marked file. And if it's to use data fetched on the server, you could do so:</p>
<pre class=""lang-js prettyprint-override""><code>// app/layout.js

import PopulateStore from &quot;./populate-store&quot;;

const getData = async () =&gt; {
  const res = await fetch(&quot;https://jsonplaceholder.org/posts&quot;);
  return await res.json();
};

export default async function Layout({ children }) {
  // Fetch data on the server
  const data = await getData();
  return (
    &lt;html&gt;
      &lt;body&gt;
        {/* Pass it to your client store initializer */}
        &lt;PopulateStore data={data}&gt;{children}&lt;/PopulateStore&gt;
      &lt;/body&gt;
    &lt;/html&gt;
  );
}
</code></pre>
<pre class=""lang-js prettyprint-override""><code>// app/populate-store.js

&quot;use client&quot;;

export default function PopulateStore({ data, children }) {
  // You can populate your store, whatever it may be, with data
  return &lt;&gt;{children}&lt;/&gt;;
}
</code></pre>
<hr />
<p>Finally, if your intention is to set up a global store or context to share data between Server Components, you may reconsider your approach, as they say on the <a href=""https://nextjs.org/docs/getting-started/react-essentials#sharing-data-between-server-components"" rel=""noreferrer"">doc</a>:</p>
<blockquote>
<p>Since Server Components are not interactive and therefore do not read from React state, you don't need the full power of context to share data. You can use native JavaScript patterns like global singletons within module scope if you have common data that multiple Server Component need to access.</p>
<p>For example, a module can be used to share a database connection across multiple components:</p>
</blockquote>
<pre class=""lang-js prettyprint-override""><code>// utils/database.ts

export const db = new DatabaseConnection();
</code></pre>
<pre class=""lang-js prettyprint-override""><code>// app/users/layout.tsx

import { db } from '@utils/database';
 
export async function UsersLayout() {
  let users = await db.query();
  // ...
}
</code></pre>
<pre class=""lang-js prettyprint-override""><code>// app/users/[id]/page.tsx

import { db } from '@utils/database';
 
export async function DashboardPage() {
  let user = await db.query();
  // ...
}
</code></pre>
<blockquote>
<p>In the above example, both the layout and page need to make database queries. Each of these components shares access to the database by importing the <code>@utils/database</code> module.</p>
</blockquote>
<p>But say you want to use the store for Server Components because you are fetching data from an API and don't want to make multiple calls. Well, if you are using <a href=""https://nextjs.org/docs/app/building-your-application/data-fetching#the-fetch-api"" rel=""noreferrer""><code>fetch()</code></a> (soon other libraries) to get data, <a href=""https://nextjs.org/docs/getting-started/react-essentials#sharing-fetch-requests-between-server-components"" rel=""noreferrer"">Next.js will dedupe those calls and uses the cache</a>. So you shouldn't bother normally.</p>
","javascript, reactjs, next.js"
Jan-23,Jan-23,"<p><a href=""https://pre-commit.com/"" rel=""noreferrer"">pre-commit</a> suddenly started to fail installing the <a href=""https://github.com/pycqa/isort"" rel=""noreferrer"">isort</a> hook in our builds today with the following error</p>
<pre><code>[INFO] Installing environment for https://github.com/pycqa/isort.
[INFO] Once installed this environment will be reused.
[INFO] This may take a few minutes...
An unexpected error has occurred: CalledProcessError: command: ('/builds/.../.cache/pre-commit/repo0_h0f938/py_env-python3.8/bin/python', '-mpip', 'install', '.')
return code: 1
expected return code: 0
[...]
stderr:
      ERROR: Command errored out with exit status 1:
[...]
        File &quot;/tmp/pip-build-env-_3j1398p/overlay/lib/python3.8/site-packages/poetry/core/masonry/api.py&quot;, line 40, in prepare_metadata_for_build_wheel
          poetry = Factory().create_poetry(Path(&quot;.&quot;).resolve(), with_groups=False)
        File &quot;/tmp/pip-build-env-_3j1398p/overlay/lib/python3.8/site-packages/poetry/core/factory.py&quot;, line 57, in create_poetry
          raise RuntimeError(&quot;The Poetry configuration is invalid:\n&quot; + message)
      RuntimeError: The Poetry configuration is invalid:
        - [extras.pipfile_deprecated_finder.2] 'pip-shims&lt;=0.3.4' does not match '^[a-zA-Z-_.0-9]+$'
</code></pre>
<p>It seems to be related with poetry configuration..</p>
",85,"<p>Upgrading the hook to the freshly released isort 5.12.0 seems to be fixing the issue.</p>
<p>Looking at the commit stack from isort repo, it sounds like recent version of Poetry had a breaking change incompatible with isort &lt;= 5.11.4 (<a href=""https://github.com/PyCQA/isort/commit/0d219a6e0b49b7f84ef0702b2387d5e14299bb8e"" rel=""noreferrer"">commit</a>)</p>
","python, pre-commit, isort, pre-commit.com"
Jan-23,Jan-23,"<p>I am still trying to wrap my head around this scenario. Can anyone please suggest what is the correct way to do this in Next.js 13?</p>
<p>I diplay a list of users in a Server Component, for example, like this (using MongoDB):</p>
<pre class=""lang-js prettyprint-override""><code>// UsersList.jsx
const UsersList = () =&gt; {
  const users = await usersCollection.getUsers()

  return (
  &lt;div&gt;
    {users.map(user) =&gt; &lt;div&gt;{user}&lt;/div&gt;}
  &lt;/div&gt;
  )
}
</code></pre>
<p>And on the same page, I have also defined client component for adding users:</p>
<pre class=""lang-js prettyprint-override""><code>// UsersEdit.jsx
'use client'
const UsersEdit = () =&gt; {
  const handleAdd() =&gt; // calls POST to /api/users
  return // render input + button
}
</code></pre>
<p>Both are displayed together like this in a Server Component Page:</p>
<pre class=""lang-js prettyprint-override""><code>// page.jsx
const Users = () =&gt; {
  return (
  &lt;div&gt;
    &lt;UsersList /&gt;
    &lt;UsersEdit /&gt;
  &lt;/div&gt;
  )
}
</code></pre>
<p>How should I &quot;reload&quot; or &quot;notify&quot; <code>UsersList</code> that a new user has been added to the collection to force it to display a new user/updated user?</p>
",64,"<p>The only way to update a Server Component is to reload the page. As it's sent to the browser as static HTML without any JavaScript attached to it to have interactivity.</p>
<p>To reload the page while keeping client side states, you could use <a href=""https://nextjs.org/docs/app/api-reference/functions/use-router#userouter"" rel=""noreferrer""><code>router.refresh()</code></a>, where <code>router</code> is the returned value by <a href=""https://nextjs.org/docs/app/api-reference/functions/use-router"" rel=""noreferrer""><code>useRouter()</code></a>. Here is an example working with a Todo List application:</p>
<blockquote>
<p>Let's consider a list view. Inside your Server Component, you fetch the list of items:</p>
</blockquote>
<pre class=""lang-js prettyprint-override""><code>// app/page.tsx

import Todo from &quot;./todo&quot;;
async function getTodos() {
  const res = await fetch(&quot;https://api.example.com/todos&quot;, { cache: 'no-store' });
  const todos = await res.json();
  return todos;
}

export default async function Page() {
  const todos = await getTodos();
  return (
    &lt;ul&gt;
      {todos.map((todo) =&gt; (
        &lt;Todo key={todo.id} {...todo} /&gt;
      ))}
    &lt;/ul&gt;
  );
}
</code></pre>
<blockquote>
<p>Each item has its own Client Component. This allows the component to use event handlers (like onClick or onSubmit) to trigger a mutation.</p>
</blockquote>
<pre><code>// app/todo.tsx

&quot;use client&quot;;

import { useRouter } from 'next/navigation';
import { useState, useTransition } from 'react';

export default function Todo(todo) {
  const router = useRouter();
  const [isPending, startTransition] = useTransition();
  const [isFetching, setIsFetching] = useState(false);

  // Create inline loading UI
  const isMutating = isFetching || isPending;

  async function handleChange() {
    setIsFetching(true);
    // Mutate external data source
    await fetch(`https://api.example.com/todo/${todo.id}`, {
      method: 'PUT',
      body: JSON.stringify({ completed: !todo.completed }),
    });
    setIsFetching(false);

    startTransition(() =&gt; {
      // Refresh the current route and fetch new data from the server without
      // losing client-side browser or React state.
      router.refresh();
    });
  }

  return (
    &lt;li style={{ opacity: !isMutating ? 1 : 0.7 }}&gt;
      &lt;input
        type=&quot;checkbox&quot;
        checked={todo.completed}
        onChange={handleChange}
        disabled={isPending}
      /&gt;
      {todo.title}
    &lt;/li&gt;
  );
}
</code></pre>
<p>‚ö†Ô∏è: <code>refresh()</code> could re-produce the same result if <a href=""https://stackoverflow.com/a/76204625/15288641"">fetch requests are cached</a>. This is why that <code>cache: 'no-store'</code> on this example.</p>
","javascript, mongodb, node.js, reactjs, next.js"
Jan-23,Jan-23,"<p>I was trying Nextjs 13 with Next-auth and Apollo Client. For that we wrap the root layout with the providers but we also need <code>'use client'</code> to be specified. I have no problem with the libraries.</p>
<p><strong>But what is confusing to me is that nextjs 13 app dir uses a server-first approach by default, and if I treat the root layout as a client, does it make all the pages client? Because, afak, the root layout is the parent of whole routes</strong></p>
<p><a href=""https://github.com/vercel/next.js/discussions/44648"" rel=""noreferrer"">Github discussion</a></p>
",32,"<p><a href=""https://nextjs.org/docs/app/building-your-application/routing/pages-and-layouts"" rel=""noreferrer"">from here</a> (thanks to Paul Serre for commenting)</p>
<blockquote>
<p>The root layout is a Server Component by default and can not be set to
a Client Component.</p>
</blockquote>
<p>in app directory, server components can render client components but client components cannot render server components. <a href=""https://nextjs.org/docs/app/building-your-application/rendering/composition-patterns"" rel=""noreferrer"">Because</a></p>
<blockquote>
<p>Since Client Components are rendered after Server Components, you
cannot import a Server Component into a Client Component module (since
it would require a new request back to the server). Instead, you can
pass a Server Component as props to a Client Component.</p>
</blockquote>
<p>the only exception is if the client component renders component which is passed as children. this is a Layout. From the same docs:</p>
<blockquote>
<p>Layouts are Server Components by default but can be set to a Client
Component.</p>
</blockquote>
<pre><code>&quot;use client&quot;;

export default function Layout({children}: {
  children: React.ReactNode
}) {
  return (
    &lt;html lang=&quot;en&quot;&gt;        
      &lt;head /&gt;
      &lt;body&gt;{children}&lt;/body&gt;
    &lt;/html&gt;
  )
}
</code></pre>
<p>Since the root layout component is rendering <code>children</code>, any component inside <code>children</code> tree can be server component</p>
<p>this would not be accepted</p>
<pre><code>&quot;use client&quot;;

export default function Layout({children}: {
  children: React.ReactNode
}) {
  return (
    &lt;html lang=&quot;en&quot;&gt;        
      &lt;head /&gt;
      &lt;body&gt; 
         // if you manually pass server component inside client component
         &lt;AnyServerRenderedComponent/&gt;
      &lt;/body&gt;
    &lt;/html&gt;
  )
}
</code></pre>
","javascript, reactjs, server-side-rendering, next.js, next.js13"
Jan-23,Jan-23,"<p>I'm having an error when installing/updating any pip module in python3. Purging and reinstalling <code>pip</code> and every package I can thing of hasn't helped. Here's the error that I get in response to running <code>python -m pip install --upgrade pip</code> specifically (but the error is the same for attempting to install or update any pip module):</p>
<pre><code>Traceback (most recent call last):
  File &quot;/usr/lib/python3.8/runpy.py&quot;, line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File &quot;/usr/lib/python3.8/runpy.py&quot;, line 87, in _run_code
    exec(code, run_globals)
  File &quot;/usr/lib/python3/dist-packages/pip/__main__.py&quot;, line 16, in &lt;module&gt;
    from pip._internal.cli.main import main as _main  # isort:skip # noqa
  File &quot;/usr/lib/python3/dist-packages/pip/_internal/cli/main.py&quot;, line 10, in &lt;module&gt;
    from pip._internal.cli.autocompletion import autocomplete
  File &quot;/usr/lib/python3/dist-packages/pip/_internal/cli/autocompletion.py&quot;, line 9, in &lt;module&gt;
    from pip._internal.cli.main_parser import create_main_parser
  File &quot;/usr/lib/python3/dist-packages/pip/_internal/cli/main_parser.py&quot;, line 7, in &lt;module&gt;
    from pip._internal.cli import cmdoptions
  File &quot;/usr/lib/python3/dist-packages/pip/_internal/cli/cmdoptions.py&quot;, line 24, in &lt;module&gt;
    from pip._internal.exceptions import CommandError
  File &quot;/usr/lib/python3/dist-packages/pip/_internal/exceptions.py&quot;, line 10, in &lt;module&gt;
    from pip._vendor.six import iteritems
  File &quot;/usr/lib/python3/dist-packages/pip/_vendor/__init__.py&quot;, line 65, in &lt;module&gt;
    vendored(&quot;cachecontrol&quot;)
  File &quot;/usr/lib/python3/dist-packages/pip/_vendor/__init__.py&quot;, line 36, in vendored
    __import__(modulename, globals(), locals(), level=0)
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible
  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module
  File &quot;/usr/share/python-wheels/CacheControl-0.12.6-py2.py3-none-any.whl/cachecontrol/__init__.py&quot;, line 9, in &lt;module&gt;
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible
  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module
  File &quot;/usr/share/python-wheels/CacheControl-0.12.6-py2.py3-none-any.whl/cachecontrol/wrapper.py&quot;, line 1, in &lt;module&gt;
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible
  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module
  File &quot;/usr/share/python-wheels/CacheControl-0.12.6-py2.py3-none-any.whl/cachecontrol/adapter.py&quot;, line 5, in &lt;module&gt;
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible
  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module
  File &quot;/usr/share/python-wheels/requests-2.22.0-py2.py3-none-any.whl/requests/__init__.py&quot;, line 95, in &lt;module&gt;
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible
  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module
  File &quot;/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/contrib/pyopenssl.py&quot;, line 46, in &lt;module&gt;
  File &quot;/home/patrick/.local/lib/python3.8/site-packages/OpenSSL/__init__.py&quot;, line 8, in &lt;module&gt;
    from OpenSSL import crypto, SSL
  File &quot;/home/patrick/.local/lib/python3.8/site-packages/OpenSSL/crypto.py&quot;, line 3268, in &lt;module&gt;
    _lib.OpenSSL_add_all_algorithms()
AttributeError: module 'lib' has no attribute 'OpenSSL_add_all_algorithms'
Error in sys.excepthook:
Traceback (most recent call last):
  File &quot;/usr/lib/python3/dist-packages/apport_python_hook.py&quot;, line 72, in apport_excepthook
    from apport.fileutils import likely_packaged, get_recent_crashes
  File &quot;/usr/lib/python3/dist-packages/apport/__init__.py&quot;, line 5, in &lt;module&gt;
    from apport.report import Report
  File &quot;/usr/lib/python3/dist-packages/apport/report.py&quot;, line 32, in &lt;module&gt;
    import apport.fileutils
  File &quot;/usr/lib/python3/dist-packages/apport/fileutils.py&quot;, line 12, in &lt;module&gt;
    import os, glob, subprocess, os.path, time, pwd, sys, requests_unixsocket
  File &quot;/usr/lib/python3/dist-packages/requests_unixsocket/__init__.py&quot;, line 1, in &lt;module&gt;
    import requests
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible
  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module
  File &quot;/usr/share/python-wheels/requests-2.22.0-py2.py3-none-any.whl/requests/__init__.py&quot;, line 95, in &lt;module&gt;
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible
  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module
  File &quot;/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/contrib/pyopenssl.py&quot;, line 46, in &lt;module&gt;
  File &quot;/home/patrick/.local/lib/python3.8/site-packages/OpenSSL/__init__.py&quot;, line 8, in &lt;module&gt;
    from OpenSSL import crypto, SSL
  File &quot;/home/patrick/.local/lib/python3.8/site-packages/OpenSSL/crypto.py&quot;, line 3268, in &lt;module&gt;
    _lib.OpenSSL_add_all_algorithms()
AttributeError: module 'lib' has no attribute 'OpenSSL_add_all_algorithms'

Original exception was:
Traceback (most recent call last):
  File &quot;/usr/lib/python3.8/runpy.py&quot;, line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File &quot;/usr/lib/python3.8/runpy.py&quot;, line 87, in _run_code
    exec(code, run_globals)
  File &quot;/usr/lib/python3/dist-packages/pip/__main__.py&quot;, line 16, in &lt;module&gt;
    from pip._internal.cli.main import main as _main  # isort:skip # noqa
  File &quot;/usr/lib/python3/dist-packages/pip/_internal/cli/main.py&quot;, line 10, in &lt;module&gt;
    from pip._internal.cli.autocompletion import autocomplete
  File &quot;/usr/lib/python3/dist-packages/pip/_internal/cli/autocompletion.py&quot;, line 9, in &lt;module&gt;
    from pip._internal.cli.main_parser import create_main_parser
  File &quot;/usr/lib/python3/dist-packages/pip/_internal/cli/main_parser.py&quot;, line 7, in &lt;module&gt;
    from pip._internal.cli import cmdoptions
  File &quot;/usr/lib/python3/dist-packages/pip/_internal/cli/cmdoptions.py&quot;, line 24, in &lt;module&gt;
    from pip._internal.exceptions import CommandError
  File &quot;/usr/lib/python3/dist-packages/pip/_internal/exceptions.py&quot;, line 10, in &lt;module&gt;
    from pip._vendor.six import iteritems
  File &quot;/usr/lib/python3/dist-packages/pip/_vendor/__init__.py&quot;, line 65, in &lt;module&gt;
    vendored(&quot;cachecontrol&quot;)
  File &quot;/usr/lib/python3/dist-packages/pip/_vendor/__init__.py&quot;, line 36, in vendored
    __import__(modulename, globals(), locals(), level=0)
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible
  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module
  File &quot;/usr/share/python-wheels/CacheControl-0.12.6-py2.py3-none-any.whl/cachecontrol/__init__.py&quot;, line 9, in &lt;module&gt;
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible
  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module
  File &quot;/usr/share/python-wheels/CacheControl-0.12.6-py2.py3-none-any.whl/cachecontrol/wrapper.py&quot;, line 1, in &lt;module&gt;
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible
  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module
  File &quot;/usr/share/python-wheels/CacheControl-0.12.6-py2.py3-none-any.whl/cachecontrol/adapter.py&quot;, line 5, in &lt;module&gt;
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible
  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module
  File &quot;/usr/share/python-wheels/requests-2.22.0-py2.py3-none-any.whl/requests/__init__.py&quot;, line 95, in &lt;module&gt;
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 991, in _find_and_load
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 975, in _find_and_load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 655, in _load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 618, in _load_backward_compatible
  File &quot;&lt;frozen zipimport&gt;&quot;, line 259, in load_module
  File &quot;/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/contrib/pyopenssl.py&quot;, line 46, in &lt;module&gt;
  File &quot;/home/patrick/.local/lib/python3.8/site-packages/OpenSSL/__init__.py&quot;, line 8, in &lt;module&gt;
    from OpenSSL import crypto, SSL
  File &quot;/home/patrick/.local/lib/python3.8/site-packages/OpenSSL/crypto.py&quot;, line 3268, in &lt;module&gt;
    _lib.OpenSSL_add_all_algorithms()
AttributeError: module 'lib' has no attribute 'OpenSSL_add_all_algorithms'
</code></pre>
<p>I'm running Ubuntu 20.04 in WSL. Python <code>openssl</code> is already installed.</p>
<pre><code>sudo apt install python3-openssl
Reading package lists... Done
Building dependency tree       
Reading state information... Done
python3-openssl is already the newest version (19.0.0-1build1).
0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.
</code></pre>
<p>My assumption is that I need to re-install some stuff, but I'm not sure what. I've tried the obvious stuff like <code>python3-openssl</code>, <code>libssl-dev</code>, <code>libffi-dev</code>, and <code>python3-pip</code> itself and <code>python3</code> alltogether.</p>
",160,"<p>As version <code>39.0.0</code> presented this bug, downgrading the <code>cryptography</code> package solves this, without purging or touching your OS.</p>
<p><code>pip install cryptography==38.0.4</code> to downgrade from <code>39.0.0</code> which presented this error</p>
<p><strong>EDIT</strong> per @thomas,</p>
<p>The error is a result of incompatibility between <code>cryptography</code> and <code>pyopenssl</code>, so if possible, also upgrading to <code>openssl&gt;22.1.0</code> should work:</p>
<pre><code>pip install -U pyopenssl cryptography
</code></pre>
","python, ubuntu, pip, windows-subsystem-for-linux"
Jan-23,Jan-23,"<p>When I ran spring-boot-2.7, there is no issue. However when I changed code and tailored it to spring-boot-3.0, there is java.lang.ClassNotFoundException: javax.servlet.http.HttpServletRequest</p>
<p>Could someone help me to download the source code and run on your computer? After run it, and you click &quot;Login using Facebook&quot;, you will see the exception.
<a href=""https://github.com/chuangtc/spring-boot-3.0-security-social-login"" rel=""noreferrer"">https://github.com/chuangtc/spring-boot-3.0-security-social-login</a></p>
<p>I tried adding jarkarta servlet api 6.0, but the exception is still there.</p>
",53,"<p>You don't have to add jakarta servlet api 6.0 into the <code>pom.xml</code>.
According to documentation <a href=""https://github.com/spring-projects/spring-boot/wiki/Spring-Boot-3.0-Migration-Guide#Jakarta-EE"" rel=""noreferrer"">here</a>, it is already included.</p>
<p>In your code whichever is using <code>javax.servlet.http.HttpServletRequest</code>, you need to change the <code>javax</code> to <code>jakarta</code>.</p>
<p>So the whole line will be something like this:
<code>import jakarta.servlet.http.HttpServletRequest</code></p>
<p>I faced this error before when I upgrade my service as well and I solved it using this way. Maybe you can try it.</p>
<p>[EDIT]</p>
<p>I see that one of your dependency is using the <code>javax.servlet</code>:
<a href=""https://mvnrepository.com/artifact/org.springframework.social/spring-social-facebook/2.0.3.RELEASE"" rel=""noreferrer"">https://mvnrepository.com/artifact/org.springframework.social/spring-social-facebook/2.0.3.RELEASE</a></p>
<p>And following this github, it seems this packages is no longer actively maintained and being archived, so it is likely they do not upgrade for Spring Boot 3.</p>
<p>I would recommend find other ways to work on the social login for Facebook, maybe you can try this way?</p>
<p><a href=""https://www.codejava.net/frameworks/spring-boot/social-login-with-facebook-example"" rel=""noreferrer"">https://www.codejava.net/frameworks/spring-boot/social-login-with-facebook-example</a></p>
","java, spring-boot"
Feb-23,Feb-23,"<p>I am getting the following warning from my NextJS Application:</p>
<blockquote>
<p>Warning: Extra attributes from the server: data-new-gr-c-s-check-loaded,data-gr-ext-installed,cz-shortcut-listen,data-lt-installed</p>
</blockquote>
<p>I don't know why it happens, what is the explanation for this?</p>
",130,"<p>Disabling the Grammarly extension solved the problem for me.</p>
","javascript, ecmascript-6, reactjs, next.js"
Feb-23,Feb-23,"<p>I have a very powerful bot in discord (discord.py, PYTHON) and it can play music in voice channels. It gets the music from youtube (youtube_dl). It <strong>worked perfectly before</strong> but now it doesn't want to work with any video.
I tried updating youtube_dl but it still doesn't work
I searched everywhere but I still can't find a answer that might help me.</p>
<p>This is the Error: <code>Error: Unable to extract uploader id</code></p>
<p>After and before the error log there is no more information.
Can anyone help?</p>
<p>I will leave some of the code that I use for my bot...
The youtube setup settings:</p>
<pre><code>youtube_dl.utils.bug_reports_message = lambda: ''


ytdl_format_options = {
    'format': 'bestaudio/best',
    'outtmpl': '%(extractor)s-%(id)s-%(title)s.%(ext)s',
    'restrictfilenames': True,
    'noplaylist': True,
    'nocheckcertificate': True,
    'ignoreerrors': False,
    'logtostderr': False,
    'quiet': True,
    'no_warnings': True,
    'default_search': 'auto',
    'source_address': '0.0.0.0',  # bind to ipv4 since ipv6 addresses cause issues sometimes
}

ffmpeg_options = {
    'options': '-vn',
}

ytdl = youtube_dl.YoutubeDL(ytdl_format_options)


class YTDLSource(discord.PCMVolumeTransformer):
    def __init__(self, source, *, data, volume=0.5):
        super().__init__(source, volume)

        self.data = data

        self.title = data.get('title')
        self.url = data.get('url')
        self.duration = data.get('duration')
        self.image = data.get(&quot;thumbnails&quot;)[0][&quot;url&quot;]
    @classmethod
    async def from_url(cls, url, *, loop=None, stream=False):
        loop = loop or asyncio.get_event_loop()
        data = await loop.run_in_executor(None, lambda: ytdl.extract_info(url, download=not stream))
        #print(data)

        if 'entries' in data:
            # take first item from a playlist
            data = data['entries'][0]
        #print(data[&quot;thumbnails&quot;][0][&quot;url&quot;])
        #print(data[&quot;duration&quot;])
        filename = data['url'] if stream else ytdl.prepare_filename(data)
        return cls(discord.FFmpegPCMAudio(filename, **ffmpeg_options), data=data)

</code></pre>
<p>Approximately the command to run the audio (from my bot):</p>
<pre><code>sessionChanel = message.author.voice.channel
await sessionChannel.connect()
url = matched.group(1)
player = await YTDLSource.from_url(url, loop=client.loop, stream=True)
sessionChannel.guild.voice_client.play(player, after=lambda e: print(
                                       f'Player error: {e}') if e else None)
</code></pre>
",112,"<p>This is a known issue, fixed in Master. For a temporary fix,</p>
<pre><code>python3 -m pip install --force-reinstall https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz
</code></pre>
<p>This installs tha master version. Run it through the command-line</p>
<pre><code>yt-dlp URL
</code></pre>
<p>where URL is the URL of the video you want. See <code>yt-dlp --help</code> for all options. It should just work without errors.</p>
<p>If you're using it as a module,</p>
<pre><code>import yt_dlp as youtube_dl
</code></pre>
<p>might fix your problems (though there could be API changes that break your code; I don't know which version of <code>yt_dlp</code> you were using etc).</p>
","python, ffmpeg, youtube-dl, discord"
Feb-23,Feb-23,"<p>Letting them compete three times (a million pops/dels each time):</p>
<pre><code>from timeit import timeit

for _ in range(3):
    t1 = timeit('b.pop(0)', 'b = bytearray(1000000)')
    t2 = timeit('del b[0]', 'b = bytearray(1000000)')
    print(t1 / t2)
</code></pre>
<p>Time ratios (<a href=""https://tio.run/##hZDBasMwDIbvfoqfXpxA6NyWwij0tvNeYIzhMCUxc@JMVjb89JnS9bDbdBGW@b5f9lxkSNPpceZ17TiNkDBSEIRxTiz3kzEzh0kqa@1zErpgt@TFx1h2kIHAXkJCyCZ9EePoHAZiatAugpxG2iTZ@IyYvqHt7JqtbWgmVsaEjC76j7LHU6I8WQHT5sfoRfS@S4yx4HOhrFFTo2xa@mHTmLPTaOg8RqirIHruaa@71uYGviFMuuPUU3WqLwZacsD1/rbKtvs5zZWrbQPb6rwtQp7Zl@rgblWr6UYd/1DvFNG@uNd/qd@v08QHFdTr@gM"" rel=""noreferrer"" title=""Python 3.8 (pre-release) ‚Äì Try It Online"">Try it online!</a>):</p>
<pre><code>274.6037053753368
219.38099365582403
252.08691226683823
</code></pre>
<p>Why is <code>pop</code> that much slower at doing the same thing?</p>
",82,"<p>When you run <code>b.pop(0)</code>, Python moves all the elements back by one as you might expect. This takes O(n) time.</p>
<p>When you <code>del b[0]</code>, Python simply increases the start pointer of the object by 1.</p>
<p>In both cases, <code>PyByteArray_Resize</code> is called to adjust the size. When the new size is smaller than half the allocated size, the allocated memory will be shrunk. In the <code>del b[0]</code> case, this is the only point where the data will be copied. As a result, this case will take O(1) amortized time.</p>
<p><strong>Relevant code:</strong></p>
<p><a href=""https://github.com/python/cpython/blob/ffcb8220d7a8c8ca169b467d9e4a752874f68af2/Objects/bytearrayobject.c#L1798"" rel=""noreferrer""><code>bytearray_pop_impl</code> function</a>: Always calls</p>
<pre class=""lang-c prettyprint-override""><code>memmove(buf + index, buf + index + 1, n - index);
</code></pre>
<p>The <a href=""https://github.com/python/cpython/blob/ffcb8220d7a8c8ca169b467d9e4a752874f68af2/Objects/bytearrayobject.c#L426"" rel=""noreferrer""><code>bytearray_setslice_linear</code> function</a> is called for <code>del b[0]</code> with <code>lo == 0</code>, <code>hi == 1</code>, <code>bytes_len == 0</code>. It reaches this code (with <code>growth == -1</code>):</p>
<pre class=""lang-c prettyprint-override""><code>if (lo == 0) {
    /* Shrink the buffer by advancing its logical start */
    self-&gt;ob_start -= growth;
    /*
      0   lo               hi             old_size
      |   |&lt;----avail-----&gt;|&lt;-----tail------&gt;|
      |      |&lt;-bytes_len-&gt;|&lt;-----tail------&gt;|
      0    new_lo         new_hi          new_size
    */
}
else {
    /*
      0   lo               hi               old_size
      |   |&lt;----avail-----&gt;|&lt;-----tomove------&gt;|
      |   |&lt;-bytes_len-&gt;|&lt;-----tomove------&gt;|
      0   lo         new_hi              new_size
    */
    memmove(buf + lo + bytes_len, buf + hi,
            Py_SIZE(self) - hi);
}
</code></pre>
","python, arrays, performance, cpython, python-internals"
Feb-23,Feb-23,"<p>So basically I have a server component in app dir and I want to get the pathname. I tried to do it using window.location but it does not work.
Is there any way I can do this?</p>
",16,"<p>This works for me</p>
<pre class=""lang-js prettyprint-override""><code>import { headers } from &quot;next/headers&quot;;

const headersList = headers();
const domain = headersList.get(&quot;x-forwarded-host&quot;) || &quot;&quot;;
const protocol = headersList.get(&quot;x-forwarded-proto&quot;) || &quot;&quot;;
const pathname = headersList.get(&quot;x-invoke-path&quot;) || &quot;&quot;;
</code></pre>
","javascript, router, path, next.js, react-server-components"
Feb-23,Feb-23,"<p>Why is np.dot so much faster than np.sum?  Following this <a href=""https://stackoverflow.com/questions/61945412/which-method-is-faster-and-why-np-sumarr-vs-arr-sum/61945719#61945719"">answer</a> we know that np.sum is slow and has faster alternatives.</p>
<p>For example:</p>
<pre><code>In [20]: A = np.random.rand(1000)

In [21]: B = np.random.rand(1000)

In [22]: %timeit np.sum(A)
3.21 ¬µs ¬± 270 ns per loop (mean ¬± std. dev. of 7 runs, 100,000 loops each)

In [23]: %timeit A.sum()
1.7 ¬µs ¬± 11.5 ns per loop (mean ¬± std. dev. of 7 runs, 1,000,000 loops each)

In [24]: %timeit np.add.reduce(A)
1.61 ¬µs ¬± 19.6 ns per loop (mean ¬± std. dev. of 7 runs, 1,000,000 loops each)
</code></pre>
<p>But all of them are slower than:</p>
<pre><code>In [25]: %timeit np.dot(A,B)
1.18 ¬µs ¬± 43.9 ns per loop (mean ¬± std. dev. of 7 runs, 1,000,000 loops each)
</code></pre>
<p>Given that np.dot is both multiplying two arrays elementwise and then summing them, how can this be faster than just summing one array?  If B were set to the all ones array then np.dot would simply be summing A.</p>
<p>So it seems the  fastest option to sum A is:</p>
<pre><code>In [26]: O = np.ones(1000)
In [27]: %timeit np.dot(A,O)
1.16 ¬µs ¬± 6.37 ns per loop (mean ¬± std. dev. of 7 runs, 1,000,000 loops each)
</code></pre>
<p>This can't be right, can it?</p>
<p>This is on Ubuntu with numpy 1.24.2 using openblas64 on Python 3.10.6.</p>
<p>Supported SIMD extensions in this NumPy install:</p>
<pre><code>baseline = SSE,SSE2,SSE3
found = SSSE3,SSE41,POPCNT,SSE42,AVX,F16C,FMA3,AVX2
</code></pre>
<p><strong>Update</strong></p>
<p>The order of the timings reverses if the array is much longer.  That is:</p>
<pre><code>In [28]: A = np.random.rand(1000000)
In [29]: O = np.ones(1000000)
In [30]: %timeit np.dot(A,O)
545 ¬µs ¬± 8.87 ¬µs per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)
In [31]: %timeit np.sum(A)
429 ¬µs ¬± 11 ¬µs per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)    
In [32]: %timeit A.sum()
404 ¬µs ¬± 2.95 ¬µs per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)
In [33]: %timeit np.add.reduce(A)
401 ¬µs ¬± 4.21 ¬µs per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)
</code></pre>
<p>This implies to me that there is some fixed sized overhead when calling np.sum(A), A.sum(), np.add.reduce(A) that doesn't exist when calling np.dot() but the part of the code that does the summation is in fact faster.</p>
<p>‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-</p>
<p>Any speed ups using cython, numba, python etc would be great to see.</p>
",35,"<p>This answer completes the good answer of @user2357112 by providing additional details. Both functions are optimized. That being said the pair-wise summation is generally a bit slower while providing generally a more accurate result. It is also sub-optimal yet though relatively good. OpenBLAS which is used by default on Windows does not perform a pair-wise summation.</p>
<p>Here is the assembly code for the Numpy code:</p>
<p><a href=""https://i.sstatic.net/JXbpr.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/JXbpr.png"" alt=""enter image description here"" /></a></p>
<p>Here is the assembly code for the OpenBLAS code:</p>
<p><a href=""https://i.sstatic.net/0ACKm.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/0ACKm.png"" alt=""enter image description here"" /></a></p>
<p><strong>The main issue with the Numpy code is that it does not use AVX</strong> (256-bit SIMD instruction set) but SSE (128-bit SIMD instruction set) as opposed to OpenBLAS, at least at the version 1.22.4 (the one I use) and before. Even worst: <strong>the instructions are scalar one</strong> in the Numpy code! We recently worked on this and the last version of Numpy should now use AVX. That being said, it may still be not as fast as OpenBLAS because of the pair-wise summation (especially for big arrays).</p>
<p>Note that <strong>both functions spent a non-negligible time in overheads</strong> because of the <strong>arrays being too small</strong>. Such overheads can be removed using a hand-written implementation in Numba.</p>
<blockquote>
<p>The order of the timings reverses if the array is much longer.</p>
</blockquote>
<p>This is expected. Indeed, functions are rather compute-bound when they operate in the cache, but they become <strong>memory-bound when the array is big</strong> and fit in the L3 cache or even the RAM. As a result, <code>np.dot</code> stats to be slower for bigger array since it needs to read twice bigger data from memory. More specifically, it needs to read <code>8*1000000*2/1024**2 ~= 15.3 MiB</code> from memory so you likely need to read data from your RAM which have a pretty limited throughout. In fact, a good bi-channel 3200 MHz DDR4 RAM like mine can reach a practical throughput close to 40 GiB and <code>15.3/(40*1024) ~= 374 ¬µs</code>. That being said, sequential codes can hardly completely saturate this throughput so reaching a 30 GiB/s in sequential is already great not to mention many mainstream PC RAM operate at a lower frequency. A 30 GHz/s throughput result in ~500 ¬µs which is close to your timings. Meanwhile, <code>np.sum</code> and <code>np.add.reduce</code> are more compute-bound because of their inefficient implementation, but the amount of data to be read is twice smaller and may actually fit better in the L3 cache having a significantly bigger throughput.</p>
<p>To prove this effect, you can simply try to run:</p>
<pre class=""lang-py prettyprint-override""><code># L3 cache of 9 MiB

# 2 x 22.9 = 45.8 MiB
a = np.ones(3_000_000)
b = np.ones(3_000_000)
%timeit -n 100 np.dot(a, a)   #  494 ¬µs =&gt; read from RAM
%timeit -n 100 np.dot(a, b)   # 1007 ¬µs =&gt; read from RAM

# 2 x 7.6 = 15.2 MiB
a = np.ones(1_000_000)
b = np.ones(1_000_000)
%timeit -n 100 np.dot(a, a)   #  90 ¬µs =&gt; read from the L3 cache
%timeit -n 100 np.dot(a, b)   # 283 ¬µs =&gt; read from RAM

# 2 x 1.9 = 3.8 MiB
a = np.ones(250_000)
b = np.ones(250_000)
%timeit -n 100 np.dot(a, a)   # 40 ¬µs =&gt; read from the L3 cache (quite compute-bound)
%timeit -n 100 np.dot(a, b)   # 46 ¬µs =&gt; read from the L3 cache too (quite memory-bound)
</code></pre>
<p>On my machine, the L3 has only a size of 9 MiB so the second call needs not only to read twice more data but also read it more from the slower RAM than from the L3 cache.</p>
<p><strong>For small array, the L1 cache is so fast that reading data should not be a bottleneck</strong>. On my i5-9600KF machine, the throughput of the L1 cache is huge : ~268 GiB/s. This means the optimal time to read two arrays of size 1000 is <code>8*1000*2/(268*1024**3) ~= 0.056 ¬µs</code>. In practice, the overhead of calling a Numpy function is much bigger than that.</p>
<hr />
<h2>Fast implementation</h2>
<p>Here is a <strong>fast Numba implementation</strong>:</p>
<pre class=""lang-py prettyprint-override""><code>import numba as nb

# Function eagerly compiled only for 64-bit contiguous arrays
@nb.njit('float64(float64[::1],)', fastmath=True)
def fast_sum(arr):
    s = 0.0
    for i in range(arr.size):
        s += arr[i]
    return s
</code></pre>
<p>Here are performance results:</p>
<pre class=""lang-none prettyprint-override""><code> array items |    time    |  speedup (dot/numba_seq)
--------------------------|------------------------
 3_000_000   |   870 ¬µs   |   x0.57
 1_000_000   |   183 ¬µs   |   x0.49
   250_000   |    29 ¬µs   |   x1.38
</code></pre>
<p>If you use the flag <code>parallel=True</code> and <code>nb.prange</code> instead of <code>range</code>, Numba will use <strong>multiple threads</strong>. This is good for large arrays, but it may not be for small ones on some machine (due to the overhead to create threads and share the work):</p>
<pre class=""lang-none prettyprint-override""><code> array items |    time    |  speedup (dot/numba_par)
--------------------------|--------------------------
 3_000_000   |   465 ¬µs   |   x1.06
 1_000_000   |    66 ¬µs   |   x1.36
   250_000   |    10 ¬µs   |   x4.00
</code></pre>
<p>As expected, Numba can be faster for small array (because the Numpy call overhead is mostly removed) and be competitive with OpenBLAS for large array. The code generated by Numba is pretty efficient:</p>
<pre class=""lang-none prettyprint-override""><code>.LBB0_7:
        vaddpd  (%r9,%rdx,8), %ymm0, %ymm0
        vaddpd  32(%r9,%rdx,8), %ymm1, %ymm1
        vaddpd  64(%r9,%rdx,8), %ymm2, %ymm2
        vaddpd  96(%r9,%rdx,8), %ymm3, %ymm3
        vaddpd  128(%r9,%rdx,8), %ymm0, %ymm0
        vaddpd  160(%r9,%rdx,8), %ymm1, %ymm1
        vaddpd  192(%r9,%rdx,8), %ymm2, %ymm2
        vaddpd  224(%r9,%rdx,8), %ymm3, %ymm3
        vaddpd  256(%r9,%rdx,8), %ymm0, %ymm0
        vaddpd  288(%r9,%rdx,8), %ymm1, %ymm1
        vaddpd  320(%r9,%rdx,8), %ymm2, %ymm2
        vaddpd  352(%r9,%rdx,8), %ymm3, %ymm3
        vaddpd  384(%r9,%rdx,8), %ymm0, %ymm0
        vaddpd  416(%r9,%rdx,8), %ymm1, %ymm1
        vaddpd  448(%r9,%rdx,8), %ymm2, %ymm2
        vaddpd  480(%r9,%rdx,8), %ymm3, %ymm3
        addq    $64, %rdx
        addq    $-4, %r11
        jne     .LBB0_7
</code></pre>
<p>That being said, it is not optimal : the LLVM-Lite JIT compiler uses a 4x unrolling while a 8x unrolling should be optimal on my Intel CoffeeLake processor. Indeed, the latency of the <code>vaddpd</code> instruction is 4 cycle while 2 instruction can be executed per cycle so 8 registers are needed to avoid a stall and the resulting code being latency bound. Besides, this assembly code is optimal on Intel Alderlake and Sapphire Rapids processors since they have a twice lower <code>vaddpd</code> latency. Saturating FMA SIMD processing units is far from being easy. I think the only way to write a faster function is to write a (C/C++) native code using SIMD intrinsics though it is less portable.</p>
<p>Note the Numba code does not support special numbers like NaN or Inf value because of <code>fastmath</code> (AFAIK OpenBLAS does). In practice, it should still work on x86-64 machines but this is not guaranteed. Besides, the Numba code is not numerically stable for very large arrays. The Numpy code should be the most numerically stable of the three variants (then the OpenBLAS code). You can compute the sum by chunk to improve the numerical stability though it makes the code more complex. There is not free lunch.</p>
","python, numpy, simd, cython, numba"
Mar-23,Mar-23,"<p>I am currently trying to use OpenAI's most recent model: <code>gpt-3.5-turbo</code>. I am following a very <a href=""https://www.youtube.com/watch?v=0l4UDn1p7gM&amp;ab_channel=TinkeringwithDeepLearning%26AI"" rel=""noreferrer"">basic tutorial</a>.</p>
<p>I am working from a Google Collab notebook. I have to make a request for each prompt in a list of prompts, which for sake of simplicity looks like this:</p>
<pre><code>prompts = ['What are your functionalities?', 'what is the best name for an ice-cream shop?', 'who won the premier league last year?']
</code></pre>
<p>I defined a function to do so:</p>
<pre><code>import openai

# Load your API key from an environment variable or secret management service
openai.api_key = 'my_API'

def get_response(prompts: list, model = &quot;gpt-3.5-turbo&quot;):
  responses = []

  
  restart_sequence = &quot;\n&quot;

  for item in prompts:

      response = openai.Completion.create(
      model=model,
      messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}],
      temperature=0,
      max_tokens=20,
      top_p=1,
      frequency_penalty=0,
      presence_penalty=0
    )

      responses.append(response['choices'][0]['message']['content'])

  return responses
</code></pre>
<p>However, when I call <code>responses = get_response(prompts=prompts[0:3])</code> I get the following error:</p>
<pre><code>InvalidRequestError: Unrecognized request argument supplied: messages
</code></pre>
<p>Any suggestions?</p>
<p>Replacing the <code>messages</code> argument with <code>prompt</code> leads to the following error:</p>
<pre><code>InvalidRequestError: [{'role': 'user', 'content': 'What are your functionalities?'}] is valid under each of {'type': 'array', 'minItems': 1, 'items': {'oneOf': [{'type': 'integer'}, {'type': 'object', 'properties': {'buffer': {'type': 'string', 'description': 'A serialized numpy buffer'}, 'shape': {'type': 'array', 'items': {'type': 'integer'}, 'description': 'Array shape'}, 'dtype': {'type': 'string', 'description': 'Stringified dtype'}, 'token': {'type': 'string'}}}]}, 'example': '[1, 1313, 451, {&quot;buffer&quot;: &quot;abcdefgh&quot;, &quot;shape&quot;: [1024], &quot;dtype&quot;: &quot;float16&quot;}]'}, {'type': 'array', 'minItems': 1, 'maxItems': 2048, 'items': {'oneOf': [{'type': 'string'}, {'type': 'object', 'properties': {'buffer': {'type': 'string', 'description': 'A serialized numpy buffer'}, 'shape': {'type': 'array', 'items': {'type': 'integer'}, 'description': 'Array shape'}, 'dtype': {'type': 'string', 'description': 'Stringified dtype'}, 'token': {'type': 'string'}}}], 'default': '', 'example': 'This is a test.', 'nullable': False}} - 'prompt'
</code></pre>
",55,"<h2>Problem</h2>
<p><strong>You used the wrong method to get a completion.</strong> When using the OpenAI SDK, whether you use Python or Node.js, you need to use the right method.</p>
<p>Which method is the right one? It depends on the OpenAI model you want to use.</p>
<h2>Solution</h2>
<p>The tables below will help you figure out which method is the right one for a given OpenAI model.</p>
<p><strong>STEP 1:</strong> Find in the table below which API endpoint is compatible with the OpenAI model you want to use.</p>
<div class=""s-table-container""><table class=""s-table"">
<thead>
<tr>
<th>API endpoint</th>
<th>Model group</th>
<th>Model name</th>
</tr>
</thead>
<tbody>
<tr>
<td>/v1/chat/completions</td>
<td>‚Ä¢ GPT-4 <br> ‚Ä¢ GPT-3.5</td>
<td>‚Ä¢ <code>gpt-4</code> and dated model releases <br> ‚Ä¢ <code>gpt-4-32k</code> and dated model releases <br> ‚Ä¢ <code>gpt-4-1106-preview</code> <br> ‚Ä¢ <code>gpt-4-vision-preview</code> <br>‚Ä¢ <code>gpt-3.5-turbo</code> and dated model releases <br> ‚Ä¢ <code>gpt-3.5-turbo-16k</code> and dated model releases <br> ‚Ä¢ fine-tuned versions of <code>gpt-3.5-turbo</code></td>
</tr>
<tr>
<td>/v1/completions (Legacy)</td>
<td>‚Ä¢ GPT-3.5 <br> ‚Ä¢ GPT base</td>
<td>‚Ä¢ <code>gpt-3.5-turbo-instruct</code> <br> ‚Ä¢ <code>babbage-002</code> <br> ‚Ä¢ <code>davinci-002</code></td>
</tr>
<tr>
<td>/v1/assistants</td>
<td></td>
<td>All models except <code>gpt-3.5-turbo-0301</code> supported. <br> Retrieval tool requires <code>gpt-4-1106-preview</code> or <code>gpt-3.5-turbo-1106</code>.</td>
</tr>
<tr>
<td>/v1/audio/transcriptions</td>
<td>Whisper</td>
<td>‚Ä¢ <code>whisper-1</code></td>
</tr>
<tr>
<td>/v1/audio/translations</td>
<td>Whisper</td>
<td>‚Ä¢ <code>whisper-1</code></td>
</tr>
<tr>
<td>/v1/audio/speech</td>
<td>TTS</td>
<td>‚Ä¢ <code>tts-1</code> <br> ‚Ä¢ <code>tts-1-hd</code></td>
</tr>
<tr>
<td>/v1/fine_tuning/jobs</td>
<td>‚Ä¢ GPT-3.5 <br> ‚Ä¢ GPT base</td>
<td>‚Ä¢ <code>gpt-3.5-turbo</code> <br> ‚Ä¢ <code>babbage-002</code> <br> ‚Ä¢ <code>davinci-002</code></td>
</tr>
<tr>
<td>/v1/embeddings</td>
<td>Embeddings</td>
<td>‚Ä¢ <code>text-embedding-ada-002</code></td>
</tr>
<tr>
<td>/v1/moderations</td>
<td>Moderations</td>
<td>‚Ä¢ <code>text-moderation-stable</code> <br> ‚Ä¢ <code>text-moderation-latest</code></td>
</tr>
</tbody>
</table></div>
<br>
<p><strong>STEP 2:</strong> Find in the table below which method you need to use for the API endpoint you selected in the table above.</p>
<p><em>Note: Pay attention, because you have to use the method that is compatible with your OpenAI SDK version.</em></p>
<div class=""s-table-container""><table class=""s-table"">
<thead>
<tr>
<th>API endpoint</th>
<th>Method for the<br> Python SDK <code>v0.28.1</code></th>
<th>Method for the<br> Python SDK &gt;=<code>v1.0.0</code></th>
<th>Method for the<br> Node.js SDK <code>v3.3.0</code></th>
<th>Method for the<br> Node.js SDK &gt;=<code>v4.0.0</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>/v1/chat/completions</td>
<td>openai.ChatCompletion.create</td>
<td>openai.chat.completions.create</td>
<td>openai.createChatCompletion</td>
<td>openai.chat.completions.create</td>
</tr>
<tr>
<td>/v1/completions (Legacy)</td>
<td>openai.Completion.create</td>
<td>openai.completions.create</td>
<td>openai.createCompletion</td>
<td>openai.completions.create</td>
</tr>
<tr>
<td>/v1/assistants</td>
<td>/</td>
<td>openai.beta.assistants.create</td>
<td>/</td>
<td>openai.beta.assistants.create</td>
</tr>
<tr>
<td>/v1/audio/transcriptions</td>
<td>openai.Audio.transcribe</td>
<td>openai.audio.transcriptions.create</td>
<td>openai.createTranscription</td>
<td>openai.audio.transcriptions.create</td>
</tr>
<tr>
<td>/v1/audio/translations</td>
<td>openai.Audio.translate</td>
<td>openai.audio.translations.create</td>
<td>openai.createTranslation</td>
<td>openai.audio.translations.create</td>
</tr>
<tr>
<td>/v1/audio/speech</td>
<td>/</td>
<td>openai.audio.speech.create</td>
<td>/</td>
<td>openai.audio.speech.create</td>
</tr>
<tr>
<td>/v1/fine_tuning/jobs</td>
<td>/</td>
<td>openai.fine_tuning.jobs.create</td>
<td>/</td>
<td>openai.fineTuning.jobs.create</td>
</tr>
<tr>
<td>/v1/embeddings</td>
<td>openai.Embedding.create</td>
<td>openai.embeddings.create</td>
<td>openai.createEmbedding</td>
<td>openai.embeddings.create</td>
</tr>
<tr>
<td>/v1/moderations</td>
<td>openai.Moderation.create</td>
<td>openai.moderations.create</td>
<td>openai.createModeration</td>
<td>openai.moderations.create</td>
</tr>
</tbody>
</table></div>
<h4>Python SDK <code>v1.0.0</code> working example for the <a href=""https://platform.openai.com/docs/guides/text-generation/chat-completions-api"" rel=""nofollow noreferrer""><code>gpt-3.5-turbo</code></a> model</h4>
<p>If you run <code>test.py</code>, the OpenAI API will return the following completion:</p>
<blockquote>
<p>Hello! How can I assist you today?</p>
</blockquote>
<p><strong>test.py</strong></p>
<pre><code>import os
from openai import OpenAI

client = OpenAI(
    api_key = os.getenv(&quot;OPENAI_API_KEY&quot;),
)

completion = client.chat.completions.create(
  model = &quot;gpt-3.5-turbo&quot;,
  messages = [
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;},
  ]
)

print(completion.choices[0].message.content.strip())
</code></pre>
<br>
<h4>Node.js SDK <code>v4.0.0</code> working example for the <a href=""https://platform.openai.com/docs/guides/text-generation/chat-completions-api"" rel=""nofollow noreferrer""><code>gpt-3.5-turbo</code></a> model</h4>
<p>If you run <code>test.js</code>, the OpenAI API will return the following completion:</p>
<blockquote>
<p>Hello! How can I assist you today?</p>
</blockquote>
<p><strong>test.js</strong></p>
<pre><code>const OpenAI = require(&quot;openai&quot;);

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

async function main() {
  const completion = await openai.chat.completions.create({
    model: &quot;gpt-3.5-turbo&quot;,
    messages: [
      { role: &quot;system&quot;, content: &quot;You are a helpful assistant.&quot; },
      { role: &quot;user&quot;, content: &quot;Hello!&quot; },
    ],
  });

  console.log(completion.choices[0].message.content.trim());
}

main();
</code></pre>
","python, openai-api, chatgpt-api"
Mar-23,Mar-23,"<p>I have a relatively simple FastAPI app that accepts a query and streams back the response from ChatGPT's API. ChatGPT is streaming back the result and I can see this being printed to console as it comes in.</p>
<p>What's not working is the <code>StreamingResponse</code> back via FastAPI. The response gets sent all together instead. I'm really at a loss as to why this isn't working.</p>
<p>Here is the FastAPI app code:</p>
<pre class=""lang-py prettyprint-override""><code>import os
import time

import openai

import fastapi
from fastapi import Depends, HTTPException, status, Request
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.responses import StreamingResponse

auth_scheme = HTTPBearer()
app = fastapi.FastAPI()

openai.api_key = os.environ[&quot;OPENAI_API_KEY&quot;]


def ask_statesman(query: str):
    #prompt = router(query)
    
    completion_reason = None
    response = &quot;&quot;
    while not completion_reason or completion_reason == &quot;length&quot;:
        openai_stream = openai.ChatCompletion.create(
            model=&quot;gpt-3.5-turbo&quot;,
            messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: query}],
            temperature=0.0,
            stream=True,
        )
        for line in openai_stream:
            completion_reason = line[&quot;choices&quot;][0][&quot;finish_reason&quot;]
            if &quot;content&quot; in line[&quot;choices&quot;][0].delta:
                current_response = line[&quot;choices&quot;][0].delta.content
                print(current_response)
                yield current_response
                time.sleep(0.25)


@app.post(&quot;/&quot;)
async def request_handler(auth_key: str, query: str):
    if auth_key != &quot;123&quot;:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail=&quot;Invalid authentication credentials&quot;,
            headers={&quot;WWW-Authenticate&quot;: auth_scheme.scheme_name},
        )
    else:
        stream_response = ask_statesman(query)
        return StreamingResponse(stream_response, media_type=&quot;text/plain&quot;)


if __name__ == &quot;__main__&quot;:
    import uvicorn
    uvicorn.run(app, host=&quot;0.0.0.0&quot;, port=8000, debug=True, log_level=&quot;debug&quot;)
</code></pre>
<p>And here is the very simple <code>test.py</code> file to test this:</p>
<pre class=""lang-py prettyprint-override""><code>import requests

query = &quot;How tall is the Eiffel tower?&quot;
url = &quot;http://localhost:8000&quot;
params = {&quot;auth_key&quot;: &quot;123&quot;, &quot;query&quot;: query}

response = requests.post(url, params=params, stream=True)

for chunk in response.iter_lines():
    if chunk:
        print(chunk.decode(&quot;utf-8&quot;))
</code></pre>
",65,"<p>First, it wouldn't be good practice to use a <a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/POST"" rel=""noreferrer""><code>POST</code></a> request for requesting data from the server. Using a <a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/GET"" rel=""noreferrer""><code>GET</code></a> request instead would be more suitable, in your case. In addition to that, you shouldn't be sending credentials, such as <code>auth_key</code> as part of the URL (i.e., using the <a href=""https://en.wikipedia.org/wiki/Query_string"" rel=""noreferrer"">query string</a>), but you should rather use <a href=""https://fastapi.tiangolo.com/tutorial/header-params/"" rel=""noreferrer""><code>Headers</code></a> and/or <a href=""https://fastapi.tiangolo.com/tutorial/cookie-params/"" rel=""noreferrer""><code>Cookies</code></a> (using <a href=""https://fastapi.tiangolo.com/deployment/https/"" rel=""noreferrer""><code>HTTPS</code></a>). Please have a look at <a href=""https://stackoverflow.com/a/73599289/17865804"">this answer</a> for more details and examples on the concepts of headers and cookies, as well as the risks involved when using query parameters instead. Helpful posts around this topic can also be found <a href=""https://stackoverflow.com/a/73137093/17865804"">here</a> and <a href=""https://stackoverflow.com/a/74268404/17865804"">here</a>, as well as <a href=""https://stackoverflow.com/a/73662576/17865804"">here</a>, <a href=""https://stackoverflow.com/a/74088523/17865804"">here</a> and <a href=""https://stackoverflow.com/a/70702903/17865804"">here</a>.</p>
<p>Second, if you are executing a blocking operation (i.e., blocking I/O-bound or CPU-bound tasks) inside the <a href=""https://fastapi.tiangolo.com/advanced/custom-response/#streamingresponse"" rel=""noreferrer""><code>StreamingResponse</code></a>'s generator function, you should define the generator function with <code>def</code> instead of <code>async def</code>, as, otherwise, the blocking operation, as well as the <code>time.sleep()</code> function that is used inside your generator, would blcok the event loop. As explained <a href=""https://stackoverflow.com/a/71398460/17865804"">here</a>, if the function for streaming the response body is a normal <code>def</code> generator and not an <code>async def</code> one, FastAPI will use <a href=""https://github.com/encode/starlette/blob/62b5b6042a39289ed561580c251c233250c3c088/starlette/concurrency.py#L58"" rel=""noreferrer""><code>iterate_in_threadpool()</code></a> to run the iterator/generator in a separate thread that is then <code>await</code>ed‚Äîsee <code>StreamingResponse</code>'s <a href=""https://github.com/encode/starlette/blob/3734e85c187a22e30c5ba3530a4f4506912f8eec/starlette/responses.py#L226"" rel=""noreferrer"">relevant source code</a>. If you prefer using an <code>async def</code> generator, then make sure to execute any blocking operations in an external <code>ThreadPool</code> (or <code>ProcessPool</code>) and <code>await</code> it, as well as use <code>await asyncio.sleep()</code> instead of <code>time.sleep()</code>, in cased you need to add delay in the execution of an operation. Have a look at this <a href=""https://stackoverflow.com/a/71517830/17865804"">detailed answer</a> for more details and examples.</p>
<p>Third, you are using <code>requests</code>' <a href=""https://requests.readthedocs.io/en/latest/api/#requests.Response.iter_lines"" rel=""noreferrer""><code>iter_lines()</code></a> function, which iterates over the response data, <strong>one line at a time</strong>. If, however, the response data did not include any line break character (i.e., <code>\n</code>), you wouldn't see the data on client's console getting printed as they arrive, until the entire response is received by the client and printed as a whole. In that case, you should instead use <a href=""https://requests.readthedocs.io/en/latest/api/#requests.Response.iter_content"" rel=""noreferrer""><code>iter_content()</code></a> and specify the <code>chunk_size</code> as desired (both cases are demonstrated in the example below).</p>
<p>Finally, if you would like the <code>StreamingResponse</code> to work in every browser (including Chrome as well)‚Äîin the sense of being able to see the data as they stream in‚Äîyou should specify the <code>media_type</code> to a different type than <code>text/plain</code> (e.g., <code>application/json</code> or <code>text/event-stream</code>, see <a href=""https://stackoverflow.com/a/75837557/17865804"">here</a>), or <strong>disable <a href=""https://mimesniff.spec.whatwg.org/"" rel=""noreferrer"">MIME Sniffing</a></strong>. As explained <a href=""https://stackoverflow.com/a/56089065"">here</a>, browsers will start buffering <code>text/plain</code> responses for a certain amount (around 1445 bytes, as documented <a href=""https://mimesniff.spec.whatwg.org/#reading-the-resource-header"" rel=""noreferrer"">here</a>), in order to check whether or not the content received is actually plain text. To avoid that, you can either set the <code>media_type</code> to <code>text/event-stream</code> (used for <a href=""https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events"" rel=""noreferrer"">server-sent events</a>), or keep using <code>text/plain</code>, but set the <a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Content-Type-Options"" rel=""noreferrer""><code>X-Content-Type-Options</code></a> response header to <code>nosniff</code>, which would disable MIME Sniffing (both options are demonstrated in the example below).</p>
<h1>Working Example</h1>
<p><strong>app.py</strong></p>
<pre class=""lang-py prettyprint-override""><code>from fastapi import FastAPI
from fastapi.responses import StreamingResponse
import asyncio


app = FastAPI()


async def fake_data_streamer():
    for i in range(10):
        yield b'some fake data\n\n'
        await asyncio.sleep(0.5)


# If your generator contains blocking operations such as time.sleep(), then define the
# generator function with normal `def`. Alternatively, use `async def` and run any 
# blocking operations in an external ThreadPool/ProcessPool. (see 2nd paragraph of this answer)
'''
import time

def fake_data_streamer():
    for i in range(10):
        yield b'some fake data\n\n'
        time.sleep(0.5)
'''        

    
@app.get('/')
async def main():
    return StreamingResponse(fake_data_streamer(), media_type='text/event-stream')
    # or, use:
    '''
    headers = {'X-Content-Type-Options': 'nosniff'}
    return StreamingResponse(fake_data_streamer(), headers=headers, media_type='text/plain')
    '''
</code></pre>
<p><strong>test.py</strong> (using Python <code>requests</code>)</p>
<pre class=""lang-py prettyprint-override""><code>import requests

url = &quot;http://localhost:8000/&quot;

with requests.get(url, stream=True) as r:
    for chunk in r.iter_content(1024):  # or, for line in r.iter_lines():
        print(chunk)
</code></pre>
<p><strong>test.py</strong> (using <a href=""https://www.python-httpx.org/"" rel=""noreferrer""><code>httpx</code></a>‚Äîsee <a href=""https://stackoverflow.com/a/73736138/17865804"">this</a>, as well as <a href=""https://stackoverflow.com/a/74239367/17865804"">this</a> and <a href=""https://stackoverflow.com/a/74556972/17865804"">this</a> for the benefits of using <code>httpx</code> over <code>requests</code>)</p>
<pre class=""lang-py prettyprint-override""><code>import httpx

url = 'http://127.0.0.1:8000/'

with httpx.stream('GET', url) as r:
    for chunk in r.iter_raw():  # or, for line in r.iter_lines():
        print(chunk)
</code></pre>
","python, streaming, python-requests, fastapi, openai-api"
Mar-23,Mar-23,"<p>I have an issue with the new Next.js <a href=""https://nextjs.org/docs/app"" rel=""noreferrer"">App Router</a>. They removed head.js files and now (as it is written in the doc) I have to use <a href=""https://nextjs.org/docs/app/building-your-application/optimizing/metadata"" rel=""noreferrer"">metadata</a> in layout.ts. My favicon name is <code>favicon.png</code>.</p>
<p>How do i specify it here:</p>
<pre><code>export const metadata = {
  title: 'Create Next App',
  description: 'Generated by create next app',
}
</code></pre>
",34,"<p>You can do it as follow:</p>
<pre><code>export const metadata = {
  icons: {
    icon: '/icon.png',
  },
};
</code></pre>
<p>The output will be</p>
<pre><code>&lt;link rel=&quot;icon&quot; href=&quot;/icon.png&quot; /&gt;
</code></pre>
<p>See all documentation regarding icons metadata:</p>
<p><a href=""https://beta.nextjs.org/docs/api-reference/metadata#icons"" rel=""noreferrer"">https://beta.nextjs.org/docs/api-reference/metadata#icons</a></p>
","javascript, reactjs, next.js, next.js13"
Mar-23,Mar-23,"<p>OpenAI's text models have a context length, e.g.: Curie has a context length of 2049 tokens.</p>
<p>They provide <code>max_tokens</code> and <code>stop</code> parameters to control the length of the generated sequence. Therefore the generation stops either when stop token is obtained, or <code>max_tokens</code> is reached.</p>
<p>The issue is: when generating a text, I don't know how many tokens my prompt contains. Since I do not know that, I cannot set <code>max_tokens = 2049 - number_tokens_in_prompt</code>.</p>
<p>This prevents me from generating text dynamically for a wide range of text in terms of their length. What I need is to continue generating until the stop token.</p>
<p>My questions are:</p>
<ul>
<li>How can I count the number of tokens in Python API so that I will set <code>max_tokens</code> parameter accordingly?</li>
<li>Is there a way to set <code>max_tokens</code> to the max cap so that I won't need to count the number of prompt tokens?</li>
</ul>
",112,"<h2>How do I count tokens before(!) I send an API request?</h2>
<p>As stated in the official <a href=""https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them"" rel=""noreferrer"">OpenAI article</a>:</p>
<blockquote>
<p>To further explore tokenization, you can use our interactive <a href=""https://platform.openai.com/tokenizer"" rel=""noreferrer"">Tokenizer</a>
tool, which allows you to calculate the number of tokens and see how
text is broken into tokens. <strong>Alternatively, if you'd like to tokenize
text programmatically, use <a href=""https://github.com/openai/tiktoken"" rel=""noreferrer"">tiktoken</a> as a fast BPE tokenizer
specifically used for OpenAI models.</strong></p>
</blockquote>
<h2>How does a tokenizer work?</h2>
<p>A tokenizer can split the text string into a list of tokens, as stated in the official <a href=""https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb"" rel=""noreferrer"">OpenAI example</a> on counting tokens with tiktoken:</p>
<blockquote>
<p>tiktoken is a fast open-source tokenizer by OpenAI.</p>
<p>Given a text string (e.g., <code>&quot;tiktoken is great!&quot;</code>) and an encoding
(e.g., <code>&quot;cl100k_base&quot;</code>), a tokenizer can split the text string into a
list of tokens (e.g., <code>[&quot;t&quot;, &quot;ik&quot;, &quot;token&quot;, &quot; is&quot;, &quot; great&quot;, &quot;!&quot;]</code>).</p>
<p>Splitting text strings into tokens is useful because GPT models see
text in the form of tokens. Knowing how many tokens are in a text
string can tell you:</p>
<ul>
<li>whether the string is too long for a text model to process and</li>
<li>how much an OpenAI API call costs (as usage is priced by token).</li>
</ul>
</blockquote>
<h2>Which encodings does OpenAI use for its models?</h2>
<p>As of April 2024, tiktoken supports 2 encodings used by OpenAI models (<a href=""https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb"" rel=""noreferrer"">source 1</a>, <a href=""https://github.com/openai/tiktoken/blob/main/tiktoken/model.py"" rel=""noreferrer"">source 2</a>):</p>
<div class=""s-table-container""><table class=""s-table"">
<thead>
<tr>
<th>Encoding name</th>
<th>OpenAI models</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>o200k_base</code></td>
<td>‚Ä¢ GPT-4o models (<code>gpt-4o</code>)</td>
</tr>
<tr>
<td><code>cl100k_base</code></td>
<td>‚Ä¢ GPT-4 models (<code>gpt-4</code>)<br>‚Ä¢ GPT-3.5 Turbo models (<code>gpt-3.5-turbo</code>)<br>‚Ä¢ GPT Base models (<code>davinci-002</code>, <code>babbage-002</code>)<br>‚Ä¢ Embeddings models (<code>text-embedding-ada-002</code>, <code>text-embedding-3-large</code>, <code>text-embedding-3-small</code>)<br>‚Ä¢ Fine-tuned models (<code>ft:gpt-4</code>, <code>ft:gpt-3.5-turbo</code>, <code>ft:davinci-002</code>, <code>ft:babbage-002</code>)</td>
</tr>
</tbody>
</table></div>
<p><em>Note: The <code>p50k_base</code> and <code>r50k_base</code> encodings were used for models that are deprecated as of April 2024.</em></p>
<h2>What tokenizer libraries are out there?</h2>
<p>Official OpenAI libraries:</p>
<ul>
<li>Python: <a href=""https://github.com/openai/tiktoken/blob/main/README.md"" rel=""noreferrer"">tiktoken</a></li>
</ul>
<p>3rd-party libraries:</p>
<ul>
<li>Python: <a href=""https://huggingface.co/docs/transformers/model_doc/gpt2#transformers.GPT2TokenizerFast"" rel=""noreferrer"">GPT2TokenizerFast</a></li>
<li>Node.js: <a href=""https://www.npmjs.com/package/@dqbd/tiktoken"" rel=""noreferrer"">tiktoken</a>, <a href=""https://www.npmjs.com/package/gpt4-tokenizer"" rel=""noreferrer"">gpt4-tokenizer</a>, <a href=""https://www.npmjs.com/package/gpt3-tokenizer"" rel=""noreferrer"">gpt3-tokenizer</a>, <a href=""https://www.npmjs.com/package/gpt-3-encoder"" rel=""noreferrer"">gpt-3-encoder</a></li>
<li>.NET / C#: <a href=""https://github.com/tryAGI/Tiktoken"" rel=""noreferrer"">tryAGI.Tiktoken</a>, <a href=""https://github.com/dmitry-brazhenko/SharpToken"" rel=""noreferrer"">SharpToken</a>, <a href=""https://github.com/aiqinxuancai/TiktokenSharp"" rel=""noreferrer"">TiktokenSharp</a>, <a href=""https://github.com/dluc/openai-tools"" rel=""noreferrer"">GPT Tokenizer</a></li>
<li>Java: <a href=""https://github.com/knuddelsgmbh/jtokkit"" rel=""noreferrer"">jtokkit</a>, <a href=""https://github.com/hyunwoongko/gpt2-tokenizer-java"" rel=""noreferrer"">gpt2-tokenizer-java</a></li>
<li>PHP: <a href=""https://github.com/CodeRevolutionPlugins/GPT-3-Encoder-PHP"" rel=""noreferrer"">GPT-3-Encoder-PHP</a></li>
</ul>
<h2>How do I use tiktoken?</h2>
<ol>
<li>Install or upgrade tiktoken: <code>pip install --upgrade tiktoken</code></li>
<li>Write the code to count tokens, where you have two options.</li>
</ol>
<p><strong>OPTION 1: Search in the table above for the correct encoding for a given OpenAI model</strong></p>
<p>If you run <code>get_tokens_1.py</code>, you'll get the following output:</p>
<blockquote>
<p>9</p>
</blockquote>
<p><strong>get_tokens_1.py</strong></p>
<pre><code>import tiktoken

def num_tokens_from_string(string: str, encoding_name: str) -&gt; int:
    encoding = tiktoken.get_encoding(encoding_name)
    num_tokens = len(encoding.encode(string))
    return num_tokens

print(num_tokens_from_string(&quot;Hello world, let's test tiktoken.&quot;, &quot;cl100k_base&quot;))
</code></pre>
<br>
<p><strong>OPTION 2: Use <code>tiktoken.encoding_for_model()</code> to automatically load the correct encoding for a given OpenAI model</strong></p>
<p>If you run <code>get_tokens_2.py</code>, you'll get the following output:</p>
<blockquote>
<p>9</p>
</blockquote>
<p><strong>get_tokens_2.py</strong></p>
<pre><code>import tiktoken

def num_tokens_from_string(string: str, encoding_name: str) -&gt; int:
    encoding = tiktoken.encoding_for_model(encoding_name)
    num_tokens = len(encoding.encode(string))
    return num_tokens

print(num_tokens_from_string(&quot;Hello world, let's test tiktoken.&quot;, &quot;gpt-3.5-turbo&quot;))
</code></pre>
<p><em>Note: If you take a careful look at the usage field in the OpenAI API response, you'll see that it reports 10 tokens used for an identical message. That's 1 token more than tiktoken. I still haven't figured out why. I tested this in the <a href=""https://stackoverflow.com/a/76356218/10347145"">past</a>. As @Jota mentioned in the comment below, there still seems to be a mismatch between the token usage reported by the OpenAI API response and tiktoken.</em></p>
","python, openai-api, gpt-3, chatgpt-api, gpt-4"
Mar-23,Mar-23,"<ul>
<li><strong>tf-nightly version</strong> = 2.12.0-dev2023203</li>
<li><strong>Python version</strong> = 3.10.6</li>
<li><strong>CUDA drivers version</strong> = 525.85.12</li>
<li><strong>CUDA version</strong> = 12.0</li>
<li><strong>Cudnn version</strong> = 8.5.0</li>
<li>I am using <strong>Linux</strong> (x86_64, Ubuntu 22.04)</li>
<li>I am coding in <strong>Visual Studio Code</strong> on a <strong>venv</strong> virtual environment</li>
</ul>
<p>I am trying to run some models on the GPU (NVIDIA GeForce RTX 3050) using tensorflow nightly 2.12 (to be able to use Cuda 12.0). The problem that I have is that apparently every checking that I am making seems to be correct, but in the end the script is not able to detect the GPU. I've dedicated a lot of time trying to see what is happening and nothing seems to work, so any advice or solution will be more than welcomed. The GPU seems to be working for torch as you can see at the very end of the question.</p>
<p>I will show some of the most common checkings regarding CUDA that I did (Visual Studio Code terminal), I hope you find them useful:</p>
<ol>
<li><p><strong>Check CUDA version:</strong></p>
<p><code>$ nvcc --version</code></p>
<pre><code>nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2023 NVIDIA Corporation
Built on Fri_Jan__6_16:45:21_PST_2023
Cuda compilation tools, release 12.0, V12.0.140
Build cuda_12.0.r12.0/compiler.32267302_0
</code></pre>
</li>
<li><p><strong>Check if the connection with the CUDA libraries is correct:</strong></p>
<p><code>$ echo $LD_LIBRARY_PATH</code></p>
<pre><code>/usr/cuda/lib
</code></pre>
</li>
<li><p><strong>Check nvidia drivers for the GPU and check if GPU is readable for the venv:</strong></p>
<p><code>$ nvidia-smi</code></p>
<pre><code>+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |
| N/A   40C    P5     6W /  20W |     46MiB /  4096MiB |     22%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1356      G   /usr/lib/xorg/Xorg                 45MiB |
+-----------------------------------------------------------------------------+
</code></pre>
</li>
<li><p><strong>Add cuda/bin PATH and Check it:</strong></p>
<p><code>$ export PATH=&quot;/usr/local/cuda/bin:$PATH&quot;</code></p>
<p><code>$ echo $PATH</code></p>
<pre><code>/usr/local/cuda-12.0/bin:/home/victus-linux/Escritorio/MasterThesis_CODE/to_share/venv_master/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin
</code></pre>
</li>
<li><p><strong>Custom function to check if CUDA is correctly installed: [<a href=""https://stackoverflow.com/questions/31326015/how-to-verify-cudnn-installation"">function by Sherlock</a>]</strong></p>
<pre class=""lang-bash prettyprint-override""><code>function lib_installed() { /sbin/ldconfig -N -v $(sed 's/:/ /' &lt;&lt;&lt; $LD_LIBRARY_PATH) 2&gt;/dev/null | grep $1; }
function check() { lib_installed $1 &amp;&amp; echo &quot;$1 is installed&quot; || echo &quot;ERROR: $1 is NOT installed&quot;; }
check libcuda
check libcudart
</code></pre>
<pre><code>libcudart.so.12 -&gt; libcudart.so.12.0.146
        libcuda.so.1 -&gt; libcuda.so.525.85.12
        libcuda.so.1 -&gt; libcuda.so.525.85.12
        libcudadebugger.so.1 -&gt; libcudadebugger.so.525.85.12
libcuda is installed
        libcudart.so.12 -&gt; libcudart.so.12.0.146
libcudart is installed
</code></pre>
</li>
<li><p><strong>Custom function to check if Cudnn is correctly installed: [<a href=""https://stackoverflow.com/questions/31326015/how-to-verify-cudnn-installation"">function by Sherlock</a>]</strong></p>
<pre class=""lang-bash prettyprint-override""><code>function lib_installed() { /sbin/ldconfig -N -v $(sed 's/:/ /' &lt;&lt;&lt; $LD_LIBRARY_PATH) 2&gt;/dev/null | grep $1; }
function check() { lib_installed $1 &amp;&amp; echo &quot;$1 is installed&quot; || echo &quot;ERROR: $1 is NOT installed&quot;; }
check libcudnn 
</code></pre>
<pre><code>        libcudnn_cnn_train.so.8 -&gt; libcudnn_cnn_train.so.8.8.0
        libcudnn_cnn_infer.so.8 -&gt; libcudnn_cnn_infer.so.8.8.0
        libcudnn_adv_train.so.8 -&gt; libcudnn_adv_train.so.8.8.0
        libcudnn.so.8 -&gt; libcudnn.so.8.8.0
        libcudnn_ops_train.so.8 -&gt; libcudnn_ops_train.so.8.8.0
        libcudnn_adv_infer.so.8 -&gt; libcudnn_adv_infer.so.8.8.0
        libcudnn_ops_infer.so.8 -&gt; libcudnn_ops_infer.so.8.8.0
libcudnn is installed
</code></pre>
</li>
</ol>
<p>So, once I did these previous checkings I used a script to evaluate if everything was finally ok and then the following error appeared:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

print(f'\nTensorflow version = {tf.__version__}\n')
print(f'\n{tf.config.list_physical_devices(&quot;GPU&quot;)}\n')
</code></pre>
<pre><code>2023-03-02 12:05:09.463343: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2023-03-02 12:05:09.489911: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2023-03-02 12:05:09.490522: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 12:05:10.066759: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT

Tensorflow version = 2.12.0-dev20230203

2023-03-02 12:05:10.748675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-03-02 12:05:10.771263: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...

[]
</code></pre>
<p><strong>Extra check:</strong> I tried to run a checking script on torch and in here it worked so I guess the problem is related with tensorflow/tf-nightly</p>
<pre class=""lang-py prettyprint-override""><code>import torch

print(f'\nAvailable cuda = {torch.cuda.is_available()}')

print(f'\nGPUs availables = {torch.cuda.device_count()}')

print(f'\nCurrent device = {torch.cuda.current_device()}')

print(f'\nCurrent Device location = {torch.cuda.device(0)}')

print(f'\nName of the device = {torch.cuda.get_device_name(0)}')
</code></pre>
<pre><code>Available cuda = True

GPUs availables = 1

Current device = 0

Current Device location = &lt;torch.cuda.device object at 0x7fbe26fd2ec0&gt;

Name of the device = NVIDIA GeForce RTX 3050 Laptop GPU
</code></pre>
<p>Please, if you know something that might help solve this issue, don't hesitate on telling me.</p>
",33,"<p>I think that, as of March 2023, the only tensorflow distribution for cuda 12 is the docker package from NVIDIA.</p>
<p>A tf package for cuda 12 should show the following info</p>
<pre><code>&gt;&gt;&gt; tf.sysconfig.get_build_info() 
OrderedDict([('cpu_compiler', '/usr/bin/x86_64-linux-gnu-gcc-11'), 
('cuda_compute_capabilities', ['compute_86']), 
('cuda_version', '12.0'), ('cudnn_version', '8'), 
('is_cuda_build', True), ('is_rocm_build', False), ('is_tensorrt_build', True)])
</code></pre>
<p>But if we run tf.sysconfig.get_build_info() on any tensorflow package installed via pip, it stills tells that cuda_version is 11.x</p>
<p>So your alternatives are:</p>
<ul>
<li>install docker with the nvidia cloud instructions and run one of the
recent containers</li>
<li>compile tensorflow from source, either nightly or last release. Caveat, it takes a lot of RAM and some time, as all good compilations do, and the occasional error to be corrected on the run. In my case, to define kFP8, the new 8-bits float.</li>
<li>wait</li>
</ul>
","python, gpu, tensorflow"
Apr-23,Apr-23,"<p>I have a pandas data frame which I want to convert into spark data frame. Usually, I use the below code to create spark data frame from pandas but all of sudden I started to get the below error, I am aware that pandas has removed iteritems() but my current pandas version is 2.0.0 and also I tried to install lesser version and tried to created spark df but I still get the same error. The error invokes inside the spark function. What is the solution for this? which pandas version should I install in order to create spark df. I also tried to change the runtime of cluster databricks and tried re running but I still get the same error.</p>
<pre><code>import pandas as pd
spark.createDataFrame(pd.DataFrame({'i':[1,2,3],'j':[1,2,3]}))

error:-
UserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:
  'DataFrame' object has no attribute 'iteritems'
Attempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.
  warn(msg)
AttributeError: 'DataFrame' object has no attribute 'iteritems'
</code></pre>
",39,"<p>It's related to the Databricks Runtime (DBR) version used - the Spark versions in up to DBR 12.2 rely on <code>.iteritems</code> function to construct a Spark DataFrame from Pandas DataFrame.  This issue was fixed in the Spark 3.4 that is available as DBR 13.x.</p>
<p>If you can't upgrade to DBR 13.x, then you need to downgrade the Pandas to latest 1.x version (1.5.3 right now) by using <code>%pip install -U pandas==1.5.3</code> command in your notebook. Although it's just better to use Pandas version shipped with your DBR - it was tested for compatibility with other packages in DBR.</p>
","python, pandas, apache-spark, pyspark, databricks"
Apr-23,Apr-23,"<p>I have recently upgraded Android Studio to Flamingo and also upgraded Gradle from 7.4.2 to 8.0.0. All things working fine in version 7.4.2.</p>
<p>When I generate a signed APK using Gradle 8.0.0, it's giving me a runtime error of <code>java.lang.ClassCastException</code>.</p>
<p>I have tried many solutions like adding Proguard rules for Retrofit, Okio, OkHttp, etc., but it still give me an error like this.</p>
<p>Note: When I downgraded from 8.0.0 to 7.4.2, it's working.</p>
<p>So anyone can help me to find out problem with AGP 8.0.0.</p>
<p><em><strong>build.gradle(app)</strong></em></p>
<pre><code>plugins {
    id 'com.android.application'
    id 'org.jetbrains.kotlin.android'
    id 'kotlin-kapt'
    id 'kotlin-parcelize'
    id 'com.google.dagger.hilt.android'
    id 'com.google.gms.google-services'
    id 'com.google.firebase.crashlytics'
}


android {
    
    compileSdk 33

    defaultConfig {
        
        minSdk 24
        targetSdk 33
        versionCode 22
        versionName &quot;1.0.16&quot;
        multiDexEnabled true

        testInstrumentationRunner &quot;androidx.test.runner.AndroidJUnitRunner&quot;
        /*vectorDrawables {
            useSupportLibrary true
        }*/

        def localPropertiesFile = rootProject.file(&quot;local.properties&quot;)
        def localProperties = new Properties()
        localProperties.load(new FileInputStream(localPropertiesFile))
        buildConfigField &quot;String&quot;, &quot;API_KEY&quot;, localProperties['API_KEY']



    }

    
    buildTypes {
        release {
            minifyEnabled true
            shrinkResources true
            signingConfig signingConfigs.release
            proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'
        }
    }
    compileOptions {
        sourceCompatibility JavaVersion.VERSION_17
        targetCompatibility JavaVersion.VERSION_17
    }
    kotlinOptions {
        jvmTarget = '17'
    }
    buildFeatures {
        compose true
        viewBinding = true
    }
    composeOptions {
        kotlinCompilerExtensionVersion '1.4.2'
    }
    packagingOptions {
        resources {
            excludes += '/META-INF/{AL2.0,LGPL2.1}'
        }
    }
    bundle {
        language {
            enableSplit = false
        }
    }
}

dependencies {

    implementation 'androidx.core:core-ktx:1.10.0'
    implementation 'androidx.appcompat:appcompat:1.6.1'
    implementation 'com.google.android.material:material:1.8.0'
    implementation 'androidx.constraintlayout:constraintlayout:2.1.4'
    implementation 'androidx.multidex:multidex:2.0.1'

    
    implementation 'com.google.accompanist:accompanist-permissions:0.24.11-rc'
    implementation 'com.google.accompanist:accompanist-webview:0.24.11-rc'
    implementation 'com.google.accompanist:accompanist-pager:0.24.13-rc'
    implementation &quot;com.google.accompanist:accompanist-pager-indicators:0.24.13-rc&quot;
    implementation &quot;com.google.accompanist:accompanist-drawablepainter:0.25.1&quot;
    implementation &quot;com.google.accompanist:accompanist-flowlayout:0.31.0-alpha&quot;


   
    implementation 'androidx.activity:activity-compose:1.7.1'
    implementation platform('androidx.compose:compose-bom:2022.10.00')
    implementation 'androidx.compose.ui:ui'
    implementation 'androidx.compose.ui:ui-graphics'
    implementation 'androidx.compose.ui:ui-tooling-preview'
    implementation 'androidx.compose.material:material'
//    implementation 'androidx.compose.material3:material3'
    implementation &quot;androidx.navigation:navigation-compose:2.5.3&quot;
    implementation 'com.google.firebase:protolite-well-known-types:18.0.0'
    implementation &quot;androidx.compose.ui:ui-viewbinding&quot;
    implementation project(path: ':pdfviewer')

  
    testImplementation 'junit:junit:4.13.2'
    androidTestImplementation 'androidx.test.ext:junit:1.1.5'
    androidTestImplementation 'androidx.test.espresso:espresso-core:3.5.1'
    androidTestImplementation &quot;androidx.compose.ui:ui-test-junit4&quot;

    
    implementation &quot;com.google.dagger:hilt-android:2.45&quot;
    debugImplementation &quot;androidx.compose.ui:ui-test-manifest&quot;
    kapt &quot;com.google.dagger:hilt-compiler:2.45&quot;
    kapt &quot;androidx.hilt:hilt-compiler:1.0.0&quot;
    implementation 'androidx.hilt:hilt-navigation-compose:1.0.0'

  
    implementation &quot;androidx.activity:activity-ktx:1.7.1&quot;

  
    implementation &quot;androidx.lifecycle:lifecycle-extensions:2.2.0&quot;
    implementation &quot;androidx.lifecycle:lifecycle-livedata-ktx:2.6.1&quot;
    implementation &quot;androidx.lifecycle:lifecycle-runtime-ktx:2.6.1&quot;
    implementation &quot;androidx.lifecycle:lifecycle-viewmodel-ktx:2.6.1&quot;
    implementation &quot;androidx.lifecycle:lifecycle-process:2.6.1&quot;
    kapt &quot;androidx.lifecycle:lifecycle-compiler:2.6.1&quot;

    /* *****************************************************
       **** Retrofit2
       ****************************************************** */
    implementation 'com.squareup.retrofit2:retrofit:2.9.0'
    implementation 'com.squareup.retrofit2:converter-gson:2.9.0'
    implementation &quot;com.squareup.okhttp3:okhttp:4.9.0&quot;
    implementation &quot;com.squareup.okhttp3:logging-interceptor:4.9.0&quot;
    implementation 'com.squareup.retrofit2:converter-moshi:2.9.0'

   
    implementation 'org.jetbrains.kotlinx:kotlinx-coroutines-core:1.6.4'
    implementation 'org.jetbrains.kotlinx:kotlinx-coroutines-android:1.6.4'

   
    implementation &quot;androidx.room:room-runtime:2.5.1&quot;
    kapt &quot;androidx.room:room-compiler:2.5.1&quot;

    
    implementation &quot;androidx.room:room-ktx:2.5.1&quot;

   
    implementation 'androidx.core:core-splashscreen:1.0.1'

    
    def billing_version = &quot;5.2.0&quot;
    implementation &quot;com.android.billingclient:billing:$billing_version&quot;
    implementation &quot;com.android.billingclient:billing-ktx:$billing_version&quot;
    implementation 'com.google.firebase:firebase-crashlytics-buildtools:2.9.5'

   
    implementation platform('com.google.firebase:firebase-bom:31.1.0')
    implementation 'com.google.firebase:firebase-config-ktx'
    implementation 'com.google.firebase:firebase-analytics-ktx'
    implementation 'com.google.firebase:firebase-crashlytics-ktx'
    implementation 'com.google.firebase:firebase-messaging-ktx'
    implementation 'com.google.android.gms:play-services-ads:22.0.0'

   
    implementation 'com.airbnb.android:lottie-compose:4.0.0'


}

kapt {
    correctErrorTypes true
}
</code></pre>
<p><strong>Project Gradle File</strong></p>
<pre><code>buildscript {
    ext {
        compose_ui_version = '1.5.0-alpha02'
        kotlin_version = '1.8.10'
    }
        dependencies {
            // Add this line
            classpath 'com.google.gms:google-services:4.3.15'
            classpath 'com.google.firebase:firebase-crashlytics-gradle:2.9.5'
            classpath &quot;org.jetbrains.kotlin:kotlin-gradle-plugin:$kotlin_version&quot;
        }
    repositories {
        mavenCentral()
    }
}// Top-level build file where you can add configuration options common to all sub-projects/modules.
plugins {
    id 'com.android.application' version '8.0.0' apply false
    id 'com.android.library' version '8.0.0' apply false
    id 'org.jetbrains.kotlin.android' version '1.8.10' apply false
    id 'com.google.dagger.hilt.android' version '2.44' apply false
}
</code></pre>
",3,"<p>I was facing this issue because of the <strong>Parcelize plugin</strong>. I'm using the Parcelize plugin to pass Custom Object ArrayList between activities.</p>
<p>After a lot of trials finally found the solution of changing <em><strong>proguard-rules.pro</strong></em> files.</p>
<p>Here is my content of <em><strong>proguard-rules.pro</strong></em> file</p>
<pre><code># Add project specific ProGuard rules here.
# You can control the set of applied configuration files using the
# proguardFiles setting in build.gradle.
#
# For more details, see
#   http://developer.android.com/guide/developing/tools/proguard.html

# If your project uses WebView with JS, uncomment the following
# and specify the fully qualified class name to the JavaScript interface
# class:
#-keepclassmembers class fqcn.of.javascript.interface.for.webview {
#   public *;
#}

# Uncomment this to preserve the line number information for
# debugging stack traces.
#-keepattributes SourceFile,LineNumberTable

# If you keep the line number information, uncomment this to
# hide the original source file name.
#-renamesourcefileattribute SourceFile

-dontwarn rx.**

-dontwarn okio.**

-dontwarn com.squareup.okhttp.**
-keep class com.squareup.okhttp.** { *; }
-keep interface com.squareup.okhttp.** { *; }

-dontwarn retrofit.**
-keep class retrofit.** { *; }
-keepclasseswithmembers class * {
    @retrofit.http.* &lt;methods&gt;;
}

-keepattributes Signature
-keepattributes *Annotation*


-dontwarn javax.annotation.**

# A resource is loaded with a relative path so the package of this class must be preserved.
-adaptresourcefilenames okhttp3/internal/publicsuffix/PublicSuffixDatabase.gz

# Animal Sniffer compileOnly dependency to ensure APIs are compatible with older versions of Java.
-dontwarn org.codehaus.mojo.animal_sniffer.*

# OkHttp platform used only on JVM and when Conscrypt and other security providers are available.
-dontwarn okhttp3.internal.platform.**
-dontwarn org.conscrypt.**
-dontwarn org.bouncycastle.**
-dontwarn org.openjsse.**

-repackageclasses
-ignorewarnings

# Retrofit does reflection on generic parameters. InnerClasses is required to use Signature and
# EnclosingMethod is required to use InnerClasses.
-keepattributes Signature, InnerClasses, EnclosingMethod

# Retrofit does reflection on method and parameter annotations.
-keepattributes RuntimeVisibleAnnotations, RuntimeVisibleParameterAnnotations

# Keep annotation default values (e.g., retrofit2.http.Field.encoded).
-keepattributes AnnotationDefault

# Retain service method parameters when optimizing.
-keepclassmembers,allowshrinking,allowobfuscation interface * {
    @retrofit2.http.* &lt;methods&gt;;
}

# Ignore JSR 305 annotations for embedding nullability information.
-dontwarn javax.annotation.**

# Guarded by a NoClassDefFoundError try/catch and only used when on the classpath.
-dontwarn kotlin.Unit

# Top-level functions that can only be used by Kotlin.
-dontwarn retrofit2.KotlinExtensions
-dontwarn retrofit2.KotlinExtensions$*

# With R8 full mode, it sees no subtypes of Retrofit interfaces since they are created with a Proxy
# and replaces all potential values with null. Explicitly keeping the interfaces prevents this.
-if interface * { @retrofit2.http.* &lt;methods&gt;; }
-keep,allowobfuscation interface &lt;1&gt;

# Keep inherited services.
-if interface * { @retrofit2.http.* &lt;methods&gt;; }
-keep,allowobfuscation interface * extends &lt;1&gt;

# Keep generic signature of Call, Response (R8 full mode strips signatures from non-kept items).
-keep,allowobfuscation,allowshrinking interface retrofit2.Call
-keep,allowobfuscation,allowshrinking class retrofit2.Response

# With R8 full mode generic signatures are stripped for classes that are not
# kept. Suspend functions are wrapped in continuations where the type argument
# is used.
-keep,allowobfuscation,allowshrinking class kotlin.coroutines.Continuation


# Animal Sniffer compileOnly dependency to ensure APIs are compatible with older versions of Java.
-dontwarn org.codehaus.mojo.animal_sniffer.*

#-keep public class com.itextpdf.**
-keep class com.itextpdf.** { *; }
-dontwarn com.itextpdf.*

-renamesourcefileattribute SourceFile

-dontwarn retrofit2.**
-keep class retrofit2.** {*;}

##---------------Begin: proguard configuration for Gson  ----------
# Gson uses generic type information stored in a class file when working with fields. Proguard
# removes such information by default, so configure it to keep all of it.
-keepattributes Signature

# For using GSON @Expose annotation
-keepattributes *Annotation*

# Gson specific classes
-dontwarn sun.misc.**
#-keep class com.google.gson.stream.** { *; }

# Application classes that will be serialized/deserialized over Gson
-keep class com.google.gson.examples.android.model.** { &lt;fields&gt;; }

# Prevent proguard from stripping interface information from TypeAdapter, TypeAdapterFactory,
# JsonSerializer, JsonDeserializer instances (so they can be used in @JsonAdapter)
-keep class * extends com.google.gson.TypeAdapter
-keep class * implements com.google.gson.TypeAdapterFactory
-keep class * implements com.google.gson.JsonSerializer
-keep class * implements com.google.gson.JsonDeserializer

# Prevent R8 from leaving Data object members always null
-keepclassmembers,allowobfuscation class * {
  @com.google.gson.annotations.SerializedName &lt;fields&gt;;
}


-keep class com.google.gson.reflect.TypeToken
-keep class * extends com.google.gson.reflect.TypeToken
-keep public class * implements java.lang.reflect.Type


# Retain generic signatures of TypeToken and its subclasses with R8 version 3.0 and higher.
-keep,allowobfuscation,allowshrinking class com.google.gson.reflect.TypeToken
-keep,allowobfuscation,allowshrinking class * extends com.google.gson.reflect.TypeToken

##---------------End: proguard configuration for Gson  ----------
-dontwarn org.slf4j.**

-keepdirectories src/main/res/font/*



-dontusemixedcaseclassnames
-verbose
-keepattributes *Annotation*

# For native methods, see http://proguard.sourceforge.net/manual/examples.html#native
-keepclasseswithmembernames class * {
    native &lt;methods&gt;;
}

# keep setters in Views so that animations can still work.
# see http://proguard.sourceforge.net/manual/examples.html#beans
-keepclassmembers public class * extends android.view.View {
   void set*(***);
   *** get*();
}

# We want to keep methods in Activity that could be used in the XML attribute onClick
-keepclassmembers class * extends android.app.Activity {
   public void *(android.view.View);
}

# For enumeration classes, see http://proguard.sourceforge.net/manual/examples.html#enumerations
-keepclassmembers enum * {
    public static **[] values();
    public static ** valueOf(java.lang.String);
}

-keep class * implements android.os.Parcelable {
  public static final android.os.Parcelable$Creator *;
}

-keepclassmembers class **.R$* {
    public static &lt;fields&gt;;
}

# Firebase
-keep class com.google.android.gms.** { *; }
-keep class com.google.firebase.** { *; }

# in order to provide the most meaningful crash reports, add the following line:
-keepattributes SourceFile,LineNumberTable
# If you are using custom exceptions, add this line so that custom exception types are skipped during obfuscation:
-keep public class * extends java.lang.Exception

-keep class com.crashlytics.** { *; }
-dontwarn com.crashlytics.**

# Jackson
-keep @com.fasterxml.jackson.annotation.JsonIgnoreProperties class * { *; }
-keep class com.fasterxml.** { *; }
-keep class org.codehaus.** { *; }
-keepnames class com.fasterxml.jackson.** { *; }
-keepclassmembers public final enum com.fasterxml.jackson.annotation.JsonAutoDetect$Visibility {
    public static final com.fasterxml.jackson.annotation.JsonAutoDetect$Visibility *;
}

# General
-keepattributes SourceFile,LineNumberTable,*Annotation*,EnclosingMethod,Signature,Exceptions,InnerClasses
</code></pre>
<p><strong>This code is for parcelize plugin</strong></p>
<pre><code># For enumeration classes, see http://proguard.sourceforge.net/manual/examples.html#enumerations
    -keepclassmembers enum * {
        public static **[] values();
        public static ** valueOf(java.lang.String);
    }
    
    -keep class * implements android.os.Parcelable {
      public static final android.os.Parcelable$Creator *;
    }
    
    -keepclassmembers class **.R$* {
        public static &lt;fields&gt;;
    }
</code></pre>
","java, gradle, kotlin, android-gradle-plugin, gradle-plugin"
Apr-23,Apr-23,"<p>I have seen many different things go wrong when trying to use the Tkinter standard library package, or its related functionality (turtle graphics using <code>turtle</code> and the built-in IDLE IDE), or with third-party libraries that have this as a dependency (e.g. displaying graphical windows with Matplotlib).</p>
<p>It seems that even when there isn't a <a href=""https://stackoverflow.com/questions/36250353"">problem caused by shadowing the name of the standard library modules</a> (this is a common problem for beginners trying to follow a tutorial and use turtle graphics - <a href=""/q/60480328"">example 1</a>; <a href=""/q/17530140"">example 2</a>; <a href=""/q/53692691"">example 3</a>; <a href=""/q/32180949"">example 4</a>), <strong>it commonly happens that the standard library Tkinter just doesn't work</strong>. This is a big problem because, again, a lot of beginners try to follow tutorials that use turtle graphics and blindly assume that the <code>turtle</code> standard library will be present.</p>
<p>The error might be reported:</p>
<ul>
<li><p>As <a href=""https://stackoverflow.com/questions/25905540""><code>ModuleNotFoundError: No module named 'tkinter'</code></a>; or an <code>ImportError</code> with the same message; or with different casing (I am aware that <a href=""https://stackoverflow.com/questions/17843596"">the name changed from <code>Tkinter</code> in 2.x to <code>tkinter</code> in 3.x</a>; that is a different problem).</p>
</li>
<li><p>Similarly, but <a href=""https://stackoverflow.com/questions/5459444"">referring to an internal <code>_tkinter</code> module</a>, and displaying code with a comment that says &quot;If this fails your Python may not be configured for Tk&quot;; or <a href=""https://stackoverflow.com/questions/15884075"">with a custom error message</a> that says &quot;please install the python-tk package&quot; or similar.</p>
</li>
<li><p>As &quot;No module named turtle&quot; <a href=""https://stackoverflow.com/questions/55318093"">when trying to use <code>turtle</code> specifically</a>, or one of the above errors.</p>
</li>
<li><p><a href=""/q/56656777"">When trying to display a plot using Matplotlib</a>; commonly, this will happen after trying to change the backend, which was set by default to avoid trying to use Tkinter.</p>
</li>
</ul>
<p><strong>Why do problems like this occur</strong>, when Tkinter is <a href=""https://docs.python.org/3/library/tk.html"" rel=""noreferrer"">documented as being part of the standard library</a>? How can I <strong>add or repair the missing standard library functionality</strong>? Are there any special concerns for specific Python environments?</p>
<hr />
<p><sub>See also: <a href=""https://stackoverflow.com/questions/56656777"">&quot;UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.&quot; when plotting figure with pyplot on Pycharm</a> . It is possible to use other GUI backends with Matplotlib to display graphs; but if the <code>TkAgg</code> backend does not work, that is because of a missing or faulty Tkinter install.</sub></p>
<p><sub>In Python 3.x, the name of the Tkinter standard library module was corrected from <code>Tkinter</code> to <code>tkinter</code> (i.e., all lowercase) in order to maintain consistent naming conventions. Please use <a href=""https://stackoverflow.com/questions/17843596"">Difference between tkinter and Tkinter</a> to close duplicate questions caused by trying to use the old name in 3.x (or the new name in 2.x). This question is about cases where Tkinter is not actually available. If it isn't clear which case applies, please either offer both duplicate links, or close the question as &quot;needs debugging details&quot;.</sub></p>
",43,"<h2>WARNING: Do not use <code>pip</code> to try to solve the problem</h2>
<p><strong>The Pip package manager cannot help to solve the problem. No part of the Python standard library - including <code>tkinter</code>, <code>turtle</code> etc. - can be installed from PyPI. For security reasons, PyPI now blocks packages using names that match the standard library.</strong></p>
<p>There are many packages on PyPI that may look suitable, but are not. Most are simply wrappers that try to add a little functionality to the standard library Tkinter. However, one especially problematic package is <code>turtle</code>. It should not be there, because <a href=""https://github.com/pypi/warehouse/issues/2151"" rel=""noreferrer"">current policy (since 2017) is to block packages with names that match the standard library</a>; but it was uploaded long before that, and has not been maintained since. It is <strong>Python 2.x specific code that <a href=""https://stackoverflow.com/questions/55318093"">will break during installation</a></strong> on Python 3, is <strong>extremely out of date</strong> (published in 2009) and - most importantly - <strong>has nothing whatsoever to do with turtle graphics</strong>.</p>
<p>Shortly before the original draft of this Q&amp;A, I <a href=""https://github.com/pypi/support/issues/2771"" rel=""noreferrer"">put in a request</a> to get the <code>turtle</code> package delisted from PyPI. As of this update (over a year later), it appears that something may soon be done about it.</p>
<h2>Why some Python installations don't include Tkinter components</h2>
<p>There are several reasons why Tkinter might be missing, depending on the platform (although generally, the <em>motivation</em> is probably just to save space).</p>
<ul>
<li><p>When Python is installed on Windows using the official installer, there is an option to include or exclude Tcl/Tk support.</p>
</li>
<li><p>Python installations that come pre-installed with Linux may exclude Tkinter, or various components, according to the distro maintainer's policy. For example, the Python that came with my copy of Linux included the <code>turtle</code> standard library, but not the underlying Tkinter package:</p>
<pre><code>&gt;&gt;&gt; import turtle
Traceback (most recent call last):
  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;
  File &quot;/usr/lib/python3.8/turtle.py&quot;, line 107, in &lt;module&gt;
    import tkinter as TK
ModuleNotFoundError: No module named 'tkinter'
</code></pre>
<p>Other builds might not include the <code>turtle</code> module either.</p>
</li>
<li><p>Python built from source might be missing Tkinter support because of deliberately chosen configuration options, or because dependencies were missing before starting compilation.</p>
</li>
</ul>
<p>Note that <strong>virtual environments will generally have the same Tkinter support as the Python installation they're based upon</strong>. However, adding Tkinter support to the base <strong>might not update the virtual environment</strong>. In this case, it will be necessary to re-create the virtual environment from scratch. <strong>It is <a href=""https://unix.stackexchange.com/questions/738583"">not possible to add or remove Tkinter support for an individual virtual environment</a>.</strong> This is because a virtual environment only differs from its base in terms of the site packages, and there is no site package for Tkinter (since, again, it is a standard library component that <strong>cannot be obtained using Pip</strong>).</p>
<h2>How to add Tkinter support, depending on the environment</h2>
<p><strong>See also</strong>:</p>
<ul>
<li>Guide in the official Tk documentation: <a href=""https://tkdocs.com/tutorial/install.html"" rel=""noreferrer"">https://tkdocs.com/tutorial/install.html</a></li>
<li>Some previous (now duplicate) versions of the question with some useful answers:
<ul>
<li><a href=""https://stackoverflow.com/questions/4783810"">Install tkinter for Python</a></li>
<li><a href=""https://stackoverflow.com/questions/5459444"">Tkinter: &quot;Python may not be configured for Tk&quot;</a></li>
<li><a href=""https://stackoverflow.com/questions/25905540"">ImportError: No module named &#39;Tkinter&#39;</a></li>
</ul>
</li>
</ul>
<h3>Windows</h3>
<p>For Python installed using the official installer from python.org, use the operating system features to choose to <strong>&quot;repair&quot; the installation</strong> (or, if acceptable, uninstall and reinstall Python). This time, make sure to <strong>check the option to install the &quot;tcl/tk and IDLE&quot;</strong> optional feature.</p>
<p>Some legacy setups <a href=""https://stackoverflow.com/questions/8724729"">may have had issues with conflicts between 32- and 64-bit versions of Python and Tcl/Tk</a>. This should not cause problems on new setups.</p>
<p>For the embeddable zip package, see <a href=""https://stackoverflow.com/questions/37710205"">Python embeddable zip: install Tkinter</a> .</p>
<h3>Linux: Python that came with the Linux distribution</h3>
<p>If the Python that came with your Linux distribution doesn't include Tkinter, consider leaving that alone and installing a separate version of Python - just on general principle. However, in general, Tkinter support can be added to the <em>system</em> Python using the <strong>system package manager (not Pip)</strong>.</p>
<p>It will <strong>typically be necessary to use <code>sudo</code> (not included in examples here)</strong> to make such changes to the system Python.</p>
<ul>
<li><p>On <strong>Ubuntu and Debian</strong> based systems (including Pop!_OS, Ubuntu-based Mint): use <code>apt-get install python3-tk</code>, assuming the system Python is a 3.x version. For 2.x legacy systems, use <code>apt-get install python-tk</code> instead. In some cases it may be necessary to specify a minor version, like <code>apt-get install python3.11-tk</code>. <a href=""https://stackoverflow.com/questions/9532547"">In some cases</a>, a custom exception message may say to install <code>python-tk</code> even though <code>python3-tk</code> should actually be installed instead.</p>
</li>
<li><p>For <strong>Fedora</strong>, use <code>dnf install python3-tkinter</code>, as described by d-coder <a href=""https://stackoverflow.com/a/25905642"">here</a>.</p>
</li>
<li><p>For <strong>Arch</strong>, use <code>pacman -S tk</code>, as described by Jabba <a href=""https://stackoverflow.com/a/36901234"">here</a>.</p>
</li>
<li><p>For <strong>RHEL</strong>, use <code>yum install python3-tkinter</code>, as described by amzy-0 <a href=""https://stackoverflow.com/a/66292120"">here</a>.</p>
</li>
</ul>
<h3>Linux: Python built from source</h3>
<p>The above packages can <em>only</em> add Tkinter support to the <em>system</em> python (the one installed in <code>/usr/bin</code>, which is used by the operating system to run essential scripts). They <em>cannot</em> add Tkinter support to a separate Python built from source. This is because, <em>in addition to</em> the actual Tcl/Tk library, using Tkinter in Python requires a per-installation &quot;binding&quot; library (referred to as <code>_tkinter</code> in the Python source code). <strong>System packages will not add this library to other Python installations</strong>.</p>
<p>Therefore, <strong>install a <em>development</em> Tk package first</strong> (e.g. <code>apt-get install tk-dev</code>) and try rebuilding.</p>
<p>See also:</p>
<ul>
<li><p><a href=""https://stackoverflow.com/questions/60469202"">Unable to install tkinter with pyenv Pythons on MacOS</a> (using <code>pyenv</code>)</p>
</li>
<li><p><a href=""https://stackoverflow.com/questions/11948295"">Install tkinter and python locally</a> (in case <code>sudo</code> privileges are not available)</p>
</li>
<li><p><a href=""https://stackoverflow.com/questions/6171210"">Building Python and more on missing modules</a> (more generally about rebuilding Python from source and filling in development dependencies)</p>
</li>
</ul>
<h3>Brew (typically MacOS)</h3>
<p>Use <code>brew install python-tk</code>; if necessary, specify a Python version like <code>brew install python-tk@3.11</code>.</p>
<p>For non-system installations, it may be necessary to re-install and specify that Tkinter support should be included, like <code>brew install python --with-tcl-tk</code>. See also: <a href=""https://stackoverflow.com/questions/36760839"">Why does Python installed via Homebrew not include Tkinter</a></p>
<h3>Headless environments</h3>
<p>It's <strong>generally not possible to install Tkinter - or any other GUI toolkit</strong> - for <a href=""https://help.pythonanywhere.com/pages/TkinterPygameEtc"" rel=""noreferrer"">headless server environments like PythonAnywhere</a> or <a href=""https://stackoverflow.com/questions/40675417"">Amazon Linux EC2</a>. The code will run on a remote server, so there is no monitor to display the GUI; while it would be possible in principle for the code to send commands back to the client that the client could then use to create a GUI, in general the server will have no knowledge of the client's environment. Making this work would require setting up some communication protocol ahead of time (<a href=""https://unix.stackexchange.com/questions/276168/what-is-x11-exactly"">such as X11</a>).</p>
<h3>Virtual environments</h3>
<p>First, <strong>fix the installation that the virtual environment is based upon</strong>. If this doesn't resolve the problem, <strong>re-create the virtual environment</strong> (and reinstall everything that was installed in the old virtual environment). Unfortunately, there is not a clean way around this. It might be possible to patch around the problem by changing a bunch of symlinks, but this is not supported.</p>
<p>If it is not possible to fix the base installation (for example, due to not having <code>sudo</code> rights on the system), <strong>consider installing a separate Python</strong> (for example, by compiling from source), ensuring that it is installed with Tkinter support, and creating virtual environments from <em>that</em> Python.</p>
<p>Additional hints: <a href=""https://stackoverflow.com/questions/15884075"">TKinter in a Virtualenv</a></p>
<h2>Tkinter components</h2>
<p>Some users will find it useful to understand exactly what the Tkinter system contains. There are several components:</p>
<ul>
<li><p>The underlying Tcl/Tk library, written in C. Some systems may independently have a Tcl/Tk installation that is unusable from Python by default.</p>
</li>
<li><p>The <code>_tkinter</code> implementation module, which is also written in C and which interfaces between Python and Tcl/Tk (&quot;tkinter&quot; means &quot;Tk interface&quot;). This is an implementation detail, and should not be imported directly in Python user code. (the <a href=""https://github.com/python/cpython/blob/main/Modules/_tkinter.c"" rel=""noreferrer"">C code</a> for this dates all the way back to 1994!)</p>
</li>
<li><p>The <code>tkinter</code> package itself, which provides wrappers for the lower-level <code>_tkinter</code> interface, as well as <code>ttk</code> (a separate interface for newer &quot;themed&quot; widgets).</p>
</li>
<li><p>Higher-level components, such as IDLE and <code>turtle</code>.</p>
</li>
</ul>
<p><strong>Any given installation could theoretically be missing any or all of these components.</strong> For system installations of Python on Linux and MacOS, the distro maintainer is responsible for making sure that the appropriate package (<code>python3-tk</code> or similar) installs whichever parts are missing by default, to the appropriate places.</p>
<p>As <a href=""https://github.com/python/cpython/issues/102501"" rel=""noreferrer"">explained to me on GitHub by Terry Jan Reedy</a>: when the <strong>Windows</strong> installer is told to install Tcl/Tk, it <strong>will install a separate copy</strong> of that library (and the corresponding <code>_tkinter</code> and <code>tkinter</code> etc.) for that Python installation. <strong>On Linux, Tcl/Tk will normally come with Linux</strong>; packages like <code>python3-tk</code> will add a <code>_tkinter</code> that uses the system Tcl/Tk, and a <code>tkinter</code> package (which will naturally find and use the <code>_tkinter</code> implementation, using the normal import mechanism).</p>
<p><strong>Since the Tcl/Tk installation is thus &quot;vendored&quot; for Windows, the Tcl/Tk version will depend on the Python version. On Linux it will depend on the system</strong>, and it should be possible to use the system package manager to upgrade Tcl/Tk independently of Python. Note in particular that newer versions of Python might not be able to work with an outdated system Tcl/Tk. (To check the Tcl/Tk version <em>for a working installation</em>, see <a href=""https://stackoverflow.com/questions/35999344"">How to determine what version of python3 tkinter is installed on my linux machine?</a> .)</p>
","python, installation, tkinter, modulenotfounderror"
Apr-23,Apr-23,"<p>I updated my android studio to the flamingo version today, and I found it strange that there is no longer an option to select languages on the new project screen. Is this a bug? did I do something wrong? Or is there really no more support for the java language in Flamingo? How can I resolve this?</p>
<p>Thanks for any help! Unfortunately I didn't find any answer to this problem on the internet.</p>
<p><img src=""https://i.sstatic.net/QEFqg.png"" alt=""new project options"" /></p>
<p>I do not know what to do.</p>
",62,"<p>On <strong>Android Studio Flamingo | 2022.2.1</strong>, you can select <strong>Empty Views Activity</strong> when creating a new project as shown below.
<a href=""https://i.sstatic.net/czhZ6.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/czhZ6.png"" alt=""enter image description here"" /></a></p>
<p>And you can still choose the <strong>Java</strong> or <strong>Kotlin</strong> language as usual.
<a href=""https://i.sstatic.net/j8SuR.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/j8SuR.png"" alt=""enter image description here"" /></a></p>
","java, android, kotlin, android-studio"
Apr-23,Apr-23,"<p>I used Metaflow to load a Dataframe. It was successfully unpickled from the artifact store, but when I try to view its index using <code>df.index</code>, I get an error that says <code>ModuleNotFoundError: No module named 'pandas.core.indexes.numeric'</code>. Why?</p>
<p>I've looked at other answers with similar error messages <a href=""https://stackoverflow.com/questions/51285798"">here</a> and <a href=""https://stackoverflow.com/questions/37371451"">here</a>, which say that this is caused by trying to unpickle a dataframe with older versions of Pandas. However, my error is slightly different, and it is not fixed by upgrading Pandas (<code>pip install pandas -U</code>).</p>
",45,"<p>This issue is caused by the new <a href=""https://pandas.pydata.org/docs/whatsnew/v2.0.0.html"" rel=""noreferrer"">Pandas 2.0.0 release</a> breaking backwards compatibility with Pandas 1.x, although I don't see this documented in the release notes. The solution is to downgrade pandas to the 1.x series: <code>pip install &quot;pandas&lt;2.0.0&quot;</code></p>
","python, pickle, pandas, netflix-metaflow"
May-23,May-23,"<p>After <code>pip install openai</code>, when I try to <code>import openai</code>, it shows this error:</p>
<blockquote>
<p>the 'ssl' module of urllib3 is compile with LibreSSL not OpenSSL</p>
</blockquote>
<p>I just followed a tutorial on a project about using API of OpenAI. But when I get to the first step which is the install and import OpenAI, I got stuck. And I tried to find the solution for this error but I found nothing.</p>
<p>Here is the message after I try to import OpenAI:</p>
<pre class=""lang-none prettyprint-override""><code>Python 3.9.6 (default, Mar 10 2023, 20:16:38)
[Clang 14.0.3 (clang-1403.0.22.14.1)] on darwin
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.

&gt;&gt;&gt; import openai

Traceback (most recent call last):
  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;
  File &quot;/Users/yule/Library/Python/3.9/lib/python/site-packages/openai/__init__.py&quot;, line 19, in &lt;module&gt;
    from openai.api_resources import (
  File &quot;/Users/mic/Library/Python/3.9/lib/python/site-packages/openai/api_resources/__init__.py&quot;, line 1, in &lt;module&gt;
    from openai.api_resources.audio import Audio  # noqa: F401
  File &quot;/Users/mic/Library/Python/3.9/lib/python/site-packages/openai/api_resources/audio.py&quot;, line 4, in &lt;module&gt;
    from openai import api_requestor, util
  File &quot;/Users/mic/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py&quot;, line 22, in &lt;module&gt;
    import requests
  File &quot;/Users/mic/Library/Python/3.9/lib/python/site-packages/requests/__init__.py&quot;, line 43, in &lt;module&gt;
    import urllib3
  File &quot;/Users/mic/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py&quot;, line 38, in &lt;module&gt;
    raise ImportError(
ImportError: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with LibreSSL 2.8.3. See: https://github.com/urllib3/urllib3/issues/2168
</code></pre>
<p>I tried to <code>--upgrade</code> the <code>urllib3</code>, but it is still not working. The result is:</p>
<pre class=""lang-none prettyprint-override""><code>pip3 install --upgrade urllib3
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: urllib3 in ./Library/Python/3.9/lib/python/site-packages (2.0.2)
</code></pre>
",240,"<p>The reason why the error message mentioned OpenSSL 1.1.1+ and LibreSSL 2.8.3 is that urllib3 v2.0 (the version you've installed) requires OpenSSL 1.1.1+ to work properly, as it relies on some new features of OpenSSL 1.1.1.</p>
<p>The issue is that the version of the 'ssl' module that is currently installed in your environment is compiled with LibreSSL 2.8.3, which is not compatible with urllib3 v2.0.</p>
<p>To use urllib3 v2.0, you need an 'ssl' module compiled with OpenSSL 1.1.1 or later, by trying:</p>
<pre class=""lang-none prettyprint-override""><code>brew install openssl@1.1
</code></pre>
<p>Or you could use an older version of urllib3 that is compatible suc. For example urllib3 v1.26.6, which does not have a strict OpenSSL version requirement.
You can force the version installing with this command:</p>
<pre class=""lang-none prettyprint-override""><code>pip install urllib3==1.26.6
</code></pre>
","python, urllib3, openai-api"
May-23,May-23,"<p>I have a root layout <code>/app/layout.tsx</code> and authentication pages. I want the authentication pages NOT to get the root layout, and I defined a custom layout for them in the <code>/app/auth/layout.tsx</code> file.</p>
<p>But the root layout(<code>/app/layout.tsx</code>) wraps the custom layout(<code>/app/auth/layout.tsx</code>). How can I exclude the auth pages and sub-pages from getting the root layout?</p>
<p>I tried putting the auth dir name in <code>()</code> as <code>(auth)</code> but not working. Most of the solution are for the <strong>Pages Router</strong> and doesn't work for <strong>App Router</strong>.</p>
<p>I'm using Next.js <code>13.4</code>.</p>
",33,"<p>In the <code>app</code> directory of Next.js, view the root layout as the <code>index.html</code> file when using <a href=""https://create-react-app.dev"" rel=""noreferrer"">Create React App</a> or <a href=""https://vitejs.dev"" rel=""noreferrer"">Vite</a>. Your components should render there. This is why it's required and should define <code>html</code> and <code>body</code> tags, as the <a href=""https://nextjs.org/docs/app/api-reference/file-conventions/layout#root-layouts"" rel=""noreferrer"">doc</a> says:</p>
<blockquote>
<p>The <code>app</code> directory must include a root <code>app/layout.js</code>.
The root layout must define <code>&lt;html&gt;</code> and <code>&lt;body&gt;</code> tags.</p>
</blockquote>
<p>Also, any parent layout wraps all nested route layouts. If different parts of your application should be different, you can, using <a href=""https://nextjs.org/docs/app/building-your-application/routing/route-groups"" rel=""noreferrer"">Routes Groups</a>, create <a href=""https://nextjs.org/docs/app/building-your-application/routing/route-groups#creating-multiple-root-layouts"" rel=""noreferrer"">multiple root layouts</a>:</p>
<blockquote>
<p>To create multiple root layouts, remove the top-level <code>layout.js</code> file, and add a <code>layout.js</code> file inside each route groups. This is useful for partitioning an application into sections that have a completely different UI or experience. The <code>&lt;html&gt;</code> and <code>&lt;body&gt;</code> tags need to be added to each root layout.</p>
</blockquote>
<p><a href=""https://i.sstatic.net/kqEMP.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/kqEMP.png"" alt=""enter image description here"" /></a></p>
<blockquote>
<p>In the example above, both <code>(marketing)</code> and <code>(shop)</code> have their own root layout.</p>
</blockquote>
<p>You can, for example, replace <code>marketing</code> with <code>general</code>, and <code>shop</code> with <code>auth</code>. Side note, the naming of route groups has no special significance other than for organization. They do not affect the URL path.</p>
<p>Also, routes inside route groups should not resolve to the same URL path. For example, since route groups don't affect URL structure, <code>(marketing)/about/page.js</code> and <code>(shop)/about/page.js</code> would both resolve to <code>/about</code> and cause an error.</p>
","javascript, reactjs, next.js"
May-23,May-23,"<p>I have this code in my <code>app/page</code> (Server Component):</p>
<pre><code>const getUsers = async () =&gt; {
  const result = await fetch('/api/users', {method: 'GET'});
  if (result.ok) {
    return result.json();
  }
  return [];
}

export default async function IndexPage() {
  const users = await getUsers();
  return (&lt;h1&gt;Users: {users.length}&lt;/h1&gt;);
}
</code></pre>
<p>This gives me the following error:</p>
<pre><code>TypeError: Failed to parse URL from api/users
</code></pre>
<p>How do I refer to the &quot;left side&quot; of the URL from within a Server Side Component? All the Next.js <code>13</code> examples I can find show pointing to some third-party server. The Postgres example project, which uses the old router and client-side fetching, uses the same syntax I used.</p>
",70,"<p>When you call <code>fetch(/api/users)</code> with a relative path on the browser, it works because it is using the origin of the document to have <code>fetch(https://your-domain.com/api/users)</code>.</p>
<p>However, in Node.js, where your server-side fetch is happening, there is no similar behaviour. It expects a fully defined URL. It's not related to Server Components, in fact, you get the same error in functions like <code>getServerSideProps</code> in the <code>pages</code> directory.</p>
<p>You can read more about it if you want on this <a href=""https://github.com/vercel/next.js/issues/48344"" rel=""noreferrer"">GitHub Issue</a>.</p>
<p>I would suggest you use an environment variable to smoothly go to production, where you may have a different URL.</p>
<p>app/page.js:</p>
<pre class=""lang-js prettyprint-override""><code>const getUsers = async () =&gt; {
  const result = await fetch(process.env.URL + '/api/users', {method: 'GET'});
  if (result.ok) {
    return result.json();
  }
  return [];
}

export default async function IndexPage() {
  const users = await getUsers();
  return (&lt;h1&gt;Users: {users.length}&lt;/h1&gt;);
}
</code></pre>
<p>.env:</p>
<pre><code>URL=&quot;http://localhost:3001&quot;
</code></pre>
<p>You just change the URL variable later on in your hosting service admin.</p>
<hr />
<p>That has been said, you may still get another error at build time if you are calling an internal API route from a server component. Because at that time, there might be no application running (the application being build and not deployed yet).</p>
<p>Tim Neutkens from Next.js <a href=""https://github.com/vercel/next.js/issues/44062#issuecomment-1544028776"" rel=""noreferrer"">points that out in this GitHub issue</a>:</p>
<blockquote>
<p>This is because you're trying to fetch from an internal api route during build, which is not supported.</p>
</blockquote>
<p>Instead of calling the internal API route from a server component, which then calls your DB or CMS, reach them directly from the component. It helps avoid the error, and also an additional useless API call.</p>
","javascript, reactjs, fetch-api, next.js"
May-23,May-23,"<p>I want to use langchain for my project.</p>
<p>so I installed it using following command : <code>pip install langchain</code></p>
<p>but While importing &quot;langchain&quot; I am facing following Error:</p>
<pre><code>File /usr/lib/python3.8/typing.py:774, in _GenericAlias.__subclasscheck__(self, cls)
    772 if self._special:
    773     if not isinstance(cls, _GenericAlias):
--&gt; 774         return issubclass(cls, self.__origin__)
    775     if cls._special:
    776         return issubclass(cls.__origin__, self.__origin__)

TypeError: issubclass() arg 1 must be a class
</code></pre>
<p>Any one who can solve this error ?</p>
",22,"<pre><code>typing-inspect==0.8.0
typing_extensions==4.5.0
</code></pre>
","python, nlp, chatbot, data-science, langchain"
May-23,May-23,"<p>Trying to configure JWT configuration. Seems like JWT is deprecated. How can I use <code>OAuth2ResourceServerConfigurer::jwt</code> now?</p>
<p>My code:</p>
<pre class=""lang-java prettyprint-override""><code>@Bean
SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {
    http.authorizeHttpRequests((requests) -&gt; requests.anyRequest().authenticated());
    http.sessionManagement((session) -&gt; session.sessionCreationPolicy(SessionCreationPolicy.STATELESS));
    //http.formLogin(withDefaults());
    http.httpBasic(Customizer.withDefaults());
    http.csrf(csrf -&gt; csrf.disable());
    http.headers(headers -&gt; headers.frameOptions(frameOptionsConfig -&gt; frameOptionsConfig.sameOrigin()));
    http.oauth2ResourceServer(OAuth2ResourceServerConfigurer::jwt);
    return http.build();
}
</code></pre>
<p>Also, in Spring Security 6.0, <code>antMatchers()</code> as well as other configuration methods for securing requests (namely <code>mvcMatchers()</code> and <code>regexMatchers()</code>) have been removed from the API.</p>
",49,"<p>In addition to @schrom answer and more related to the deprecation of <code>OAuth2ResourceServerConfigurer#jwt</code>, Spring Security deprecated the methods that return its own configurer in favor of the ones that return <code>HttpSecurity</code>, and deprecated the <code>.and()</code> method from the <code>HttpSecurity</code>.</p>
<p>For example, <code>httpBasic()</code> is deprecated in favor of <code>httpBasic(Customizer)</code>. Those deprecations were done to have only one way to configure the security DSL, which is using lambdas. Take a look <a href=""https://docs.spring.io/spring-security/reference/migration-7/configuration.html#_use_the_lambda_dsl"" rel=""noreferrer"">at the documentation</a>.</p>
<p>So, for JWT configuration, you'd have to do:</p>
<pre class=""lang-java prettyprint-override""><code>oauth2ResourceServer((oauth2) -&gt; oauth2
    .jwt(Customizer.withDefaults())
)
</code></pre>
","java, spring, spring-security, spring-boot"
Jun-23,Jun-23,"<h1>What I want to achieve</h1>
<p>To scrape an website using AWS Lambda and save the data on S3.</p>
<h1>The issues I'm having</h1>
<p>When I execute Lambda, the following error message appears.</p>
<blockquote>
<p>{   &quot;errorMessage&quot;: &quot;Unable to import module 'lambda_function': cannot
import name 'DEFAULT_CIPHERS' from 'urllib3.util.ssl_'
(/opt/python/urllib3/util/ssl_.py)&quot;,   &quot;errorType&quot;:
&quot;Runtime.ImportModuleError&quot;,   &quot;requestId&quot;:
&quot;fb66bea9-cbad-4bd3-bd4d-6125454e21be&quot;,   &quot;stackTrace&quot;: [] }</p>
</blockquote>
<h1>Code</h1>
<p>The minimum Lambda code is as follows.</p>
<pre><code>import requests
import boto3 

def lambda_handler(event, context):
    s3 = boto3.client('s3')
    upload_res = s3.put_object(Bucket='horserace-dx', Key='/raw/a.html', Body='testtext')
    
    return event
</code></pre>
<p>An layer was added to the Lambda. Files were save in <code>python</code> folder using the commands below , frozen in a zip file, then uploaded to AWS Lambda as a layer.</p>
<pre><code>!pip install requests -t ./python --no-user
!pip install pandas -t ./python --no-user
!pip install beautifulsoup4 -t ./python --no-user
</code></pre>
<ul>
<li>The bucket <code>horserace-dx</code> exists</li>
<li>The folder <code>raw</code> exists</li>
<li>The role of the Lambda is properly set. It can read from and write to S3</li>
<li>The runtime of the Lambda is Python 3.9. The python version of the local computer is 3.9.13.</li>
</ul>
<h1>What I did so far</h1>
<p>I google &quot;cannot import name 'DEFAULT_CIPHERS' from 'urllib3.util.ssl_'&quot; and found some suggestions. I made the layer with the following code and tried again in vain.</p>
<pre><code>!pip install requests -t ./python --no-user
!pip install pandas -t ./python --no-user
!pip install beautifulsoup4 -t ./python --no-user
!pip install urllib3==1.26.15 -t ./python --no-user
</code></pre>
<p>So what should I do to achieve what I want to achieve? Any suggestions would be greatly appreciated.</p>
",4,"<ol>
<li><p>Execute the following commands.</p>
<p>pip install requests==2.25.0 -t ./python --no-user
pip install beautifulsoup4 -t ./python --no-user
pip install pytz -t ./python --no-user</p>
</li>
<li><p>On PyPI, download the following whl files from the pages of numpy and pandas</p>
</li>
</ol>
<ul>
<li>numpy-1.24.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl</li>
<li>pandas-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl</li>
</ul>
<ol start=""3"">
<li><p>Unzip the files and move the contents to the <code>python</code> folder.</p>
</li>
<li><p>Zip the <code>python</code> folder and upload it to AWS Lambda Layer.</p>
</li>
<li><p>Set the layer to the Lambda.</p>
</li>
<li><p>Then the code runs without errors.</p>
</li>
</ol>
","python, amazon-s3, amazon-web-services, boto3, aws-lambda"
Jun-23,Jun-23,"<p>I am new to SQLAlchemy and I see that in the documentation the older version (Column) can be swapped directly with the newer &quot;mapped_column&quot;.</p>
<p>Is there any advantage to using mapped_column over Column? Could you stick to the older 'Column'?</p>
",43,"<p>I think originally <code>Column</code> was used in the lower &quot;core&quot;/<code>sqlalchemy.sql</code> layer <strong>AND</strong> the higher ORM layer.  This created a conflict of purpose.  So <code>mapped_column</code> now supersedes <code>Column</code> when using the ORM layer to add more functionality that can't be used by the core layer.  The core layer will keep using <code>Column</code>.  So I think it is just meant to help you do more faster or more succinctly with the ORM.</p>
<p>There is a blurb about them titled &quot;mapped_column() supersedes the use of Column()&quot; below <a href=""https://docs.sqlalchemy.org/en/20/orm/declarative_tables.html#declarative-table-with-mapped-column"" rel=""noreferrer"">declarative-table-with-mapped-column</a>.</p>
<h2>Here are some basic examples, using postgresql.</h2>
<p>See <code>SQL</code> output at end.</p>
<pre class=""lang-py prettyprint-override""><code>class Base(DeclarativeBase):
    pass

class Controller(Base):
    __tablename__ = &quot;controllers&quot;

    id: Mapped[int] = mapped_column(primary_key=True)
    name: Mapped[str] = mapped_column() # Example 1
    index: Mapped[int] # Example 2
    configured: Mapped[Optional[bool]] # Example 3
    setup_mode: Mapped[bool] # Example 4
    created_at = Column(DateTime(timezone=True)) # Example 5
</code></pre>
<h4>Example 1</h4>
<p>The column type is derived from the type hint, <code>VARCHAR</code> is derived from <code>str</code> in this case.</p>
<pre class=""lang-py prettyprint-override""><code>name: Mapped[str] = mapped_column()
</code></pre>
<h4>Example 2</h4>
<p>When <code>mapped_column</code> would be empty it can be left out entirely and this still works, ie. <code>INTEGER</code> is derived from <code>int</code>.</p>
<pre class=""lang-py prettyprint-override""><code>index: Mapped[int]
</code></pre>
<h3>Example 3</h3>
<p>When <code>Optional</code> from <code>typing</code> is used then a column will allow <code>NULL</code>, ie. <code>nullable=True</code>.</p>
<pre class=""lang-py prettyprint-override""><code>configured: Mapped[Optional[bool]]
</code></pre>
<h3>Example 4</h3>
<p>When <code>Optional</code> is <strong>NOT</strong> used then a column will not allow <code>NULL</code>, ie. <code>nullable=False</code>.</p>
<pre class=""lang-py prettyprint-override""><code>setup_mode: Mapped[bool]
</code></pre>
<h3>Example 5</h3>
<p><code>Column</code> can still be used alongside <code>mapped_column</code> without using type hints at all.</p>
<pre class=""lang-py prettyprint-override""><code>created_at = Column(DateTime(timezone=True))
</code></pre>
<h3>Example of type checking</h3>
<p>Running this code through <code>mypy</code> will produce an error similar to <code>error: &quot;Controller&quot; has no attribute &quot;unknown_attribute&quot;  [attr-defined]</code></p>
<pre class=""lang-py prettyprint-override""><code>
with Session(engine) as session:
    controller = session.scalars(select(Controller).limit(1)).first()
    if controller is not None:
        assert controller.created_at
        assert controller.unknown_attribute
</code></pre>
<h2>Final <code>CREATE TABLE</code> output</h2>
<pre class=""lang-sql prettyprint-override""><code>CREATE TABLE controllers (
    id SERIAL NOT NULL, 
    name VARCHAR NOT NULL, 
    index INTEGER NOT NULL, 
    configured BOOLEAN, 
    setup_mode BOOLEAN NOT NULL, 
    created_at TIMESTAMP WITH TIME ZONE, 
    PRIMARY KEY (id)
)
</code></pre>
<h2>Some &quot;Why&quot;s</h2>
<ul>
<li>allow more orm specific functionality that does not make sense to be in <code>Column()</code></li>
<li>reduce boilerplate code
<ul>
<li><code>int</code>, <code>str</code>, <code>datetime</code>, <code>Optional</code>, etc. are available from python without needing <code>sqlalchemy</code> imports</li>
<li>In cases where the type can be derived from the typehint and no special configuration is necessary the entire column/mapped_column definition can be left out, ie. <code>index: Mapped[int]</code></li>
</ul>
</li>
<li>allow type checkers to better check types
<ul>
<li>the checks can be expanded by using something like the data-class integration but is beyond this question</li>
</ul>
</li>
</ul>
","python, sqlalchemy"
Jun-23,Jun-23,"<p>I am wondering if there can be a version of Ackermann function with better time complexity than the standard variation.</p>
<p>This is not a homework and I am just curious. I know the Ackermann function doesn't have any practical use besides as a performance benchmark, because of the deep recursion. I know the numbers grow very large very quickly, and I am not interested in computing it.</p>
<p>Even though I use Python 3 and the integers won't overflow, I do have finite time, but I have implemented a version of it myself according to the definition found on <a href=""https://en.wikipedia.org/wiki/Ackermann_function"" rel=""noreferrer"">Wikipedia</a>, and computed the output for extremely small values, just to make sure the output is correct.</p>
<p><a href=""https://i.sstatic.net/vsPES.jpg"" rel=""noreferrer""><img src=""https://i.sstatic.net/vsPES.jpg"" alt=""enter image description here"" /></a></p>
<pre><code>def A(m, n):
    if not m:
        return n + 1
    return A(m - 1, A(m, n - 1)) if n else A(m - 1, 1)
</code></pre>
<p>The above code is a direct translation of the image, and is extremely slow, I don't know how it can be optimized, is it impossible to optimize it?</p>
<p>One thing I can think of is to memoize it, but the recursion runs backwards, each time the function is recursively called the arguments were not encountered before, each successive function call the arguments decrease rather than increase, therefore each return value of the function needs to be calculated, memoization doesn't help when you call the function with different arguments the first time.</p>
<p>Memoization can only help if you call it with the same arguments again, it won't compute the results and will retrieve cached result instead, but if you call the function with any input with (m, n) &gt;= (4, 2) it will crash the interpreter regardless.</p>
<p>I also implemented another version according to this <a href=""https://stackoverflow.com/a/20411205/16383578"">answer</a>:</p>
<pre><code>def ack(x, y):
    for i in range(x, 0, -1):
        y = ack(i, y - 1) if y else 1
    return y + 1
</code></pre>
<p>But it is actually slower:</p>
<pre><code>In [2]: %timeit A(3, 4)
1.3 ms ¬± 9.75 ¬µs per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)

In [3]: %timeit ack(3, 4)
2 ms ¬± 59.9 ¬µs per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)
</code></pre>
<p>Theoretically can Ackermann function be optimized? If not, can it be definitely proven that its time complexity cannot decrease?</p>
<hr />
<p>I have just tested <code>A(3, 9)</code> and <code>A(4, 1)</code> will crash the interpreter, and the performance of the two functions for <code>A(3, 8)</code>:</p>
<pre><code>In [2]: %timeit A(3, 8)
432 ms ¬± 4.63 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)

In [3]: %timeit ack(3, 8)
588 ms ¬± 10.4 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)
</code></pre>
<hr />
<p>I did some more experiments:</p>
<pre><code>from collections import Counter
from functools import cache

c = Counter()
def A1(m, n):
    c[(m, n)] += 1
    if not m:
        return n + 1
    return A(m - 1, A(m, n - 1)) if n else A(m - 1, 1)

def test(m, n):
    c.clear()
    A1(m, n)
    return c
</code></pre>
<p>The arguments indeed repeat.</p>
<p>But surprisingly caching doesn't help at all:</p>
<pre><code>In [9]: %timeit Ackermann = cache(A); Ackermann(3, 4)
1.3 ms ¬± 10.1 ¬µs per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)
</code></pre>
<p>Caching only helps when the function is called with the same arguments again, as explained:</p>
<pre><code>In [14]: %timeit Ackermann(3, 2)
101 ns ¬± 0.47 ns per loop (mean ¬± std. dev. of 7 runs, 10,000,000 loops each)
</code></pre>
<p>I have tested it with different arguments numerous times, and it always gives the same efficiency boost (which is none).</p>
",27,"<h2>Solution</h2>
<p>I recently wrote a bunch of solutions based on the same paper that templatetypedef mentioned. Many use generators, one for each m-value, yielding the values for n=0, n=1, n=2, etc. This one might be my favorite:</p>
<pre><code>def A_Stefan_generator_stack3(m, n):
    def a(m):
        if not m:
            yield from count(1)
        x = 1
        for i, ai in enumerate(a(m-1)):
            if i == x:
                x = ai
                yield x
    return next(islice(a(m), n, None))
</code></pre>
<h2>Explanation</h2>
<p>Consider the generator <code>a(m)</code>. It yields A(m,0), A(m,1), A(m,2), etc. The definition of A(m,n) uses A(m-1, A(m, n-1)). So <code>a(m)</code> at its index n yields A(m,n), computed like this:</p>
<ul>
<li>A(m,n-1) gets yielded by the  <code>a(m)</code> generator itself at index n-1. Which is just the previous value (x) yielded by this generator.</li>
<li>A(m-1, A(m, n-1)) = A(m-1, x) gets yielded by the <code>a(m-1)</code> generator at index x. So the <code>a(m)</code> generator iterates over the <code>a(m-1)</code> generator and grabs the value at index i == x.</li>
</ul>
<h2>Benchmark</h2>
<p>Here are times for computing all A(m,n) for m‚â§3 and n‚â§17, also including templatetypedef's solution:</p>
<pre><code> 1325 ms  A_Stefan_row_class
 1228 ms  A_Stefan_row_lists
  544 ms  A_Stefan_generators
 1363 ms  A_Stefan_paper
  459 ms  A_Stefan_generators_2
  866 ms  A_Stefan_m_recursion
  704 ms  A_Stefan_function_stack
  468 ms  A_Stefan_generator_stack
  945 ms  A_Stefan_generator_stack2
  582 ms  A_Stefan_generator_stack3
  467 ms  A_Stefan_generator_stack4
 1652 ms  A_templatetypedef
</code></pre>
<p>Note: Even faster (<em>much</em> faster) solutions using math insights/formulas are possible, see <a href=""https://stackoverflow.com/questions/76559257/theoretically-can-the-ackermann-function-be-optimized/76561503#comment134988343_76561010"">my comment</a> and <a href=""https://stackoverflow.com/a/76562536/1672429"">pts's answer</a>. I intentionally didn't do that, as I was interested in <em>coding</em> techniques, for avoiding deep recursion and avoiding <em>re</em>-calculation. I got the impression that that's also what the question/OP wanted, and they <a href=""https://stackoverflow.com/questions/76559257/theoretically-can-the-ackermann-function-be-optimized/76561503#comment134989599_76561954"">confirmed</a> that now (under a deleted answer, visible if you have enough reputation).</p>
<h2>Code</h2>
<pre><code>def A_Stefan_row_class(m, n):
    class A0:
        def __getitem__(self, n):
            return n + 1
    class A:
        def __init__(self, a):
            self.a = a
            self.n = 0
            self.value = a[1]
        def __getitem__(self, n):
            while self.n &lt; n:
                self.value = self.a[self.value]
                self.n += 1
            return self.value
    a = A0()
    for _ in range(m):
        a = A(a)
    return a[n]


from collections import defaultdict

def A_Stefan_row_lists(m, n):
    memo = defaultdict(list)
    def a(m, n):
        if not m:
            return n + 1
        if m not in memo:
            memo[m] = [a(m-1, 1)]
        Am = memo[m]
        while len(Am) &lt;= n:
            Am.append(a(m-1, Am[-1]))
        return Am[n]
    return a(m, n)


from itertools import count

def A_Stefan_generators(m, n):
    a = count(1)
    def up(a, x=1):
        for i, ai in enumerate(a):
            if i == x:
                x = ai
                yield x
    for _ in range(m):
        a = up(a)
    return next(up(a, n))


def A_Stefan_paper(m, n):
    next = [0] * (m + 1)
    goal = [1] * m + [-1]
    while True:
        value = next[0] + 1
        transferring = True
        i = 0
        while transferring:
            if next[i] == goal[i]:
                goal[i] = value
            else:
                transferring = False
            next[i] += 1
            i += 1
        if next[m] == n + 1:
            return value


def A_Stefan_generators_2(m, n):
    def a0():
        n = yield
        while True:
            n = yield n + 1
    def up(a):
        next(a)
        a = a.send
        i, x = -1, 1
        n = yield
        while True:
            while i &lt; n:
                x = a(x)
                i += 1
            n = yield x
    a = a0()
    for _ in range(m):
        a = up(a)
    next(a)
    return a.send(n)


def A_Stefan_m_recursion(m, n):
    ix = [None] + [(-1, 1)] * m
    def a(m, n):
        if not m:
            return n + 1
        i, x = ix[m]
        while i &lt; n:
            x = a(m-1, x)
            i += 1
        ix[m] = i, x
        return x
    return a(m, n)


def A_Stefan_function_stack(m, n):
    def a(n):
        return n + 1
    for _ in range(m):
        def a(n, a=a, ix=[-1, 1]):
            i, x = ix
            while i &lt; n:
                x = a(x)
                i += 1
            ix[:] = i, x
            return x
    return a(n)


from itertools import count, islice

def A_Stefan_generator_stack(m, n):
    a = count(1)
    for _ in range(m):
        a = (
            x
            for a, x in [(a, 1)]
            for i, ai in enumerate(a)
            if i == x
            for x in [ai]
        )
    return next(islice(a, n, None))


from itertools import count, islice

def A_Stefan_generator_stack2(m, n):
    a = count(1)
    def up(a):
        i, x = 0, 1
        while True:
            i, x = x+1, next(islice(a, x-i, None))
            yield x
    for _ in range(m):
        a = up(a)
    return next(islice(a, n, None))


def A_Stefan_generator_stack3(m, n):
    def a(m):
        if not m:
            yield from count(1)
        x = 1
        for i, ai in enumerate(a(m-1)):
            if i == x:
                x = ai
                yield x
    return next(islice(a(m), n, None))


def A_Stefan_generator_stack4(m, n):
    def a(m):
        if not m:
            return count(1)
        return (
            x
            for x in [1]
            for i, ai in enumerate(a(m-1))
            if i == x
            for x in [ai]
        )
    return next(islice(a(m), n, None))


def A_templatetypedef(i, n):
    positions = [-1] * (i + 1)
    values = [0] + [1] * i
    
    while positions[i] != n:       
        values[0]    += 1
        positions[0] += 1
            
        j = 1
        while j &lt;= i and positions[j - 1] == values[j]:
            values[j] = values[j - 1]
            positions[j] += 1
            j += 1

    return values[i]


funcs = [
    A_Stefan_row_class,
    A_Stefan_row_lists,
    A_Stefan_generators,
    A_Stefan_paper,
    A_Stefan_generators_2,
    A_Stefan_m_recursion,
    A_Stefan_function_stack,
    A_Stefan_generator_stack,
    A_Stefan_generator_stack2,
    A_Stefan_generator_stack3,
    A_Stefan_generator_stack4,
    A_templatetypedef,
]

N = 18
args = (
    [(0, n) for n in range(N)] +
    [(1, n) for n in range(N)] +
    [(2, n) for n in range(N)] +
    [(3, n) for n in range(N)]
)

from time import time

def print(*args, print=print, file=open('out.txt', 'w')):
    print(*args)
    print(*args, file=file, flush=True)
    
expect = none = object()
for _ in range(3):
  for f in funcs:
    t = time()
    result = [f(m, n) for m, n in args]
    # print(f'{(time()-t) * 1e3 :5.1f} ms ', f.__name__)
    print(f'{(time()-t) * 1e3 :5.0f} ms ', f.__name__)
    if expect is none:
        expect = result
    elif result != expect:
        raise Exception(f'{f.__name__} failed')
    del result
  print()
</code></pre>
","python, algorithm, python-3.x, ackermann"
Jun-23,Jun-23,"<p>I'm encountering a problem when building a Docker image using a Python-based Dockerfile. I'm trying to use the mysqlclient library (version 2.2.0) and Django (version 4.2.2). Here is my Dockerfile:</p>
<pre><code>FROM python:3.11-alpine
WORKDIR /usr/src/app
COPY requirements.txt .
RUN apk add --no-cache gcc musl-dev mariadb-connector-c-dev &amp;&amp; \
    pip install --no-cache-dir -r requirements.txt
COPY . .
CMD [&quot;python&quot;, &quot;manage.py&quot;, &quot;runserver&quot;, &quot;0.0.0.0:8000&quot;]
</code></pre>
<p>The problem arises when the Docker build process reaches the point of installing the mysqlclient package. I get the following error: <em>Exception: Can not find valid pkg-config name</em>
To address this issue, I tried adding pkgconfig to the apk add command, Unfortunately, this didn't help and the same error persists.</p>
<p>I would appreciate any guidance on how to resolve this issue.</p>
<p>Thank you in advance.</p>
",1,"<p>I've managed to solve the issue and here's how I did it:
Here is the new Dockerfile:</p>
<pre><code>FROM python:3.11-alpine
WORKDIR /usr/src/app
COPY requirements.txt .
RUN apk add --no-cache --virtual build-deps gcc musl-dev libffi-dev2 pkgconf mariadb-dev &amp;&amp; \
    apk add --no-cache mariadb-connector-c-dev &amp;&amp; \
    pip install --no-cache-dir -r requirements.txt &amp;&amp; \
    apk del build-deps
COPY . .
CMD [&quot;python&quot;, &quot;manage.py&quot;, &quot;runserver&quot;, &quot;0.0.0.0:8000&quot;]
</code></pre>
<p><code>requirements.txt</code>:</p>
<pre><code>mysqlclient==2.2.0
Django~=4.2.0
</code></pre>
<p>I hope this will help someone who visits this post in the future.</p>
","python, docker, mysql-connector-python, alpine-linux"
Jun-23,Jun-23,"<p>I'm using the <code>transformers</code> library in Google colab, and
When i am using TrainingArguments from transformers library i'm getting Import error with this  code:</p>
<pre><code>from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir = &quot;/content/our-model&quot;,
    learning_rate=2e-5,
    per_device_train_batch_size= 64,
    per_device_eval_batch_size = 16,
    num_train_epochs = 2,
    weight_decay = 0.01,
    evaluation_strategy = &quot;epoch&quot;,
    save_strategy = &quot;epoch&quot;,
    load_best_model_at_end = True,
    push_to_hub = False
)
</code></pre>
<p>This is the error i'm getting:</p>
<pre><code>&lt;ipython-input-28-0518ea5ff407&gt; in &lt;cell line: 2&gt;()
      1 from transformers import TrainingArguments
----&gt; 2 training_args = TrainingArguments(
      3     output_dir = &quot;/content/our-model&quot;,
      4     learning_rate=2e-5,
      5     per_device_train_batch_size= 64,

4 frames
/usr/local/lib/python3.10/dist-packages/transformers/training_args.py in _setup_devices(self)
   1670         if not is_sagemaker_mp_enabled():
   1671             if not is_accelerate_available(min_version=&quot;0.20.1&quot;):
-&gt; 1672                 raise ImportError(
   1673                     &quot;Using the `Trainer` with `PyTorch` requires `accelerate&gt;=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`&quot;
   1674                 )

ImportError: Using the `Trainer` with `PyTorch` requires `accelerate&gt;=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U 
</code></pre>
<p>I already tried pip install for 0.20.1 version of accelerate and pip install transformers[torch]
and both didn't worked.</p>
",35,"<p>If you're not particular about which transformers and accelerate version to tie to, then do this to use the most up-to-date version in Google Colab:</p>
<pre><code>! pip install -U accelerate
! pip install -U transformers
</code></pre>
<p>Then the issue you are having with accelerate should auto-resolve itself.</p>
<p>Note:</p>
<ul>
<li><p>Underspecifying <code>pip install -U transformers</code> instead of <code>pip install transformers[pytorch]</code> might be easier since that's what most of the users do and the developers of the library will make sure that the basic pip works with the common functions and class like <code>TrainingArguments</code></p>
</li>
<li><p>Instead of specifying accelerate to the <code>pip install accelerate&gt;=0.20.1</code>, if you have no particular need to fixed the version, automatically upgrading to the latest version might get you more stability when using the library, esp. with &quot;hot&quot;/&quot;trending&quot; libraries that are constantly changing (almost) daily.</p>
</li>
</ul>
<hr />
<p>If further debugging is necessary, i.e. if the above didn't work. To check your transformers and accelerate version, do this:</p>
<pre><code>import accelerate

accelerate.__version__
</code></pre>
<p>Most probably you might have an <code>ImportError</code> at the first line if accelerate is not already installed when you installed <code>transformers</code>.</p>
<p>And then if the first line works and the 2nd line is not outputting a version <code>&gt;=0.20.1</code>, then that is the cause of your issue.</p>
<p>The current versions to-date (July 2023) are:</p>
<pre><code>import accelerate
import transformers

transformers.__version__, accelerate.__version__
</code></pre>
<p>[out]:</p>
<pre><code>('4.30.1', '0.21.0')
</code></pre>
<p>Here's an example notebook with the model that you wish to use as per the comments in your question, <a href=""https://colab.research.google.com/drive/1D79AjHMeE6HAZC-g2S83baTgsHtDUu5i?usp=sharing"" rel=""noreferrer"">https://colab.research.google.com/drive/1D79AjHMeE6HAZC-g2S83baTgsHtDUu5i?usp=sharing</a></p>
<hr />
<p>If the error persist after the <code>pip install ...</code>, try restarting the runtime.</p>
<p>If you can't find the buttons to press to restart, try this in the cell <a href=""https://stackoverflow.com/questions/55005114/restart-kernel-in-google-colab"">Restart kernel in Google Colab</a> then re-run the cells for <code>import ...</code></p>
<pre><code>import os
os._exit(00)
</code></pre>
","python, nlp, importerror, huggingface-transformers, huggingface"
Jul-23,Jul-23,"<p>I have a springBoot all with these dependencies:</p>
<pre><code>&lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-validation&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;version&gt;1.18.28&lt;/version&gt;
            &lt;scope&gt;provided&lt;/scope&gt;
        &lt;/dependency&gt;

        &lt;!-- https://mvnrepository.com/artifact/com.mashape.unirest/unirest-java --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.mashape.unirest&lt;/groupId&gt;
            &lt;artifactId&gt;unirest-java&lt;/artifactId&gt;
            &lt;version&gt;1.4.9&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;com.mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-j&lt;/artifactId&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt;
            &lt;artifactId&gt;jjwt-api&lt;/artifactId&gt;
            &lt;version&gt;0.11.5&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt;
            &lt;artifactId&gt;jjwt-impl&lt;/artifactId&gt;
            &lt;version&gt;0.11.5&lt;/version&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt;
            &lt;artifactId&gt;jjwt-jackson&lt;/artifactId&gt;
            &lt;version&gt;0.11.5&lt;/version&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;


        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.security&lt;/groupId&gt;
            &lt;artifactId&gt;spring-security-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
</code></pre>
<p>but I have this message on the console:</p>
<pre><code>Standard Commons Logging discovery in action with spring-jcl: please remove commons-logging.jar from classpath in order to avoid potential conflicts
</code></pre>
<p>Here the mvn dependency:tree :</p>
<pre><code>[INFO] Scanning for projects...
[INFO] 
[INFO] ----------------&lt; com.planets:com.planets &gt;-----------------
[INFO] Building planets 0.0.1-SNAPSHOT
[INFO]   from pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- dependency:3.5.0:tree (default-cli) @ com.planets ---
[INFO] com.planets:com.planets:jar:0.0.1-SNAPSHOT
[INFO] +- org.springframework.boot:spring-boot-starter-data-jpa:jar:3.1.1:compile
[INFO] |  +- org.springframework.boot:spring-boot-starter-aop:jar:3.1.1:compile
[INFO] |  |  \- org.aspectj:aspectjweaver:jar:1.9.19:compile
[INFO] |  +- org.springframework.boot:spring-boot-starter-jdbc:jar:3.1.1:compile
[INFO] |  |  +- com.zaxxer:HikariCP:jar:5.0.1:compile
[INFO] |  |  \- org.springframework:spring-jdbc:jar:6.0.10:compile
[INFO] |  +- org.hibernate.orm:hibernate-core:jar:6.2.5.Final:compile
[INFO] |  |  +- jakarta.persistence:jakarta.persistence-api:jar:3.1.0:compile
[INFO] |  |  +- jakarta.transaction:jakarta.transaction-api:jar:2.0.1:compile
[INFO] |  |  +- org.jboss.logging:jboss-logging:jar:3.5.1.Final:compile
[INFO] |  |  +- org.hibernate.common:hibernate-commons-annotations:jar:6.0.6.Final:runtime
[INFO] |  |  +- io.smallrye:jandex:jar:3.0.5:runtime
[INFO] |  |  +- com.fasterxml:classmate:jar:1.5.1:compile
[INFO] |  |  +- net.bytebuddy:byte-buddy:jar:1.14.5:runtime
[INFO] |  |  +- org.glassfish.jaxb:jaxb-runtime:jar:4.0.3:runtime
[INFO] |  |  |  \- org.glassfish.jaxb:jaxb-core:jar:4.0.3:runtime
[INFO] |  |  |     +- org.eclipse.angus:angus-activation:jar:2.0.1:runtime
[INFO] |  |  |     +- org.glassfish.jaxb:txw2:jar:4.0.3:runtime
[INFO] |  |  |     \- com.sun.istack:istack-commons-runtime:jar:4.1.2:runtime
[INFO] |  |  +- jakarta.inject:jakarta.inject-api:jar:2.0.1:runtime
[INFO] |  |  \- org.antlr:antlr4-runtime:jar:4.10.1:compile
[INFO] |  +- org.springframework.data:spring-data-jpa:jar:3.1.1:compile
[INFO] |  |  +- org.springframework.data:spring-data-commons:jar:3.1.1:compile
[INFO] |  |  +- org.springframework:spring-orm:jar:6.0.10:compile
[INFO] |  |  +- org.springframework:spring-context:jar:6.0.10:compile
[INFO] |  |  +- org.springframework:spring-tx:jar:6.0.10:compile
[INFO] |  |  +- org.springframework:spring-beans:jar:6.0.10:compile
[INFO] |  |  +- jakarta.annotation:jakarta.annotation-api:jar:2.1.1:compile
[INFO] |  |  \- org.slf4j:slf4j-api:jar:2.0.7:compile
[INFO] |  \- org.springframework:spring-aspects:jar:6.0.10:compile
[INFO] +- org.springframework.boot:spring-boot-starter-security:jar:3.1.1:compile
[INFO] |  +- org.springframework.boot:spring-boot-starter:jar:3.1.1:compile
[INFO] |  |  +- org.springframework.boot:spring-boot:jar:3.1.1:compile
[INFO] |  |  +- org.springframework.boot:spring-boot-autoconfigure:jar:3.1.1:compile
[INFO] |  |  +- org.springframework.boot:spring-boot-starter-logging:jar:3.1.1:compile
[INFO] |  |  |  +- ch.qos.logback:logback-classic:jar:1.4.8:compile
[INFO] |  |  |  |  \- ch.qos.logback:logback-core:jar:1.4.8:compile
[INFO] |  |  |  +- org.apache.logging.log4j:log4j-to-slf4j:jar:2.20.0:compile
[INFO] |  |  |  |  \- org.apache.logging.log4j:log4j-api:jar:2.20.0:compile
[INFO] |  |  |  \- org.slf4j:jul-to-slf4j:jar:2.0.7:compile
[INFO] |  |  \- org.yaml:snakeyaml:jar:1.33:compile
[INFO] |  +- org.springframework:spring-aop:jar:6.0.10:compile
[INFO] |  +- org.springframework.security:spring-security-config:jar:6.1.1:compile
[INFO] |  \- org.springframework.security:spring-security-web:jar:6.1.1:compile
[INFO] |     \- org.springframework:spring-expression:jar:6.0.10:compile
[INFO] +- org.springframework.boot:spring-boot-starter-validation:jar:3.1.1:compile
[INFO] |  +- org.apache.tomcat.embed:tomcat-embed-el:jar:10.1.10:compile
[INFO] |  \- org.hibernate.validator:hibernate-validator:jar:8.0.0.Final:compile
[INFO] |     \- jakarta.validation:jakarta.validation-api:jar:3.0.2:compile
[INFO] +- org.springframework.boot:spring-boot-starter-web:jar:3.1.1:compile
[INFO] |  +- org.springframework.boot:spring-boot-starter-json:jar:3.1.1:compile
[INFO] |  |  +- com.fasterxml.jackson.datatype:jackson-datatype-jdk8:jar:2.15.2:compile
[INFO] |  |  +- com.fasterxml.jackson.datatype:jackson-datatype-jsr310:jar:2.15.2:compile
[INFO] |  |  \- com.fasterxml.jackson.module:jackson-module-parameter-names:jar:2.15.2:compile
[INFO] |  +- org.springframework.boot:spring-boot-starter-tomcat:jar:3.1.1:compile
[INFO] |  |  +- org.apache.tomcat.embed:tomcat-embed-core:jar:10.1.10:compile
[INFO] |  |  \- org.apache.tomcat.embed:tomcat-embed-websocket:jar:10.1.10:compile
[INFO] |  +- org.springframework:spring-web:jar:6.0.10:compile
[INFO] |  |  \- io.micrometer:micrometer-observation:jar:1.11.1:compile
[INFO] |  |     \- io.micrometer:micrometer-commons:jar:1.11.1:compile
[INFO] |  \- org.springframework:spring-webmvc:jar:6.0.10:compile
[INFO] +- com.fasterxml.jackson.core:jackson-annotations:jar:2.15.2:compile
[INFO] +- org.projectlombok:lombok:jar:1.18.28:provided
[INFO] +- com.mashape.unirest:unirest-java:jar:1.4.9:compile
[INFO] |  +- org.apache.httpcomponents:httpclient:jar:4.5.2:compile
[INFO] |  |  +- org.apache.httpcomponents:httpcore:jar:4.4.16:compile
[INFO] |  |  +- commons-logging:commons-logging:jar:1.2:compile
[INFO] |  |  \- commons-codec:commons-codec:jar:1.15:compile
[INFO] |  +- org.apache.httpcomponents:httpasyncclient:jar:4.1.5:compile
[INFO] |  |  \- org.apache.httpcomponents:httpcore-nio:jar:4.4.16:compile
[INFO] |  +- org.apache.httpcomponents:httpmime:jar:4.5.2:compile
[INFO] |  \- org.json:json:jar:20160212:compile
[INFO] +- com.itextpdf:itextpdf:jar:5.5.13.3:compile
[INFO] +- com.mysql:mysql-connector-j:jar:8.0.33:runtime
[INFO] +- io.jsonwebtoken:jjwt-api:jar:0.11.5:compile
[INFO] +- io.jsonwebtoken:jjwt-impl:jar:0.11.5:runtime
[INFO] +- io.jsonwebtoken:jjwt-jackson:jar:0.11.5:runtime
[INFO] |  \- com.fasterxml.jackson.core:jackson-databind:jar:2.15.2:compile
[INFO] |     \- com.fasterxml.jackson.core:jackson-core:jar:2.15.2:compile
[INFO] +- org.springframework.boot:spring-boot-starter-test:jar:3.1.1:test
[INFO] |  +- org.springframework.boot:spring-boot-test:jar:3.1.1:test
[INFO] |  +- org.springframework.boot:spring-boot-test-autoconfigure:jar:3.1.1:test
[INFO] |  +- com.jayway.jsonpath:json-path:jar:2.8.0:test
[INFO] |  +- jakarta.xml.bind:jakarta.xml.bind-api:jar:4.0.0:runtime
[INFO] |  |  \- jakarta.activation:jakarta.activation-api:jar:2.1.2:runtime
[INFO] |  +- net.minidev:json-smart:jar:2.4.11:test
[INFO] |  |  \- net.minidev:accessors-smart:jar:2.4.11:test
[INFO] |  |     \- org.ow2.asm:asm:jar:9.3:test
[INFO] |  +- org.assertj:assertj-core:jar:3.24.2:test
[INFO] |  +- org.hamcrest:hamcrest:jar:2.2:test
[INFO] |  +- org.junit.jupiter:junit-jupiter:jar:5.9.3:test
[INFO] |  |  +- org.junit.jupiter:junit-jupiter-api:jar:5.9.3:test
[INFO] |  |  |  +- org.opentest4j:opentest4j:jar:1.2.0:test
[INFO] |  |  |  +- org.junit.platform:junit-platform-commons:jar:1.9.3:test
[INFO] |  |  |  \- org.apiguardian:apiguardian-api:jar:1.1.2:test
[INFO] |  |  +- org.junit.jupiter:junit-jupiter-params:jar:5.9.3:test
[INFO] |  |  \- org.junit.jupiter:junit-jupiter-engine:jar:5.9.3:test
[INFO] |  |     \- org.junit.platform:junit-platform-engine:jar:1.9.3:test
[INFO] |  +- org.mockito:mockito-core:jar:5.3.1:test
[INFO] |  |  +- net.bytebuddy:byte-buddy-agent:jar:1.14.5:test
[INFO] |  |  \- org.objenesis:objenesis:jar:3.3:test
[INFO] |  +- org.mockito:mockito-junit-jupiter:jar:5.3.1:test
[INFO] |  +- org.skyscreamer:jsonassert:jar:1.5.1:test
[INFO] |  |  \- com.vaadin.external.google:android-json:jar:0.0.20131108.vaadin1:test
[INFO] |  +- org.springframework:spring-core:jar:6.0.10:compile
[INFO] |  |  \- org.springframework:spring-jcl:jar:6.0.10:compile
[INFO] |  +- org.springframework:spring-test:jar:6.0.10:test
[INFO] |  \- org.xmlunit:xmlunit-core:jar:2.9.1:test
[INFO] \- org.springframework.security:spring-security-test:jar:6.1.1:test
[INFO]    \- org.springframework.security:spring-security-core:jar:6.1.1:compile
[INFO]       \- org.springframework.security:spring-security-crypto:jar:6.1.1:compile
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
</code></pre>
",22,"<p>In your case <code>unirest-java</code> has a transitive dependency on <code>org.apache.httpcomponents</code>, which further has a transitive dependency on <code>commons-logging</code>. Spring JCL probably scans the classpath, finds <code>commons-logging</code> and that's why it warns you about potential conflicts with Spring Boot's pre-configured loggers.</p>
<p>You can list all the dependencies and transitive dependencies in your Maven project by running <code>mvn dependency:tree</code>. For Gradle projects you can run <code>gradle dependencies</code>.</p>
<p>To exclude <code>commons-logging</code> in a Maven project, add this to your <code>pom.xml</code> configuration file:</p>
<pre><code>&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.mashape.unirest&lt;/groupId&gt;
        &lt;artifactId&gt;unirest-java&lt;/artifactId&gt;
        &lt;version&gt;1.4.9&lt;/version&gt;
        &lt;exclusions&gt;
            &lt;exclusion&gt;
                &lt;groupId&gt;commons-logging&lt;/groupId&gt;
                &lt;artifactId&gt;commons-logging&lt;/artifactId&gt;
            &lt;/exclusion&gt;
        &lt;/exclusions&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
<p>If you're using Gradle, add this to your <code>build.gradle</code> file:</p>
<pre><code>implementation('com.mashape.unirest:unirest-java:1.4.9') {
        exclude group: 'commons-logging', module: 'commons-logging'
    }
</code></pre>
<p>You may also exclude dependencies globally from your project:</p>
<pre><code>configurations {
    compileOnly {
        extendsFrom annotationProcessor
    }
    all {
        exclude group: 'commons-logging', module: 'commons-logging'
    }
}
</code></pre>
","java, logging, spring-boot"
Jul-23,Jul-23,"<p>I have Chrome 115.0.5790.99 installed on Windows, and I use Selenium 4.10.0. In my Python code, I call <strong>service = Service(ChromeDriverManager().install())</strong> and it returns the error:</p>
<blockquote>
<p>ValueError: There is no such driver by url [sic] <a href=""https://chromedriver.storage.googleapis.com/LATEST_RELEASE_115.0.5790"" rel=""nofollow noreferrer"">https://chromedriver.storage.googleapis.com/LATEST_RELEASE_115.0.5790</a>.</p>
</blockquote>
<p>I use ChromeDriverManager().install() in order to ensure the use of last stable version of webdriver. How to solve the issue?</p>
<p><strong>My simple code:</strong></p>
<pre><code>from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
import time

# Install Webdriver
service = Service(ChromeDriverManager().install())

# Create Driver Instance
driver = webdriver.Chrome(service=service)

# Get Web Page
driver.get('https://www.crawler-test.com')
time.sleep(5)
driver.quit()
</code></pre>
<p><strong>Error output:</strong></p>
<pre class=""lang-none prettyprint-override""><code>Traceback (most recent call last):
  File &quot;C:\Users\Administrator\Documents\...\test.py&quot;, line 7, in &lt;module&gt;
    service = Service(ChromeDriverManager().install())
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &quot;C:\Users\Administrator\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\chrome.py&quot;, line 39, in install
    driver_path = self._get_driver_path(self.driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &quot;C:\Users\Administrator\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\manager.py&quot;, line 30, in _get_driver_path
    file = self._download_manager.download_file(driver.get_driver_download_url())
                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &quot;C:\Users\Administrator\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\drivers\chrome.py&quot;, line 40, in get_driver_download_url
    driver_version_to_download = self.get_driver_version_to_download()
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &quot;C:\Users\Administrator\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\driver.py&quot;, line 51, in get_driver_version_to_download
    self._driver_to_download_version = self._version if self._version not in (None, &quot;latest&quot;) else self.get_latest_release_version()
                                                                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &quot;C:\Users\Administrator\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\drivers\chrome.py&quot;, line 62, in get_latest_release_version
    resp = self._http_client.get(url=latest_release_url)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &quot;C:\Users\Administrator\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\http.py&quot;, line 37, in get
    self.validate_response(resp)
  File &quot;C:\Users\Administrator\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\http.py&quot;, line 16, in validate_response
    raise ValueError(f&quot;There is no such driver by url {resp.url}&quot;)
ValueError: There is no such driver by url https://chromedriver.storage.googleapis.com/LATEST_RELEASE_115.0.5790
</code></pre>
<p>I tried the following but no success:</p>
<ul>
<li>to disable Chrome auto-update, but Chrome manages to update itself anyway (<a href=""https://www.minitool.com/news/disable-automatic-chrome-updates.html"" rel=""nofollow noreferrer"">https://www.minitool.com/news/disable-automatic-chrome-updates.html</a> and <a href=""https://www.webnots.com/7-ways-to-disable-automatic-chrome-update-in-windows-and-mac"" rel=""nofollow noreferrer"">https://www.webnots.com/7-ways-to-disable-automatic-chrome-update-in-windows-and-mac</a>);</li>
<li>to install Chrome 114 and webdriver for version 114, than it works till Chrome get updated automatically;</li>
<li>to follow instructions <a href=""https://chromedriver.chromium.org/downloads/version-selection"" rel=""nofollow noreferrer"">https://chromedriver.chromium.org/downloads/version-selection</a> but when generating URL and running link <a href=""https://chromedriver.storage.googleapis.com/LATEST_RELEASE_115.0.5790"" rel=""nofollow noreferrer"">https://chromedriver.storage.googleapis.com/LATEST_RELEASE_115.0.5790</a> I get error <strong>No such object: chromedriver/LATEST_RELEASE_115.0.5790</strong></li>
</ul>
<p>How can I solve the issue till webdriver for Chrome 115 will be finally released at <a href=""https://chromedriver.chromium.org/downloads"" rel=""nofollow noreferrer"">the download location</a>?</p>
",3,"<p>Until the stable webdriver version 115 is released, the solution is to use the test webdriver and test Chrome accordingly. The steps are:</p>
<ul>
<li><p>uninstall the current installed webdriver and Chrome from the system;</p>
</li>
<li><p>find the stable version of webdriver and Chrome at <em><a href=""https://googlechromelabs.github.io/chrome-for-testing/"" rel=""nofollow noreferrer"">Chrome for Testing availability</a></em></p>
</li>
<li><p>search for the binary Chrome and chromedriver (the version of the webdriver and Chrome should be the same!);</p>
</li>
<li><p>install Chrome (actually you just unzip it and put it in some folder,
i.e.: C:\chrome-test-ver);</p>
</li>
<li><p>set folder C:\chrome-test-ver to the PATH environment variable);</p>
</li>
<li><p>install <em>webdriver.exe</em> (just unzip it and copy it to the Python folder,
i.e.: <em>C:\Users\Administrator\AppData\Local\Programs\Python\Python311</em>);</p>
</li>
<li><p>run your Python script with Selenium, and it should work.</p>
</li>
</ul>
","python, google-chrome, selenium-webdriver"
Jul-23,Jul-23,"<p>I recently updated my Google Chrome browser to version <em>115.0.5790.99</em> and I'm using Python webdrivermanager library (version 3.8.6) for Chrome driver management.</p>
<p>However, since this update, when I call the <code>ChromeDriverManager().install()</code> function, I encounter the following error:</p>
<blockquote>
<p>There is no such driver by URL <a href=""https://chromedriver.storage.googleapis.com/LATEST_RELEASE_115.0.5790"" rel=""noreferrer"">https://chromedriver.storage.googleapis.com/LATEST_RELEASE_115.0.5790</a></p>
</blockquote>
<p>Steps to reproduce the issue:</p>
<ul>
<li>Update Google Chrome to version 115.0.5790.99.</li>
</ul>
<p>Execute the following Python code:</p>
<pre><code>from webdriver_manager.chrome import ChromeDriverManager

driver_path = ChromeDriverManager().install()
</code></pre>
<p>capture:</p>
<p><img src=""https://i.sstatic.net/TzVsD.png"" alt=""exception catched"" /></p>
",4,"<h2><a href=""https://stackoverflow.com/a/76563271/7429447""><strong>Selenium Manager</strong></a></h2>
<p>With the availability of <a href=""https://stackoverflow.com/a/54482491/7429447"">Selenium</a> <em><strong>v4.6</strong></em> and above you don't need to explicitly download <a href=""https://stackoverflow.com/a/59927747/7429447"">ChromeDriver</a>, <a href=""https://stackoverflow.com/a/45331403/7429447"">GeckoDriver</a> or any browser drivers as such using <a href=""https://stackoverflow.com/q/63421086/7429447""><em>webdriver_manager</em></a>. You just need to ensure that the desired browser client i.e. <a href=""/questions/tagged/google-chrome"" class=""post-tag"" title=""show questions tagged &#39;google-chrome&#39;"" aria-label=""show questions tagged &#39;google-chrome&#39;"" rel=""tag"" aria-labelledby=""tag-google-chrome-tooltip-container"">google-chrome</a>, <a href=""/questions/tagged/firefox"" class=""post-tag"" title=""show questions tagged &#39;firefox&#39;"" aria-label=""show questions tagged &#39;firefox&#39;"" rel=""tag"" aria-labelledby=""tag-firefox-tooltip-container"">firefox</a> or <a href=""/questions/tagged/microsoft-edge"" class=""post-tag"" title=""show questions tagged &#39;microsoft-edge&#39;"" aria-label=""show questions tagged &#39;microsoft-edge&#39;"" rel=""tag"" aria-labelledby=""tag-microsoft-edge-tooltip-container"">microsoft-edge</a> is installed.</p>
<p><a href=""https://www.selenium.dev/blog/2022/introducing-selenium-manager/"" rel=""nofollow noreferrer""><strong>Selenium Manager</strong></a> is the new tool integrated with <a href=""/questions/tagged/selenium4"" class=""post-tag"" title=""show questions tagged &#39;selenium4&#39;"" aria-label=""show questions tagged &#39;selenium4&#39;"" rel=""tag"" aria-labelledby=""tag-selenium4-tooltip-container"">selenium4</a> that would help to get a working environment to run Selenium out of the box. Beta 1 of <a href=""https://stackoverflow.com/a/76555236/7429447""><em><strong>Selenium Manager</strong></em></a> will configure the browser drivers for Chrome, Firefox, and Edge if they are not present on the <em><code>PATH</code></em>.</p>
<hr />
<h2>Solution</h2>
<p>As a solution you can simply do:</p>
<pre><code>from selenium import webdriver
from selenium.webdriver.chrome.options import Options

options = Options()
options.add_argument(&quot;start-maximized&quot;)
driver = webdriver.Chrome(options=options)
driver.get(&quot;https://www.google.com/&quot;)
</code></pre>
","python, google-chrome, python-3.x, selenium-chromedriver, selenium-webdriver"
Jul-23,Jul-23,"<p>Python <a href=""https://docs.python.org/library/functions.html#zip"" rel=""noreferrer""><code>zip</code></a> function is
its own inverse (in a way), thus we can do this:</p>
<pre><code>points = [(1,2), (3,4), (5,6), (7,8)]
xs, ys = zip(*points)
</code></pre>
<p>and now <code>xs=[1,3,5,7]</code> and <code>ys=[2,4,6,8]</code>.</p>
<p>I wonder if something similar can be done with <a href=""https://docs.python.org/library/dataclasses.html"" rel=""noreferrer"">data class</a> instances instead of tuples:</p>
<pre><code>from dataclasses import dataclass

@dataclass
class XY:
    &quot;2d point&quot;
    x: float | int
    y: float | int

points = [XY(1,2), XY(3,4), XY(5,6), XY(7,8)]
xs, ys = zip(*[(p.x,p.y) for p in points])
</code></pre>
<p>but <em>without</em> an <em>explicit</em> list comprehension.</p>
<p>Of course, the result would not be a tuple <code>(xs,ys)</code> but a dict with keys <code>x</code>
and <code>y</code> because, without an explicit list comprehension, we would be collecting
<em>all</em> fields.</p>
",19,"<p>With <a href=""https://docs.python.org/library/dataclasses.html#dataclasses.astuple"" rel=""noreferrer""><code>astuple</code></a>:</p>
<pre><code>from dataclasses import dataclass, astuple

@dataclass
class XY:
    &quot;2d point&quot;
    x: float | int
    y: float | int
    def __iter__(self):
        return iter(astuple(self))

points = [XY(1,2), XY(3,4), XY(5,6), XY(7,8)]
xs, ys = zip(*points)
</code></pre>
<p>Or instead map it:</p>
<pre><code>xs, ys = zip(*map(astuple, points))
</code></pre>
",python
Jul-23,Jul-23,"<ul>
<li>I am trying to have images in my Tkinter GUI, hence I am using <a href=""https://en.wikipedia.org/wiki/Python_Imaging_Library"" rel=""noreferrer"">PIL</a>.</li>
<li><em>Image.ANTIALAIS</em> is not working. However, <em>Image.BILINEAR</em> works</li>
</ul>
<p>Here's some sample code:</p>
<pre class=""lang-py prettyprint-override""><code>import tkinter as tk
from PIL import Image, ImageTk

window = tk.Tk()

image = Image.open(r&quot;VC.png&quot;)
image = image.resize((20, 20), Image.ANTIALIAS)

tk_image = ImageTk.PhotoImage(image)

image_label = tk.Label(window, image=tk_image)
image_label.pack()

window.mainloop()
</code></pre>
<p>Here's the error:</p>
<pre class=""lang-none prettyprint-override""><code>Traceback (most recent call last):
  File &quot;&lt;module1&gt;&quot;, line 19, in &lt;module&gt;
AttributeError: module 'PIL.Image' has no attribute 'ANTIALIAS'
</code></pre>
<ul>
<li>I tried reinstalling pip <em>and</em> <a href=""https://en.wikipedia.org/wiki/Python_Imaging_Library"" rel=""noreferrer"">Pillow</a>. It didn't work.</li>
<li>I asked <a href=""https://en.wikipedia.org/wiki/ChatGPT"" rel=""noreferrer"">ChatGPT</a> about this, and it advised me to upgrade to Pillow's latest version. I am on the latest version (10.0.0).</li>
</ul>
",20,"<p>The problem is with <a href=""https://en.wikipedia.org/wiki/Python_Imaging_Library"" rel=""noreferrer"">Pillow</a> 10.0.</p>
<p>Trying to uninstall Pillow might give some errors.</p>
<p>Just put this in cmd:</p>
<p><code>pip install Pillow==9.5.0</code></p>
","python, python-imaging-library"
Aug-23,Aug-23,"<p>I am currently struggling with Spring Security in my Spring Boot 3 applications. It was working in Spring Boot 2 but not since I tried to upgrade to version 3.</p>
<p>My authentication seems to work properly and the stuff that needs to be authenticated works. However when I do a preflight (OPTIONS) check it still returns me a 401 error.</p>
<p>My WebSecurityConfig:</p>
<pre><code>@Configuration
@EnableWebSecurity
@EnableMethodSecurity(prePostEnabled = true)
public class WebSecurityConfig {

@Bean
    public SecurityFilterChain configure(HttpSecurity httpSecurity) throws Exception {
        httpSecurity
                .cors(Customizer.withDefaults())
                .csrf(c -&gt; c.disable())
                .authorizeHttpRequests(requests -&gt; requests
                        .requestMatchers(
                            AntPathRequestMatcher.antMatcher(&quot;/comments/**&quot;), 
                            AntPathRequestMatcher.antMatcher(&quot;/requests/admin/**&quot;)
                        ).authenticated()
                        .anyRequest().permitAll())
                .authenticationProvider(authenticationProvider())
                .exceptionHandling(r -&gt; r.authenticationEntryPoint(jwtAuthenticationEntryPoint))
                .sessionManagement(r -&gt; r.sessionCreationPolicy(SessionCreationPolicy.STATELESS))
                // Add a filter to validate the tokens with every request
                .addFilterBefore(jwtRequestFilter, UsernamePasswordAuthenticationFilter.class)
                ;
        return httpSecurity.build();
    }
}
</code></pre>
<p>I tried using a CorsConfigurationSource bean, but with no luck</p>
<pre><code>@Bean
public CorsConfigurationSource corsConfigurationSource() {
    CorsConfiguration corsConfig = new CorsConfiguration();
    corsConfig.applyPermitDefaultValues();
    corsConfig.setAllowCredentials(true);
    corsConfig.addAllowedMethod(&quot;GET&quot;);
    corsConfig.addAllowedMethod(&quot;PATCH&quot;);
    corsConfig.addAllowedMethod(&quot;POST&quot;);
    corsConfig.addAllowedMethod(&quot;OPTIONS&quot;);
    corsConfig.setAllowedOrigins(Arrays.asList(&quot;*&quot;));
    corsConfig.setAllowedHeaders(Arrays.asList(&quot;*&quot;));

    UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();
    source.registerCorsConfiguration(&quot;/**&quot;, corsConfig);
    return source;
}
</code></pre>
<p>And changed the <code>.cors(Customizer.withDefaults())</code> to <code>.cors(c -&gt; c.configurationSource(corsConfigurationSource())))</code> in the SecutiryFilterChain.</p>
<p>A lot of links on the internet provide help on the issue but for SB2 instead of 3.</p>
",21,"<p>i tried configuring CORS the same way you did, using <code>http.cors(Customizer.withDefaults())</code> and <code>http.cors(c -&gt; c.configurationSource(corsConfigurationSource())</code> but both did not work.</p>
<p>however, this works for me</p>
<pre><code>http.cors(cors -&gt; cors.configurationSource(request -&gt; {
        CorsConfiguration configuration = new CorsConfiguration();
        configuration.setAllowedOrigins(Arrays.asList(&quot;*&quot;));
        configuration.setAllowedMethods(Arrays.asList(&quot;*&quot;));
        configuration.setAllowedHeaders(Arrays.asList(&quot;*&quot;));
        return configuration;
    }));
</code></pre>
","java, spring-security, spring-boot, spring-boot-3"
Aug-23,Aug-23,"<p>I cannot import the <code>getReactNativePersistence</code> module from the <code>firebase/auth</code>. I'm using Typescript.</p>
<p>Importing the function as below was possible, but it didn't work when I updated the Firebase SDK from <code>9.22.0</code> to <code>10.1.0</code>.</p>
<pre class=""lang-js prettyprint-override""><code>import { getReactNativePersistence } from &quot;firebase/auth/react-native&quot;;
</code></pre>
<p>It seems like <strong>there is no <code>firebase/auth/react-native</code> anymore.</strong></p>
<p>I also tried the following code, as <a href=""https://firebase.google.com/docs/reference/js/auth"" rel=""noreferrer"">the document</a> indicates,</p>
<pre class=""lang-js prettyprint-override""><code>import { getReactNativePersistence } from &quot;firebase/auth&quot;;
</code></pre>
<p>But it throws an error.</p>
<pre class=""lang-bash prettyprint-override""><code>Module '&quot;firebase/auth&quot;' has no exported member 'getReactNativePersistence'.
</code></pre>
<p>I'm using Expo, which uses Metro as default.</p>
<p>This is my <code>metro.config.js</code></p>
<pre class=""lang-js prettyprint-override""><code>// Learn more https://docs.expo.io/guides/customizing-metro
const { getDefaultConfig } = require('expo/metro-config');

module.exports = getDefaultConfig(__dirname);
</code></pre>
<p>How can I import <code>getReactNativePersistence</code> in <code>firebase@10.1.0</code>?</p>
",70,"<pre><code>{
  &quot;compilerOptions&quot;: {
    &quot;paths&quot;: {
      &quot;@firebase/auth&quot;: [&quot;./node_modules/@firebase/auth/dist/index.rn.d.ts&quot;]
    }
  },
  &quot;extends&quot;: &quot;expo/tsconfig.base&quot;
}
</code></pre>
<p>Apparently, it is a typescript issue. Add the code above to your tsconfig.json file. This fix worked for me.</p>
","javascript, firebase, typescript, react-native"
Aug-23,Aug-23,"<p>I have the following FastAPI application:</p>
<pre class=""lang-py prettyprint-override""><code>from fastapi import FastAPI
import logging
import uvicorn

app = FastAPI(title=&quot;api&quot;)

LOG = logging.getLogger(__name__)
LOG.info(&quot;API is starting up&quot;)
LOG.info(uvicorn.Config.asgi_version)

@app.get(&quot;/&quot;)
async def get_index():
    LOG.info(&quot;GET /&quot;)
    return {&quot;Hello&quot;: &quot;Api&quot;}
</code></pre>
<p>The application locally is run with:</p>
<pre class=""lang-bash prettyprint-override""><code>uvicorn api:app --reload
</code></pre>
<pre class=""lang-py prettyprint-override""><code>INFO:     Will watch for changes in these directories: ['/Users/user/code/backend/api']
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [44258] using StatReload
INFO:     Started server process [44260]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
</code></pre>
<p>It is not logging any of the startup messages. Later on when sending an HTTP request to the API:</p>
<pre class=""lang-bash prettyprint-override""><code>INFO:     127.0.0.1:50538 - &quot;POST /api/v1/endpoint HTTP/1.1&quot; 200 OK
</code></pre>
<p>In the function body there is <code>LOG.info(&quot;example&quot;)</code> that does not get logged either. Is there a way to make FastAPI logging work with Uvicorn and also in production (independently of the execution environments like Uvicorn)?</p>
",22,"<h2>Setting up the <code>uvicorn</code> logger</h2>
<p>Straight from the <a href=""https://www.uvicorn.org/settings/#logging"" rel=""nofollow noreferrer"">documentation</a>:</p>
<blockquote>
<h3>Logging</h3>
<ul>
<li><code>--log-config &lt;path&gt;</code> - Logging configuration file. <strong>Options</strong>: <code>dictConfig()</code> formats: <em>.json</em>, .<em>yaml</em>. Any other format will be processed with <code>fileConfig()</code>. Set the <code>formatters.default.use_colors</code> and <code>formatters.access.use_colors</code> values to override the auto-detected behavior.</li>
<li>If you wish to use a YAML file for your logging config, you will need    to include PyYAML as a dependency for your project or install uvicorn with the <code>[standard]</code> optional extras.</li>
<li><code>--log-level &lt;str&gt;</code> - Set the log level. <strong>Options</strong>: '<em>critical</em>', '<em>error</em>', '<em>warning</em>', '<em>info</em>', '<em>debug</em>', '<em>trace</em>'. <strong>Default</strong>: '<em>info</em>'.</li>
<li><code>--no-access-log</code> - Disable access log only, without changing log level.</li>
<li><code>--use-colors</code> / <code>--no-use-colors</code> - Enable / disable colorized formatting of the log records, in case this is not set it will be auto-detected. This option is ignored if the <code>--log-config</code> CLI option is used.</li>
</ul>
</blockquote>
<h4>Regarding the log level</h4>
<p>As shown above, the <code>--log-level</code> flag specifies the lowest severity log message the logger will handle, where '<em>trace</em>' is the lowest severity/level and '<em>critical</em>' is the highest one. For instance, if the level is set to '<em>info</em>', the logger will only handle '<em>info</em>', '<em>warning</em>', '<em>error</em>' and '<em>critical</em>'  messages, whereas '<em>debug</em>' and '<em>trace</em>' messages will be ignored. If the level is set to '<em>trace</em>', the logger will handle all the messages.</p>
<h4>Running <code>uvicorn</code> from the command line</h4>
<p>When running uvicorn using the command line interface, you could set the log level as follows. On a side note, if one would like to disable the &quot;access log&quot; messages only, without changing the log level, they could use the <code>--no-access-log</code> flag (the <code>--access-log</code> flag is enabled by default). Moreover, in order to change the <code>host</code> and/or <code>port</code>, one could do that using <code>--host 0.0.0.0</code> and/or <code>--port 8000</code>. In the example below, <code>main</code> refers to the filename of the application (e.g., <code>main.py</code>)‚Äîsee <a href=""https://stackoverflow.com/a/73909126/17865804"">this answer</a> for more details.</p>
<pre class=""lang-py prettyprint-override""><code>uvicorn main:app --log-level trace
</code></pre>
<h4>Running <code>uvicorn</code> programmatically</h4>
<p>To run <code>uvicorn</code> from within a Python program, you could use the following. One could set the logging level, using the <code>log_level</code> flag in <code>uvicorn.run()</code>, as shown below. Again, if one would like to disable the &quot;access log&quot; messages only, they could do that by setting the <a href=""https://github.com/encode/uvicorn/blob/ff54b029b15adc5259cfbbfa2749778179c48d37/uvicorn/config.py#L195"" rel=""nofollow noreferrer""><code>access_log</code></a> argument to <code>False</code> (i.e., <code>access_log=False</code>). To change the <code>host</code> and/or <code>port</code>, one could use, for instance, <code>host='0.0.0.0'</code> and/or <code>port=8000</code>.</p>
<pre class=""lang-py prettyprint-override""><code>uvicorn.run(app, log_level=&quot;trace&quot;)
</code></pre>
<h2>Using the <code>uvicorn</code> logger to log custom messages too</h2>
<p>Uvicorn, as shown in its implementation <a href=""https://github.com/encode/uvicorn/blob/master/uvicorn/config.py"" rel=""nofollow noreferrer"">here</a>, internally uses various loggers such as <code>uvicorn</code>, <code>uvicorn.access</code>, <code>uvicorn.error</code> and <code>uvicorn.asgi</code>. The logger, however, that comes by the name <code>uvicorn.error</code> seems to be the one mostly used by Uvicorn, as shown <a href=""https://github.com/encode/uvicorn/blob/47304d9ae76321f0f5f649ff4f73e09b17085933/uvicorn/config.py#L99"" rel=""nofollow noreferrer"">here</a> and <a href=""https://github.com/encode/uvicorn/blob/47304d9ae76321f0f5f649ff4f73e09b17085933/uvicorn/server.py#L36"" rel=""nofollow noreferrer"">here</a>, for instance, to log various warnings, errors, as well as other type of information. On the other hand, <code>uvicorn.access</code> logger appears to be used for logging HTTP requests; for example, see <a href=""https://github.com/encode/uvicorn/blob/47304d9ae76321f0f5f649ff4f73e09b17085933/uvicorn/protocols/http/httptools_impl.py#L468"" rel=""nofollow noreferrer"">here</a>. For <code>uvicorn.asgi</code> logger, see <a href=""https://github.com/encode/uvicorn/blob/master/uvicorn/middleware/message_logger.py"" rel=""nofollow noreferrer"">here</a> as well.</p>
<p>Hence, one could use the <code>uvicorn.error</code> logger to log their own <strong>custom messages/errors</strong>, as shown in the example below, along with the <code>uvicorn</code> messages (again, the logging level could be changed using the <code>log_level</code> flag in <code>uvicorn.run()</code>) The <code>uvicorn.error</code> logger, as shown in the implementation <a href=""https://github.com/encode/uvicorn/blob/47304d9ae76321f0f5f649ff4f73e09b17085933/uvicorn/config.py#L92"" rel=""nofollow noreferrer"">here</a>, will <a href=""https://docs.python.org/3/library/logging.html#logging.Logger.propagate"" rel=""nofollow noreferrer""><code>propagate</code></a> a message by default to its ancestor logger, i.e., <code>uvicorn</code>.</p>
<p>On a side note, the parent logger, in this case <code>uvicorn</code>, would normally pass on the message to the highest-level logger, known as the <code>root</code> logger, but the <code>uvicorn</code> logger seems to have <code>propagate</code> flag set to <code>False</code> (see the <a href=""https://github.com/encode/uvicorn/blob/47304d9ae76321f0f5f649ff4f73e09b17085933/uvicorn/config.py#L93"" rel=""nofollow noreferrer"">relevant implementation</a>), meaning that its messages won't propagate to the <code>root</code> logger (which is perfectly fine‚Äîas described in the official Python documentation, it is <a href=""https://docs.python.org/3/howto/logging.html#configuring-logging-for-a-library"" rel=""nofollow noreferrer""><em>strongly advised that you <strong>do not</strong> log to the <code>root</code> logger in your library</em></a>). For the sake of completeness, it should be noted that in order to disable this behaviour‚Äînot that you have to‚Äîon <code>uvicorn.error</code> logger in the example below, one could set the <code>propagate</code> attribute to <code>False</code> for that logger as well, e.g., <code>logger.propagate = False</code>.</p>
<p><strong>main.py</strong></p>
<pre class=""lang-py prettyprint-override""><code>from fastapi import FastAPI
import uvicorn
import logging


app = FastAPI(title='api')
logger = logging.getLogger('uvicorn.error')

@app.get('/')
async def main():
    logger.info('GET /') # or logger.debug(), logger.error() etc.
    return 'success'
    
    
if __name__ == '__main__':
    uvicorn.run(app, log_level=&quot;trace&quot;) 
</code></pre>
<h2>Using custom-formatted <code>uvicorn</code> loggers to log custom messages too</h2>
<p>This approach demonstrates how to customise the <code>uvicorn</code> loggers, as well as use them to log <strong>both</strong> <code>uvicorn</code> and custom messages.</p>
<p>To define a custom format for the <code>uvicorn</code> loggers, one could use the <code>log_config</code> attribute in <code>uvicorn.run()</code> to pass a <a href=""https://docs.python.org/3/library/logging.config.html"" rel=""nofollow noreferrer"">logging configuration</a> dictionary (i.e., <a href=""https://docs.python.org/3/library/logging.config.html#logging.config.dictConfig"" rel=""nofollow noreferrer""><code>dictConfig()</code></a>), as shown in the exmaple below, including the various <a href=""https://docs.python.org/3/library/logging.config.html#dictionary-schema-details"" rel=""nofollow noreferrer"">schema details</a>, such as <code>formatters</code>, <code>handlers</code> and <code>loggers</code>. You could then define the <code>uvicorn.error</code> logger in <code>main.py</code>, as demonstrated in the previous section, and use it across your application.</p>
<p>For the file handler in the example below, <a href=""https://docs.python.org/3/library/logging.handlers.html#logging.handlers.RotatingFileHandler"" rel=""nofollow noreferrer""><code>RotatingFileHandler</code></a> is used, in which:</p>
<blockquote>
<p>You can use the <code>maxBytes</code> and <code>backupCount</code> values to allow the file to
<em>rollover</em> at a predetermined size. When the size is about to be
exceeded, the file is closed and a new file is silently opened for
output. Rollover occurs whenever the current log file is nearly
<code>maxBytes</code> in length; but if either of <code>maxBytes</code> or <code>backupCount</code> is zero,
rollover never occurs, so you generally want to set <code>backupCount</code> to at
least 1, and have a non-zero <code>maxBytes</code> (by default, the file would grow indefinitely).</p>
<p>When <code>backupCount</code> is non-zero, the system will save old log files by
appending the extensions ‚Äò.1‚Äô, ‚Äò.2‚Äô etc., to the filename. For
example, with a <code>backupCount</code> of 5 and a base file name of <code>app.log</code>,
you would get <code>app.log</code>, <code>app.log.1</code>, <code>app.log.2</code>, up to <code>app.log.5</code>.
The file being written to is always <code>app.log</code>. When this file is filled, it is closed and renamed to <code>app.log.1</code>, and if files <code>app.log.1</code>, <code>app.log.2</code>, etc. exist, then they are renamed to <code>app.log.2</code>, <code>app.log.3</code> etc. respectively.</p>
</blockquote>
<p><strong>main.py</strong></p>
<pre class=""lang-py prettyprint-override""><code>from fastapi import FastAPI
import uvicorn
import logging
import settings


app = FastAPI(title='api')
logger = logging.getLogger('uvicorn.error')


@app.get('/')
async def main():
    logger.info('GET /') # or logger.debug(), logger.error() etc.
    return 'success'
    
    
if __name__ == '__main__':
    uvicorn.run(app, log_config=settings.LOGGING_CONFIG)
</code></pre>
<p><strong>settings.py</strong></p>
<pre class=""lang-py prettyprint-override""><code>LOGGING_CONFIG = { 
    'version': 1,
    'disable_existing_loggers': True,
    'formatters': { 
        'standard': { 
            'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s'
        },
        'custom_formatter': { 
            'format': &quot;%(asctime)s [%(processName)s: %(process)d] [%(threadName)s: %(thread)d] [%(levelname)s] %(name)s: %(message)s&quot;
            
        },
    },
    'handlers': { 
        'default': { 
            'formatter': 'standard',
            'class': 'logging.StreamHandler',
            'stream': 'ext://sys.stdout',  # Default is stderr
        },
        'stream_handler': { 
            'formatter': 'custom_formatter',
            'class': 'logging.StreamHandler',
            'stream': 'ext://sys.stdout',  # Default is stderr
        },
        'file_handler': { 
            'class': 'logging.handlers.RotatingFileHandler',
            'formatter': 'custom_formatter',
            'filename': 'app.log',
            'maxBytes': 1024 * 1024 * 1, # = 1MB
            'backupCount': 3,
        },
    },
    'loggers': { 
        'uvicorn': {
            'handlers': ['default', 'file_handler'],
            'level': 'TRACE',
            'propagate': False
        },
        'uvicorn.access': {
            'handlers': ['stream_handler', 'file_handler'],
            'level': 'TRACE',
            'propagate': False
        },
        'uvicorn.error': { 
            'handlers': ['stream_handler', 'file_handler'],
            'level': 'TRACE',
            'propagate': False
        },
        'uvicorn.asgi': {
            'handlers': ['stream_handler', 'file_handler'],
            'level': 'TRACE',
            'propagate': False
        },

    },
}
</code></pre>
<h5>Custom JSON Formatter</h5>
<p>One could have the log messages displayed and/or saved in JSON format, if they wish, by either using a simple JSON format such as:</p>
<p><strong>settings.py</strong></p>
<pre class=""lang-py prettyprint-override""><code>LOGGING_CONFIG = { 
    'version': 1,
    'disable_existing_loggers': True,
    'formatters': {
        'standard': ...,  # same as above or customise that as well
        'custom_formatter': { 
            'format': &quot;{'time':'%(asctime)s', 'process_name': '%(processName)s', 'process_id': '%(process)s', 'thread_name': '%(threadName)s', 'thread_id': '%(thread)s','level': '%(levelname)s', 'logger_name': '%(name)s', 'message': '%(message)s'}&quot;            
        },
    },
    ...  # the rest is the same as in the original settings.py above
}
</code></pre>
<p>or, a more elegant version, as demonstrated previously in <a href=""https://stackoverflow.com/a/70899261/17865804"">this answer</a> and as shown below. Please refer to that answer and <a href=""https://stackoverflow.com/a/73464007/17865804"">this one</a> for further details, as well as the relevant middleware and methods for logging <code>Request</code> and <code>Response</code> information, which would go into the <code>extra</code> parameter when logging messages in the application (e.g., <code>logger.info(&quot;some msg&quot;, extra={'extra_info': get_extra_info(request, response)})</code>)‚Äîif you don't need that kind of information, please feel free to remove the <code>extra_info</code> part from the <code>get_log()</code> function below.</p>
<p><strong>settings.py</strong></p>
<pre class=""lang-py prettyprint-override""><code>import logging, json


class CustomJSONFormatter(logging.Formatter):
    def __init__(self, fmt):
        logging.Formatter.__init__(self, fmt)

    def format(self, record):
        logging.Formatter.format(self, record)
        return json.dumps(get_log(record), indent=2)


def get_log(record):
    d = {
        &quot;time&quot;: record.asctime,
        &quot;process_name&quot;: record.processName,
        &quot;process_id&quot;: record.process,
        &quot;thread_name&quot;: record.threadName,
        &quot;thread_id&quot;: record.thread,
        &quot;level&quot;: record.levelname,
        &quot;logger_name&quot;: record.name,
        &quot;pathname&quot;: record.pathname,
        &quot;line&quot;: record.lineno,
        &quot;message&quot;: record.message,
    }

    if hasattr(record, &quot;extra_info&quot;):
        d[&quot;req&quot;] = record.extra_info[&quot;req&quot;]
        d[&quot;res&quot;] = record.extra_info[&quot;res&quot;]

    return d


LOGGING_CONFIG = { 
    'version': 1,
    'disable_existing_loggers': True,
    'formatters': {
        'standard': ...,  # same as above or customise that as well
        'custom_formatter': { 
            '()':  lambda: CustomJSONFormatter(fmt='%(asctime)s')           
        },
    },
    ...  # the rest is the same as in the original settings.py above
}
</code></pre>
<p><strong>Output example:</strong></p>
<pre class=""lang-json prettyprint-override""><code>{
  &quot;time&quot;: &quot;2024-10-27 11:05:00,300&quot;,
  &quot;process_name&quot;: &quot;MainProcess&quot;,
  &quot;process_id&quot;: 4102,
  &quot;thread_name&quot;: &quot;AnyIO worker thread&quot;,
  &quot;thread_id&quot;: 1147,
  &quot;level&quot;: &quot;INFO&quot;,
  &quot;logger_name&quot;: &quot;uvicorn.error&quot;,
  &quot;pathname&quot;: &quot;C:\\...&quot;,
  &quot;line&quot;: 33,
  &quot;message&quot;: &quot;GET /&quot;,
  &quot;req&quot;: {
    &quot;url&quot;: &quot;/&quot;,
    &quot;headers&quot;: {
      &quot;host&quot;: &quot;localhost:8000&quot;,
      &quot;user-agent&quot;: &quot;Mozilla...&quot;,
      &quot;accept&quot;: &quot;text/html,application/xhtml+xml,...&quot;
    },
    &quot;method&quot;: &quot;GET&quot;,
    &quot;http_version&quot;: &quot;1.1&quot;,
    &quot;original_url&quot;: &quot;/&quot;,
    &quot;query&quot;: {}
  },
  &quot;res&quot;: {
    &quot;status_code&quot;: 200,
    &quot;status&quot;: &quot;OK&quot;
  }
}
</code></pre>
<h2>Using a custom Python logger separate from <code>uvicorn</code> loggers</h2>
<p>In case one wished having a separate custom Python logger instead of customising the existing <code>uvicorn</code> loggers, as demonstrated earlier, they would need to add a <code>StreamHandler</code> and/or <code>FileHandler</code> and set the desired level, i.e., <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, etc.‚Äîthe lowest level offered by Python's <code>logging</code> module is <code>DEBUG</code>, with the <a href=""https://docs.python.org/3/howto/logging.html#when-to-use-logging"" rel=""nofollow noreferrer"">default level being <code>WARNING</code></a> (if one is interested in adding a custom log level, see <a href=""https://stackoverflow.com/q/2183233"">this post</a>).</p>
<p>You could either do that using a <code>dictConfig()</code>, as shown earlier, or directly using the <code>logging</code>'s module functions and classes. The following example is based on <a href=""https://stackoverflow.com/a/70899261/17865804"">this answer</a>, which demonstrates <strong>how to customise the format of the logging messages in JSON</strong> (hence, see that answer, if you are looking for a similar format presented in the previous section), as well as <a href=""https://stackoverflow.com/a/73464007/17865804"">this answer</a> that shows <strong>how to log both the request and response bodies</strong> in the background.</p>
<p>More details and examples can also be found in Python's official documentation page <a href=""https://docs.python.org/3/howto/logging.html"" rel=""nofollow noreferrer"">here</a>. You may also want to have a look at all the available <a href=""https://docs.python.org/3/library/logging.html#logrecord-attributes"" rel=""nofollow noreferrer""><code>LogRecord</code> attributes</a> that can be used to format the logging records.</p>
<p>Setting <code>log_level=&quot;trace&quot;</code> in <code>uvicorn.run()</code> would set the level of the <code>uvicorn</code> logger to <code>TRACE</code>, as described earlier‚Äîin case one needed that as well. Also, one could still customise the <code>uvicorn</code> loggers, if they wish, using the <code>LOGGING_CONFIG</code> dictionary provided in the previous section and passing it to the settings, i.e., <code>uvicorn.run(..., log_config=settings.LOGGING_CONFIG)</code>. In that way, one could get the <code>uvicorn</code> logs in an elegant format and have them saved to a file on disk as well.</p>
<h2>Working Example</h2>
<pre class=""lang-py prettyprint-override""><code>from fastapi import FastAPI
import logging
import uvicorn
import sys

app = FastAPI()

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
formatter = logging.Formatter(&quot;%(asctime)s [%(processName)s: %(process)d] [%(threadName)s: %(thread)d] [%(levelname)s] %(name)s: %(message)s&quot;)

stream_handler = logging.StreamHandler(sys.stdout)
stream_handler.setFormatter(formatter)
file_handler = logging.FileHandler(&quot;info.log&quot;)
file_handler.setFormatter(formatter)

logger.addHandler(stream_handler)
logger.addHandler(file_handler)

logger.info('API is starting up')


@app.get('/')
async def main():
    logger.info('GET /')
    return 'ok'


if __name__ == '__main__':
    uvicorn.run(app, log_level=&quot;trace&quot;)  # or `log_config=settings.LOGGING_CONFIG`
</code></pre>
<h2>Final Note</h2>
<p>In each of the above cases, one may wish to initialise the <code>logger</code> at startup inside a <code>lifespan</code> handler, and then add it to <code>request.state</code>, so that it can be accessed outside the main file of the application as well; for instance, from a submodule that uses <code>APIRouter</code> to create <em>endpoints</em>, lying inside a <code>routers</code> package, which is normally the case when building <a href=""https://fastapi.tiangolo.com/tutorial/bigger-applications/"" rel=""nofollow noreferrer"">Bigger Applications</a>. To do that, please have a look at <a href=""https://stackoverflow.com/a/76322910/17865804"">this answer</a>.</p>
","python, logging, fastapi, uvicorn"
Aug-23,Aug-23,"<p>I want to execute this code in google colab but I get following error:</p>
<pre class=""lang-python prettyprint-override""><code>from llama_index.prompts.prompts import SimpleInputPrompt

# Create a system prompt 
system_prompt = &quot;&quot;&quot;[INST] &lt;&gt;
more string here.&lt;&gt;
&quot;&quot;&quot;

query_wrapper_prompt = SimpleInputPrompt(&quot;{query_str} [/INST]&quot;)
</code></pre>
<p>Error:</p>
<pre><code>/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_config.py:269: UserWarning: Valid config keys have changed in V2:
* 'allow_population_by_field_name' has been renamed to 'populate_by_name'
  warnings.warn(message, UserWarning)
---------------------------------------------------------------------------
PydanticUserError                         Traceback (most recent call last)
&lt;ipython-input-36-c45796b371fe&gt; in &lt;cell line: 3&gt;()
      1 # Import the prompt wrapper...
      2 # but for llama index
----&gt; 3 from llama_index.prompts.prompts import SimpleInputPrompt
      4 # Create a system prompt
      5 system_prompt = &quot;&quot;&quot;[INST] &lt;&gt;

6 frames
/usr/local/lib/python3.10/dist-packages/pydantic/deprecated/class_validators.py in root_validator(pre, skip_on_failure, allow_reuse, *__args)
    226     mode: Literal['before', 'after'] = 'before' if pre is True else 'after'
    227     if pre is False and skip_on_failure is not True:
--&gt; 228         raise PydanticUserError(
    229             'If you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`.'
    230             ' Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.',

PydanticUserError: If you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`. Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.

For further information visit https://errors.pydantic.dev/2.1.1/u/root-validator-pre-skip
</code></pre>
<p>If I follow  the link, there is no solution for my case.
How can I solve that problem?</p>
<p>Thanks in forward.</p>
",34,"<p>In my env, I have</p>
<pre class=""lang-bash prettyprint-override""><code>pip list | grep pydantic
pydantic                     2.2.1
</code></pre>
<p>I fix the problem, by downgrading <code>pydantic</code> version</p>
<pre class=""lang-py prettyprint-override""><code>pip install pydantic==1.10.9
</code></pre>
","python, prompt, pydantic, llama-index"
Aug-23,Aug-23,"<p>My question is simple, but I find it difficult to get the point straight, so please allow me to explain step by step.</p>
<p>Suppose I have <code>N</code> items and <code>N</code> corresponding indices.
Each item can be loaded using the corresponding index.</p>
<pre class=""lang-py prettyprint-override""><code>def load_item(index: int) -&gt; ItemType:
    # Mostly just reading, but very slow.
    return item
</code></pre>
<p>Also I have a function that takes two (loaded) items and calculates a score.</p>
<pre class=""lang-py prettyprint-override""><code>def calc_score(item_a: ItemType, item_b: ItemType) -&gt; ScoreType:
    # Much faster than load function.
    return score
</code></pre>
<p>Note that <code>calc_score(a, b) == calc_score(b, a)</code>.</p>
<p>What I want to do is calculate the score for all 2-item combinations and find (at least) one combination that gives the maximum score.</p>
<p>This can be implemented as follows:</p>
<pre class=""lang-py prettyprint-override""><code>def dumb_solution(n: int) -&gt; Tuple[int, int]:
    best_score = 0
    best_combination = None
    for index_a, index_b in itertools.combinations(range(n), 2):
        item_a = load_item(index_a)
        item_b = load_item(index_b)
        score = calc_score(item_a, item_b)
        if score &gt; best_score:
            best_score = score
            best_combination = (index_a, index_b)
    return best_combination
</code></pre>
<p>However, this solution calls the <code>load_item</code> function <code>2*C(N,2) = N*(N-1)</code> times, which is the bottleneck for this function.</p>
<p>This can be resolved by using a cache.
Unfortunately, however, the items are so large that it is impossible to keep all items in memory.
Therefore, we need to use a size-limited cache.</p>
<pre class=""lang-py prettyprint-override""><code>from functools import lru_cache

@lru_cache(maxsize=M)
def load(index: int) -&gt; ItemType:
    # Very slow process.
    return item
</code></pre>
<p>Note that <code>M</code> (cache size) is much smaller than <code>N</code> (approx. <code>N // 10</code> to <code>N // 2</code>).</p>
<p>The problem is that the typical sequence of combinations is not ideal for the LRU cache.</p>
<p>For instance, when <code>N=6, M=3</code>, <code>itertools.combinations</code> generates the following sequence, and the number of calls of the <code>load_item</code> function is 17.</p>
<pre class=""lang-py prettyprint-override""><code>[
    (0, 1),  # 1, 2
    (0, 2),  # -, 3
    (0, 3),  # -, 4
    (0, 4),  # -, 5
    (0, 5),  # -, 6
    (1, 2),  # 7, 8
    (1, 3),  # -, 9
    (1, 4),  # -, 10
    (1, 5),  # -, 11
    (2, 3),  # 12, 13
    (2, 4),  # -, 14
    (2, 5),  # -, 15
    (3, 4),  # 16, 17
    (3, 5),  # -, -
    (4, 5),  # -, -
]
</code></pre>
<p>However, if I rearrange the above sequence as follows, the number of calls will be 10.</p>
<pre class=""lang-py prettyprint-override""><code>[
    (0, 1),  # 1, 2
    (0, 2),  # -, 3
    (1, 2),  # -, -
    (0, 3),  # -, 4
    (2, 3),  # -, -
    (0, 4),  # -, 5
    (3, 4),  # -, -
    (0, 5),  # -, 6
    (4, 5),  # -, -
    (1, 4),  # 7, -
    (1, 5),  # -, -
    (1, 3),  # -, 8
    (3, 5),  # -, -
    (2, 5),  # 9, -
    (2, 4),  # -, 10
]
</code></pre>
<h1>Question:</h1>
<p>How can I generate a sequence of 2-item combinations that maximizes the cache hit rate?</p>
<hr />
<h1>What I tried:</h1>
<p>The solution I came up with is to prioritize items that are already in the cache.</p>
<pre class=""lang-py prettyprint-override""><code>from collections import OrderedDict


def prioritizes_item_already_in_cache(n, cache_size):
    items = list(itertools.combinations(range(n), 2))
    cache = OrderedDict()
    reordered = []

    def update_cache(x, y):
        cache[x] = cache[y] = None
        cache.move_to_end(x)
        cache.move_to_end(y)
        while len(cache) &gt; cache_size:
            cache.popitem(last=False)

    while items:
        # Find a pair where both are cached.
        for i, (a, b) in enumerate(items):
            if a in cache and b in cache:
                reordered.append((a, b))
                update_cache(a, b)
                del items[i]
                break
        else:
            # Find a pair where one of them is cached.
            for i, (a, b) in enumerate(items):
                if a in cache or b in cache:
                    reordered.append((a, b))
                    update_cache(a, b)
                    del items[i]
                    break
            else:
                # Cannot find item in cache.
                a, b = items.pop(0)
                reordered.append((a, b))
                update_cache(a, b)

    return reordered
</code></pre>
<p>For <code>N=100, M=10</code>, this sequence resulted in 1660 calls, which is about 1/3 of the typical sequence. For <code>N=100, M=50</code> there are only 155 calls. So I think I can say that this is a promising approach.</p>
<p>Unfortunately, this function is too slow and useless for large <code>N</code>.
I was not able to finish for <code>N=1000</code>, but the actual data is in the tens of thousands.
Also, it does not take into account how to select an item when no cached item is found.
Therefore, even if it is fast, it is doubtful that it is theoretically the best solution (so please note my question is not how to make the above function faster).</p>
<p>(Edited) Here is the complete code including everyone's answers and the test and benchmark code.</p>
<pre class=""lang-py prettyprint-override""><code>import functools
import itertools
import math
import time
from collections import Counter, OrderedDict
from itertools import chain, combinations, product
from pathlib import Path
from typing import Callable, Iterable, Tuple

import joblib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from PIL import Image, ImageDraw

ItemType = int
ScoreType = int


def load_item(index: int) -&gt; ItemType:
    return int(index)


def calc_score(item_a: ItemType, item_b: ItemType) -&gt; ScoreType:
    return abs(item_a - item_b)


class LRUCacheWithCounter:
    def __init__(self, maxsize: int):
        def wrapped_func(key):
            self.load_count += 1
            return load_item(key)

        self.__cache = functools.lru_cache(maxsize=maxsize)(wrapped_func)
        self.load_count = 0

    def __call__(self, key: int) -&gt; int:
        return self.__cache(key)


def basic_loop(iterator: Iterable[Tuple[int, int]], cached_load: Callable[[int], int]):
    best_score = 0
    best_combination = None
    for i, j in iterator:
        a = cached_load(i)
        b = cached_load(j)
        score = calc_score(a, b)
        if score &gt; best_score:
            best_score = score
            best_combination = (i, j)
    return best_score, best_combination


def baseline(n, _):
    return itertools.combinations(range(n), 2)


def prioritizes(n, cache_size):
    items = list(itertools.combinations(range(n), 2))
    cache = OrderedDict()
    reordered = []

    def update_cache(x, y):
        cache[x] = cache[y] = None
        cache.move_to_end(x)
        cache.move_to_end(y)
        while len(cache) &gt; cache_size:
            cache.popitem(last=False)

    while items:
        # Find a pair where both are cached.
        for i, (a, b) in enumerate(items):
            if a in cache and b in cache:
                reordered.append((a, b))
                update_cache(a, b)
                del items[i]
                break
        else:
            # Find a pair where one of them is cached.
            for i, (a, b) in enumerate(items):
                if a in cache or b in cache:
                    reordered.append((a, b))
                    update_cache(a, b)
                    del items[i]
                    break
            else:
                # Cannot find item in cache.
                a, b = items.pop(0)
                reordered.append((a, b))
                update_cache(a, b)

    return reordered


def Matt_solution(n: int, cache_size: int) -&gt; Iterable[Tuple[int, int]]:
    dest = []

    def findPairs(lo1: int, n1: int, lo2: int, n2: int):
        if n1 &lt; 1 or n2 &lt; 1:
            return
        if n1 == 1:
            for i in range(max(lo1 + 1, lo2), lo2 + n2):
                dest.append((lo1, i))
        elif n2 == 1:
            for i in range(lo1, min(lo1 + n1, lo2)):
                dest.append((i, lo2))
        elif n1 &gt;= n2:
            half = n1 // 2
            findPairs(lo1, half, lo2, n2)
            findPairs(lo1 + half, n1 - half, lo2, n2)
        else:
            half = n2 // 2
            findPairs(lo1, n1, lo2, half)
            findPairs(lo1, n1, lo2 + half, n2 - half)

    findPairs(0, n, 0, n)
    return dest


def Kelly_solution(n: int, cache_size: int) -&gt; Iterable[Tuple[int, int]]:
    k = cache_size // 2
    r = range(n)
    return chain.from_iterable(combinations(r[i : i + k], 2) if i == j else product(r[i : i + k], r[j : j + k]) for i in r[::k] for j in r[i::k])


def Kelly_solution2(n: int, cache_size: int) -&gt; Iterable[Tuple[int, int]]:
    k = cache_size - 2
    r = range(n)
    return chain.from_iterable(combinations(r[i : i + k], 2) if i == j else product(r[i : i + k], r[j : j + k]) for i in r[::k] for j in r[i::k])


def diagonal_block(lower, upper):
    for i in range(lower, upper + 1):
        for j in range(i + 1, upper + 1):
            yield i, j


def strip(i_lower, i_upper, j_lower, j_upper):
    for i in range(i_lower, i_upper + 1):
        for j in range(j_lower, j_upper + 1):
            yield i, j


def btilly_solution(n: int, cache_size: int):
    i_lower = 0
    i_upper = n - 1
    k = cache_size - 2
    is_asc = True
    while i_lower &lt;= i_upper:
        # Handle a k*k block first. At the end that is likely loaded.
        if is_asc:
            upper = min(i_lower + k - 1, i_upper)
            yield from diagonal_block(i_lower, upper)
            j_lower = i_lower
            j_upper = upper
            i_lower = upper + 1
        else:
            lower = max(i_lower, i_upper - k + 1)
            yield from diagonal_block(lower, i_upper)
            j_lower = lower
            j_upper = i_upper
            i_upper = lower - 1
        yield from strip(i_lower, i_upper, j_lower, j_upper)
        is_asc = not is_asc


def btilly_solution2(n: int, cache_size: int):
    k = cache_size - 2
    for top in range(0, n, k):
        bottom = top + k
        # Diagonal part.
        for y in range(top, min(bottom, n)):  # Y-axis Top to Bottom
            for x in range(y + 1, min(bottom, n)):  # X-axis Left to Right
                yield y, x
        # Strip part.
        # Stripping right to left works well when cache_size is very small, but makes little difference when it is not.
        for x in range(n - 1, bottom - 1, -1):  # X-axis Right to Left
            for y in range(top, min(bottom, n)):  # Y-axis Top to Bottom
                yield y, x


def btilly_solution3(n: int, cache_size: int):
    k = cache_size - 2
    r = range(n)
    for i in r[::k]:
        yield from combinations(r[i : i + k], 2)
        yield from product(r[i + k :], r[i : i + k])


def btilly_solution4(n: int, cache_size: int):
    def parts():
        k = cache_size - 2
        r = range(n)
        for i in r[::k]:
            yield combinations(r[i : i + k], 2)
            yield product(r[i + k :], r[i : i + k])

    return chain.from_iterable(parts())


def plot(df, series, ignore, y, label, title):
    df = df[df[&quot;name&quot;].isin(series)]
    # plt.figure(figsize=(10, 10))
    for name, group in df.groupby(&quot;name&quot;):
        plt.plot(group[&quot;n&quot;], group[y], label=name)

    y_max = df[~df[&quot;name&quot;].isin(ignore)][y].max()
    plt.ylim(0, y_max * 1.1)

    plt.xlabel(&quot;n&quot;)
    plt.ylabel(label)
    plt.title(title)
    plt.legend(loc=&quot;upper left&quot;)
    plt.tight_layout()
    plt.grid()
    plt.show()


def run(func, n, cache_ratio, output_dir: Path):
    cache_size = int(n * cache_ratio / 100)
    output_path = output_dir / f&quot;{n}_{cache_ratio}_{func.__name__}.csv&quot;
    if output_path.exists():
        return

    started = time.perf_counter()
    for a, b in func(n, cache_size):
        pass
    elapsed_iterate = time.perf_counter() - started

    # test_combinations(func(n, cache_size), n)

    started = time.perf_counter()
    cache = LRUCacheWithCounter(cache_size)
    basic_loop(iterator=func(n, cache_size), cached_load=cache)
    elapsed_cache = time.perf_counter() - started

    output_path.write_text(f&quot;{func.__name__},{n},{cache_ratio},{cache_size},{cache.load_count},{elapsed_iterate},{elapsed_cache}&quot;)


def add_lower_bound(df):
    def calc_lower_bound(ni, mi):
        n = ni
        m = n * mi // 100
        return m + math.ceil((math.comb(n, 2) - math.comb(m, 2)) / (m - 1))

    return pd.concat(
        [
            df,
            pd.DataFrame(
                [
                    {&quot;name&quot;: &quot;lower_bound&quot;, &quot;n&quot;: ni, &quot;m&quot;: mi, &quot;count&quot;: calc_lower_bound(ni, mi)}
                    for ni, mi in itertools.product(df[&quot;n&quot;].unique(), df[&quot;m&quot;].unique())
                ]
            ),
        ]
    )


def benchmark(output_dir: Path):
    log_dir = output_dir / &quot;log&quot;
    log_dir.mkdir(parents=True, exist_ok=True)

    candidates = [
        baseline,
        prioritizes,
        Matt_solution,
        Kelly_solution,
        Kelly_solution2,
        btilly_solution,
        btilly_solution2,
        btilly_solution3,
        btilly_solution4,
    ]

    nc = np.linspace(100, 500, num=9).astype(int)
    # nc = np.linspace(500, 10000, num=9).astype(int)[1:]
    # nc = np.linspace(10000, 100000, num=9).astype(int).tolist()[1:]
    print(nc)

    mc = np.linspace(10, 50, num=2).astype(int)
    print(mc)

    joblib.Parallel(n_jobs=1, verbose=5, batch_size=1)([joblib.delayed(run)(func, ni, mi, log_dir) for ni in nc for mi in mc for func in candidates])


def plot_graphs(output_dir: Path):
    log_dir = output_dir / &quot;log&quot;

    results = []
    for path in log_dir.glob(&quot;*.csv&quot;):
        results.append(path.read_text().strip())
    (output_dir / &quot;stat.csv&quot;).write_text(&quot;\n&quot;.join(results))

    df = pd.read_csv(output_dir / &quot;stat.csv&quot;, header=None, names=[&quot;name&quot;, &quot;n&quot;, &quot;m&quot;, &quot;size&quot;, &quot;count&quot;, &quot;time&quot;, &quot;time_full&quot;])
    df = add_lower_bound(df)
    df = df.sort_values([&quot;name&quot;, &quot;n&quot;, &quot;m&quot;])

    for m in [10, 50]:
        plot(
            df[df[&quot;m&quot;] == m],
            series=[
                baseline.__name__,
                prioritizes.__name__,
                Matt_solution.__name__,
                Kelly_solution.__name__,
                Kelly_solution2.__name__,
                btilly_solution.__name__,
                &quot;lower_bound&quot;,
            ],
            ignore=[
                baseline.__name__,
                prioritizes.__name__,
            ],
            y=&quot;count&quot;,
            label=&quot;load count&quot;,
            title=f&quot;cache_size = {m}% of N&quot;,
        )

    plot(
        df[df[&quot;m&quot;] == 10],
        series=[
            baseline.__name__,
            prioritizes.__name__,
            Matt_solution.__name__,
            Kelly_solution.__name__,
            Kelly_solution2.__name__,
            btilly_solution.__name__,
            btilly_solution2.__name__,
            btilly_solution3.__name__,
            btilly_solution4.__name__,
        ],
        ignore=[
            prioritizes.__name__,
            Matt_solution.__name__,
        ],
        y=&quot;time&quot;,
        label=&quot;time (sec)&quot;,
        title=f&quot;cache_size = {10}% of N&quot;,
    )


class LRUCacheForTest:
    def __init__(self, maxsize: int):
        self.cache = OrderedDict()
        self.maxsize = maxsize
        self.load_count = 0

    def __call__(self, key: int) -&gt; int:
        if key in self.cache:
            value = self.cache[key]
            self.cache.move_to_end(key)
        else:
            if len(self.cache) == self.maxsize:
                self.cache.popitem(last=False)
            value = load_item(key)
            self.cache[key] = value
            self.load_count += 1
        return value

    def hit(self, i, j):
        count = int(i in self.cache)
        self(i)
        count += int(j in self.cache)
        self(j)
        return count


def visualize():
    # Taken from https://stackoverflow.com/a/77024514/18125313 and modified.
    n, m = 100, 30
    func = btilly_solution2

    pairs = func(n, m)
    cache = LRUCacheForTest(m)

    # Create the images, save as animated png.
    images = []
    s = 5
    img = Image.new(&quot;RGB&quot;, (s * n, s * n), (255, 255, 255))
    draw = ImageDraw.Draw(img)

    colors = [(255, 0, 0), (255, 255, 0), (0, 255, 0)]
    for step, (i, j) in enumerate(pairs):
        draw.rectangle((s * j, s * i, s * j + s - 2, s * i + s - 2), colors[cache.hit(i, j)])
        if not step % 17:
            images.append(img.copy())

    images += [img] * 40

    images[0].save(f&quot;{func.__name__}_{m}.gif&quot;, save_all=True, append_images=images[1:], optimize=False, duration=30, loop=0)


def test_combinations(iterator: Iterable[Tuple[int, int]], n: int):
    # Note that this function is not suitable for large N.
    expected = set(frozenset(pair) for pair in itertools.combinations(range(n), 2))
    items = list(iterator)
    actual = set(frozenset(pair) for pair in items)
    assert len(actual) == len(items), f&quot;{[item for item, count in Counter(items).items() if count &gt; 1]}&quot;
    assert actual == expected, f&quot;dup={actual - expected}, missing={expected - actual}&quot;


def test():
    n = 100  # N
    cache_size = 30  # M

    def run(func):
        func(n, cache_size)

        # Measure generation performance.
        started = time.perf_counter()
        for a, b in func(n, cache_size):
            pass
        elapsed = time.perf_counter() - started

        # Test generated combinations.
        test_combinations(func(n, cache_size), n)

        # Measure cache hit (load count) performance.
        cache = LRUCacheWithCounter(cache_size)
        _ = basic_loop(iterator=func(n, cache_size), cached_load=cache)
        print(f&quot;{func.__name__}: {cache.load_count=}, {elapsed=}&quot;)

    candidates = [
        baseline,
        prioritizes,
        Matt_solution,
        Kelly_solution,
        Kelly_solution2,
        btilly_solution,
        btilly_solution2,
        btilly_solution3,
        btilly_solution4,
    ]
    for f in candidates:
        run(f)


def main():
    test()
    visualize()

    output_dir = Path(&quot;./temp2&quot;)
    benchmark(output_dir)
    plot_graphs(output_dir)


if __name__ == &quot;__main__&quot;:
    main()
</code></pre>
<p>I have no problem with you not using the above test code or changing the behavior of <code>basic_loop</code> or <code>LRUCacheWithCounter</code>.</p>
<p>Additional Note:</p>
<ul>
<li>The score calculation cannot be pruned using neighbor scores.</li>
<li>The score calculation cannot be pruned using only a portion of the item.</li>
<li>It is impossible to guess where the best combination will be.</li>
<li>Using faster media is one option, but I'm already at my limit, so I'm looking for a software solution.</li>
</ul>
<p>Thank you for reading this long post to the end.</p>
<hr />
<h1>Edit:</h1>
<p>Thanks to btilly's answer and help with Kelly's visualization, I have come to the conclusion that btilly's solution is the best and (possibly) optimal one.</p>
<p>Here is a theoretical explanation (although I am not very good at math, so it could be wrong).</p>
<hr />
<p>Let <code>N</code> represent the number of indexes, <code>M</code> the cache size, and <code>C</code> the number of combinations (same as <code>math.comb</code>).</p>
<p>Consider a situation where the cache is full and <strong>no further combinations can be generated</strong> without loading.
If we add a new index at this point, the only combinations that can be generated are combinations of the newly added index and the remaining indexes in the cache.
This pattern holds for each subsequent iteration.
Hence, while the cache is full, the maximum number of combinations can be generated per load is <code>M - 1</code>.</p>
<p>This logic holds if the cache isn't full as well.
If <code>M'</code> indexes are currently in the cache, then the next index can generate at most <code>M'</code> combinations.
The subsequent index can generate at most <code>M' + 1</code> combinations, and so forth.
In total, at most <code>C(M,2)</code> combinations can be generated before the cache is full.</p>
<p>Thus, to generate <code>C(N,2)</code> combinations, at least <code>M</code> loads are required to fill the cache, at least <code>(C(N,2) - C(M,2)) / (M - 1)</code> loads are required after the cache is filled.</p>
<p>From above, the load counts complexity of this problem is <code>Œ©(N^2 / M)</code>.</p>
<hr />
<p>I have plotted this formula as a <code>lower_bound</code> in the graphs below.
Note that it is only a lower bound and no guarantee that it can actually be achieved.</p>
<p>As an aside, Kelly's solution needs to configure <code>k</code> to maximize its performance.
For <code>M = 50% of N</code>, it's about <code>M * 2/3</code>.
For <code>M = 30% of N</code>, it's about <code>M * 5/6</code>.
Although I couldn't figure out how to calculate it.
As a general configuration, I use <code>k = M - 2</code> (which is not best, but relatively good) in the <code>Kelly_solution2</code> in the graphs below.</p>
<p>For <code>M = 10% of N</code>:</p>
<p><a href=""https://i.sstatic.net/xL5Rx.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/xL5Rx.png"" alt=""n_to_load_count_graph_10"" /></a></p>
<p>For <code>M = 50% of N</code>:</p>
<p><a href=""https://i.sstatic.net/LsWwa.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/LsWwa.png"" alt=""n_to_load_count_graph_50"" /></a></p>
<p>Note that, in these graphs, it looks like <code>O(N)</code>, but this is because I determined <code>M</code> based on <code>N</code>. When <code>M</code> does not change, it is <code>O(N^2)</code> as described above.</p>
<p>Here is an animation visualizing the cache hit rate of <code>btilly_solution2</code>, composed by a modified version of Kelly's code.
Each pixel represents a combination, with red representing combinations where both indexes are loaded, yellow where one index is loaded, and green where neither index is loaded.</p>
<p><a href=""https://i.sstatic.net/fYjDw.gif"" rel=""noreferrer""><img src=""https://i.sstatic.net/fYjDw.gif"" alt=""visualization_of_btilly_solution2"" /></a></p>
<p>In addition, since I'm looking for the optimal sequence, execution time doesn't matter much.
But just in case anyone is curious, here is a comparison of execution times (iteration only).</p>
<p><a href=""https://i.sstatic.net/eiun9.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/eiun9.png"" alt=""n_to_time_graph"" /></a></p>
<p><code>btilly_solution4</code> (btilly's solution modified by Kelly) is almost as fast as <code>itertools.combinations</code>, which should be optimal in this case.
Note, however, that even without the modification, it took only 112 nanoseconds per combination.</p>
<p>That's it. Thanks to everyone involved.</p>
",12,"<p>Here is a simple approach that depends on the cache and gets 230 on your benchmark.</p>
<pre><code>def diagonal_block (lower, upper):
    for i in range(lower, upper + 1):
        for j in range(i, upper + 1):
            yield (i, j)

def strip (i_lower, i_upper, j_lower, j_upper):
    for i in range(i_lower, i_upper+1):
        for j in range (j_lower, j_upper + 1):
            yield (i, j)

# def your_solution_here(n: int, cache_size: int) -&gt; Iterable[Tuple[int, int]]:
def your_solution_here(n: int, cache_size: int):
    i_lower = 0
    i_upper = n-1
    k = cache_size - 2
    is_asc = True
    while i_lower &lt;= i_upper:
        # Handle a k*k block first. At the end that is likely loaded.
        if is_asc:
            upper = min(i_lower + k - 1, i_upper)
            yield from diagonal_block(i_lower, upper)
            j_lower = i_lower
            j_upper = upper
            i_lower = upper + 1
        else:
            lower = max(i_lower, i_upper - k + 1)
            yield from diagonal_block(lower, i_upper)
            j_lower = lower
            j_upper = i_upper
            i_upper = lower - 1
        yield from strip(i_lower, i_upper, j_lower, j_upper)
        is_asc = not is_asc
</code></pre>
<hr />
<p>A comment about how I thought this one up.</p>
<p>We want to compare a group of objects with every other uncompared object. The group should be everything that fits in the cache except one.</p>
<p>So we start with the first <code>k</code> objects, compare them with each other, then just proceed along in a strip to the end.</p>
<p>And now we need our second group. Well, we already have the last object, and we don't need the rest. So we take <code>k</code> objects from the end, make that a group. Compare the group with itself, then proceed along a strip to the first object outside of our original group.</p>
<p>Now reverse direction, and so on.</p>
<p>At all points, <code>i_lower</code> represents the first object still needing comparing, and <code>i_upper</code> represents the last. If we're going forward, we take <code>k</code> objects starting at <code>i_lower</code>. If we're going backwards we take <code>k</code> objects starting at <code>i_upper</code> and go backwards.</p>
<p>When I was implementing it, there were two complications. The first is that we have to worry about the edge condition when we meet in the middle. The second is that we might have to do the strip in 2 directions.</p>
<p>I chose to only do the strip ascending. This is actually a bug. On most of the ascending loads, I did not get the first element in my cache. Oops. But it is still pretty good.</p>
","python, algorithm, caching, combinations"
Sep-23,Sep-23,"<p>As it's usually advised, I have managed to reduce my problem to a minimal reproducible example:</p>
<pre class=""lang-py prettyprint-override""><code>import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

matrix = np.array([[0.1234, 1.4567, 0.7890, 0.1234],
                   [0.9876, 0, 0.5432, 0.6789],
                   [0.1111, 0.2222, 0, 0.3333],
                   [0.4444, 0.5555, 0.6666, 0]])
sns.heatmap(matrix, annot=True)
plt.show()
</code></pre>
<p>Vaguely based on Seaborn <a href=""https://seaborn.pydata.org/generated/seaborn.heatmap.html?highlight=heatmap#seaborn.heatmap:%7E:text=values%20with%20text%3A-,sns.heatmap(glue%2C%20annot%3DTrue),-Control%20the%20annotations"" rel=""noreferrer"">official documentation</a>.</p>
<p>Unfortunately, unlike what would be expected (all numbers visible), I get only the numbers in the top row visible:</p>
<p><a href=""https://i.sstatic.net/iedcm.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/iedcm.png"" alt=""enter image description here"" /></a></p>
<hr />
<p>As there is not really much room for error in this one, I'm out of ideas and google/SO doesn't seem to have this question asked before. Is this a bug?</p>
<hr />
<p>I am running:</p>
<pre><code>Seaborn 0.12.2
Matplotlib 3.8.0
PyCharm 2023.1.4
Windows 10
</code></pre>
",39,"<p>Just ran into the issue myself, I was on Seaborn 0.12.2. Ran <code>pip install seaborn --upgrade</code> and now have 0.13.0</p>
<p>Restarted vscode and annotations appeared.</p>
","python, matplotlib, seaborn"
Sep-23,Sep-23,"<p>I made function 'warn' in line 17 whose parameter is enum Shape. Why is it warning about visibility scope and how can I fix it?</p>
<pre><code>import java.util.Scanner;

public class AreaCalculator {

    enum Shape {TRIANGLE, RECTANGLE, CIRCLE}
    static Scanner scanner = new Scanner(System.in);

    public static void main(String[] args) {
        String str = scanner.next();

        while (!str.equals(&quot;quit&quot;)){
            str = str.toUpperCase();
            warn(Shape.valueOf(str));
        }
    }

    public static void warn(Shape shape) { //warning

    }
</code></pre>
<p>IntelliJ recommends generate overloaded method with default parameter values like following code.</p>
<pre><code>public static void warn(){
    warn(null);
}
</code></pre>
<p>But I think it doesn't look intuitive.</p>
",36,"<p>Why is there a warning <code>Class 'Shape' is exposed outside its defined visibility scope</code>?</p>
<p>Because the <code>enum</code> <code>AreaCalculator.Shape</code> is only visible to classes in the same package, but the method <code>public static void warn(Shape shape)</code> is visible to any class.</p>
<p>So if we write a class:</p>
<pre><code>package a;

import b.AreaCalculator;

public class AreaCalculatorClient {
    public static void main(String[] args) {
        AreaCalculator.warn(AreaCalculator.Shape.CIRCLE);
    }
}
</code></pre>
<p>It will fail to compile, because <code>'b.AreaCalculator.Shape' is not public in 'b.AreaCalculator'. Cannot be accessed from outside package</code>.</p>
<p>The fix is to with make <code>Shape</code> public or <code>warn</code> package-private, depending on your intent.</p>
<p>The fix suggested by IntelliJ IDEA is something you might do if you're convinced that you've chosen the correct visibility for <code>Shape</code>, and yet you want to call something like the <code>warn</code> method from arbitrary classes.</p>
","java, enums, warnings, visibility, function"
Sep-23,Sep-23,"<p>I use shadcn in my next.js 13 project. I want to have a dropdown with the option to edit or delete an entry. When the user clicks on &quot;delete&quot; a dialog should pop up and ask them for a confirmation. However, the dialog only shows for about 0.5 seconds before it closes together with the dropdown. How can I prevent that from happening?</p>
<p>Here is the example on codesandbox: <a href=""https://codesandbox.io/p/sandbox/shadcn-playground-3gs3v6?file=%2Fsrc%2Flib%2Futils.js%3A1%2C1"" rel=""noreferrer"">Codesandbox</a></p>
<p>This is the code:</p>
<pre class=""lang-html prettyprint-override""><code>    &lt;DropdownMenu&gt;
      &lt;DropdownMenuTrigger&gt;
        &lt;p&gt;Trigger&lt;/p&gt;
      &lt;/DropdownMenuTrigger&gt;
      &lt;DropdownMenuContent&gt;
        &lt;Dialog&gt;
          &lt;DropdownMenuLabel&gt;Edit Entry&lt;/DropdownMenuLabel&gt;
          &lt;DropdownMenuSeparator /&gt;
          &lt;DropdownMenuItem
            onClick={() =&gt; conosle.log(&quot;Navigate to edit page&quot;)}
          &gt;
            Edit
          &lt;/DropdownMenuItem&gt;
          &lt;DialogTrigger&gt;
            &lt;DropdownMenuItem&gt;Delete&lt;/DropdownMenuItem&gt;
          &lt;/DialogTrigger&gt;
          &lt;DialogContent&gt;
            &lt;DialogHeader&gt;
              &lt;DialogTitle&gt;Are you sure?&lt;/DialogTitle&gt;
              &lt;DialogDescription&gt;
                Do you want to delete the entry? Deleting this entry cannot be
                undone.
              &lt;/DialogDescription&gt;
            &lt;/DialogHeader&gt;
            &lt;DialogFooter&gt;
              &lt;DialogClose asChild&gt;
                &lt;Button variant=&quot;outline&quot;&gt;Cancel&lt;/Button&gt;
              &lt;/DialogClose&gt;
              &lt;Button&gt;Delete&lt;/Button&gt;
            &lt;/DialogFooter&gt;
          &lt;/DialogContent&gt;
        &lt;/Dialog&gt;
      &lt;/DropdownMenuContent&gt;
    &lt;/DropdownMenu&gt;
</code></pre>
",37,"<h2>What is the problem?</h2>
<p>When you click any <code>&lt;DropdownMenuItem /&gt;</code>, It will trigger the action (onClick) and close (unmount) the <code>&lt;DropdownMenuContent /&gt;</code> which includes the <code>&lt;DialogContent /&gt;</code> so it'll be unmounted with it.</p>
<h2>Solutions</h2>
<h3>1. Move the <code>&lt;DialogContent /&gt;</code> outside of the <code>&lt;DropdownMenuContent /&gt;</code></h3>
<pre><code>// ...
export default function App() {
  return (
    &lt;Dialog&gt; {/* üî¥ The dialog provider outside of the DropdownMenuContent */}
      &lt;DropdownMenu&gt;
        &lt;DropdownMenuTrigger&gt;
          &lt;p&gt;Trigger&lt;/p&gt;
        &lt;/DropdownMenuTrigger&gt;
        &lt;DropdownMenuContent&gt;
          &lt;DropdownMenuItem&gt;
            &lt;DialogTrigger&gt;
              Open Popup
            &lt;/DialogTrigger&gt;
          &lt;/DropdownMenuItem&gt;
        &lt;/DropdownMenuContent&gt;
      &lt;/DropdownMenu&gt;
      {/* üî¥ DialogContent ouside of DropdownMenuContent */}
      &lt;DialogContent&gt;
        &lt;DialogHeader&gt;
          &lt;DialogTitle&gt;Are you sure?&lt;/DialogTitle&gt;
          &lt;DialogDescription&gt;
            Do you want to delete the entry? Deleting this entry cannot be
            undone.
          &lt;/DialogDescription&gt;
        &lt;/DialogHeader&gt;
        &lt;DialogFooter&gt;
          &lt;DialogClose asChild&gt;
            &lt;Button variant=&quot;outline&quot;&gt;Cancel&lt;/Button&gt;
          &lt;/DialogClose&gt;
          &lt;Button&gt;Delete&lt;/Button&gt;
        &lt;/DialogFooter&gt;
      &lt;/DialogContent&gt;
    &lt;/Dialog&gt;
  );
}
</code></pre>
<p>This solution works well if you have a single item triggers dialog. But what if you have multiple dialogs?</p>
<h3>2. Multiple dialogs</h3>
<p>Move your dialog outside the <code>&lt;DropdownMenuContent /&gt;</code>, create a state for each one:</p>
<pre><code>const [isEditDialogOpen, setIsEditDialogOpen] = useState(false)
const [isDeleteDialogOpen, setIsDeleteDialogOpen] = useState(false)
</code></pre>
<p>then remove any <code>&lt;DialogTrigger /&gt;</code>, add onClick instead</p>
<pre><code>&lt;DropdownMenuItem onClick={() =&gt; setIsEditDialogOpen(true)}&gt;Edit&lt;/DropdownMenuItem&gt;
&lt;DropdownMenuItem onClick={() =&gt; setIsDeleteDialogOpen(true)}&gt;Delete&lt;/DropdownMenuItem&gt;
</code></pre>
<p>In your dialog add</p>
<pre><code>&lt;Dialog open={isEditDialogOpen || isDeleteDialogOpen} 
        onOpenChange={isEditDialogOpen ? 
            setIsEditDialogOpen : setIsDeleteDialogOpen}&gt;
...
&lt;/Dialog&gt;
</code></pre>
<p>If you don't want to make it controlled and can render two trigger buttons, you can render two separate dialogs:</p>
<pre class=""lang-js prettyprint-override""><code>&lt;Dialog&gt;
  &lt;DialogTrigger&gt;Edit Post&lt;/DialogTrigger&gt;
  &lt;DialogContent&gt;
     Content 
  &lt;/DialogContent&gt;
&lt;/Dialog&gt;

&lt;Dialog&gt;
  &lt;DialogTrigger&gt;Edit Post&lt;/DialogTrigger&gt;
  &lt;DialogContent&gt;
    Content 
  &lt;/DialogContent&gt;
&lt;/Dialog&gt;
</code></pre>
","javascript, reactjs, next.js"
Sep-23,Sep-23,"<p>I'm using macOS and I want to try Java 21 in IntelliJ IDEA. I believe I have done all the required steps to change Java version of a project / module. Nevertheless I still can't use new Java 21 Features, such as <a href=""https://openjdk.org/jeps/430"" rel=""nofollow noreferrer"">String Templates</a>. How to be able to use Java 21 in IntelliJ?</p>
<p><a href=""https://i.sstatic.net/btA2f.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/btA2f.png"" alt=""enter image description here"" /></a></p>
<p>I have changed:</p>
<ul>
<li><p>Project SDK to 21</p>
</li>
<li><p>Module SDK to 21</p>
</li>
<li><p>OS java version to 21. Typing <code>java -version</code> in terminal outputs:</p>
<blockquote>
<p>java version &quot;21&quot; 2023-09-19 LTS</p>
<p>Java(TM) SE Runtime Environment (build 21+35-LTS-2513)</p>
<p>Java HotSpot(TM) 64-Bit Server VM (build 21+35-LTS-2513, mixed mode, sharing)</p>
</blockquote>
</li>
<li><p>I have also updated IntelliJ to version 2023.2</p>
</li>
</ul>
",21,"<p>I needed to update Intellij version to 2023.2.2 and change Language level (File -&gt; Project structure -&gt; project -&gt; language level) to 21 (preview)</p>
<p><a href=""https://i.sstatic.net/4zkOj.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/4zkOj.png"" alt=""language level 21 (preview)"" /></a>
The new language level won't show up until Intellij is updated to the latest version.</p>
<p>To update Intellij, I needed to manually check for new update</p>
<p><strong>Manually updating Intellij on Mac</strong></p>
<p>Intellij IDEA | Check for Updates</p>
<p><a href=""https://i.sstatic.net/ENLlm.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/ENLlm.png"" alt=""enter image description here"" /></a></p>
<p><strong>Manually updating Intellij on Windows / Linux</strong></p>
<p>File | Settings | Appearance &amp; Behavior | System Settings | Updates</p>
<p><a href=""https://i.sstatic.net/HfSUn.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/HfSUn.png"" alt=""enter image description here"" /></a></p>
","java, sdk, intellij-idea, java-21"
Sep-23,Sep-23,"<p>When trying to configure the project using Java 21 I'm getting the error:</p>
<blockquote>
<p>Unsupported Java. Your build is currently configured to use Java 21 and Gradle 8.3.</p>
</blockquote>
<p>Unfortunately, there is no information in official documentation for now: <a href=""https://docs.gradle.org/current/userguide/compatibility.html"" rel=""noreferrer"">https://docs.gradle.org/current/userguide/compatibility.html</a></p>
<blockquote>
<p>A Java version between 8 and 20 is required to execute Gradle. Java 21
and later versions are not yet supported.</p>
</blockquote>
<p>Starting from which version does Gradle support Java 21?</p>
",33,"<p>See <a href=""https://docs.gradle.org/8.8-rc-1/userguide/compatibility.html"" rel=""noreferrer""><em>Compatibility Matrix</em></a> in the fine manual.</p>
<p><a href=""https://i.sstatic.net/TgmfV5Jj.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/TgmfV5Jj.png"" alt=""enter image description here"" /></a></p>
<h1>Java 22, Gradle 8.7</h1>
<p>Gradle 8.7 supports <a href=""https://en.wikipedia.org/wiki/Java_version_history#Java_22"" rel=""noreferrer"">Java 22</a> for compiling, testing, and running JVM-based projects. See <a href=""https://docs.gradle.org/8.7/release-notes.html"" rel=""noreferrer""><em>Gradle Release Notes</em></a> and <a href=""https://docs.gradle.org/current/userguide/userguide.html"" rel=""noreferrer""><em>Gradle User Manual</em></a>.</p>
<p>But Groovy does not yet support Java 22. Therefore Gradle itself cannot run on Java 22. The workaround is to install both Java 21 <em>and</em> Java 22. Run Gradle on Java 21, while letting Gradle manage your Java 22 project. To do this in IntelliJ, see <a href=""https://stackoverflow.com/a/78388163/642706"">my Answer</a>.</p>
<p>On its eventual release, <strong>Gradle 8.8</strong> will fully support Java 22.</p>
<p>See related Question, <a href=""https://stackoverflow.com/q/78252122/642706""><em>Gradle 8.7 cannot find installed JDK 22 in IntelliJ</em></a>.</p>
<h1>Java 21, Gradle 8.5</h1>
<p>For full <a href=""https://en.wikipedia.org/wiki/Java_version_history#Java_21"" rel=""noreferrer"">Java 21</a> support, you can use <a href=""https://github.com/gradle/gradle/releases"" rel=""noreferrer"">Gradle 8.5</a>. The <a href=""https://docs.gradle.org/8.5/release-notes.html#full-java-21-support"" rel=""noreferrer"">release notes</a> say:</p>
<blockquote>
<p>With this release, Gradle now fully supports compiling, testing and running on Java 21.</p>
</blockquote>
<hr />
<p>If migrating from older Gradle, see <a href=""https://gradle.org/whats-new/gradle-8/"" rel=""noreferrer""><em>What's new in Gradle 8.0</em></a>.</p>
","java, gradle, java-21"
Oct-23,Oct-23,"<p>Earlier I installed some packages like <a href=""https://en.wikipedia.org/wiki/Matplotlib"" rel=""noreferrer"">Matplotlib</a>, <a href=""https://en.wikipedia.org/wiki/NumPy"" rel=""noreferrer"">NumPy</a>, pip (version 23.3.1), wheel (version 0.41.2), etc., and did some programming with those. I used the command <code>C:\Users\UserName&gt;pip list</code> to find the list of packages that I have installed, and I am using Python 3.12.0 (by employing code <code>C:\Users\UserName&gt;py -V</code>).</p>
<p>I need to use <a href=""https://github.com/spedas/pyspedas"" rel=""noreferrer"">pyspedas</a> to analyse some data. I am following the instruction that that I received from site to install the package, with a variation (I am not sure whether it matters or not: I am using <code>py</code>, instead of <code>python</code>). The commands that I use, in the order, are:</p>
<pre class=""lang-none prettyprint-override""><code>py -m venv pyspedas
.\pyspedas\Scripts\activate
pip install pyspedas
</code></pre>
<p>After the last step, I am getting the following output:</p>
<pre class=""lang-none prettyprint-override""><code>Collecting pyspedas
  Using cached pyspedas-1.4.47-py3-none-any.whl.metadata (14 kB)
Collecting numpy&gt;=1.19.5 (from pyspedas)
  Using cached numpy-1.26.1-cp312-cp312-win_amd64.whl.metadata (61 kB)
Collecting requests (from pyspedas)
  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)
Collecting geopack&gt;=1.0.10 (from pyspedas)
  Using cached geopack-1.0.10-py3-none-any.whl (114 kB)
Collecting cdflib&lt;1.0.0 (from pyspedas)
  Using cached cdflib-0.4.9-py3-none-any.whl (72 kB)
Collecting cdasws&gt;=1.7.24 (from pyspedas)
  Using cached cdasws-1.7.43.tar.gz (21 kB)
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
  Preparing metadata (pyproject.toml) ... done
Collecting netCDF4&gt;=1.6.2 (from pyspedas)
  Using cached netCDF4-1.6.5-cp312-cp312-win_amd64.whl.metadata (1.8 kB)
Collecting pywavelets (from pyspedas)
  Using cached PyWavelets-1.4.1.tar.gz (4.6 MB)
  Installing build dependencies ... done
  Getting requirements to build wheel ... error
  error: subprocess-exited-with-error

  √ó Getting requirements to build wheel did not run successfully.
  ‚îÇ exit code: 1
  ‚ï∞‚îÄ&gt; [33 lines of output]
      Traceback (most recent call last):
        File &quot;C:\Users\UserName\pyspedas\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py&quot;, line 353, in &lt;module&gt;
          main()
        File &quot;C:\Users\UserName\pyspedas\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py&quot;, line 335, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        File &quot;C:\Users\UserName\pyspedas\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py&quot;, line 112, in get_requires_for_build_wheel
          backend = _build_backend()
                    ^^^^^^^^^^^^^^^^
        File &quot;C:\Users\UserName\pyspedas\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py&quot;, line 77, in _build_backend
          obj = import_module(mod_path)
                ^^^^^^^^^^^^^^^^^^^^^^^
        File &quot;C:\Users\UserName\AppData\Local\Programs\Python\Python312\Lib\importlib\__init__.py&quot;, line 90, in import_module
          return _bootstrap._gcd_import(name[level:], package, level)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1381, in _gcd_import
        File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1354, in _find_and_load
        File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1304, in _find_and_load_unlocked
        File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 488, in _call_with_frames_removed
        File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1381, in _gcd_import
        File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1354, in _find_and_load
        File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1325, in _find_and_load_unlocked
        File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 929, in _load_unlocked
        File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 994, in exec_module
        File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 488, in _call_with_frames_removed
        File &quot;C:\Users\UserName\AppData\Local\Temp\pip-build-env-_lgbq70y\overlay\Lib\site-packages\setuptools\__init__.py&quot;, line 16, in &lt;module&gt;
          import setuptools.version
        File &quot;C:\Users\UserName\AppData\Local\Temp\pip-build-env-_lgbq70y\overlay\Lib\site-packages\setuptools\version.py&quot;, line 1, in &lt;module&gt;
          import pkg_resources
        File &quot;C:\Users\UserName\AppData\Local\Temp\pip-build-env-_lgbq70y\overlay\Lib\site-packages\pkg_resources\__init__.py&quot;, line 2191, in &lt;module&gt;
          register_finder(pkgutil.ImpImporter, find_on_path)
                          ^^^^^^^^^^^^^^^^^^^
      AttributeError: module 'pkgutil' has no attribute 'ImpImporter'. Did you mean: 'zipimporter'?
      [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

√ó Getting requirements to build wheel did not run successfully.
‚îÇ exit code: 1
‚ï∞‚îÄ&gt; See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</code></pre>
<p>After little bit of googling, I came to know that this issues was reported at multiple places, but none for this package. I did install wheel in the new environment as mentioned in the answer <a href=""https://stackoverflow.com/a/56504270/6323020"">here</a>, but the problem still persists.</p>
<p>Instead of setting up a virtual environment, I simply executed the command <code>py -m pip install pyspedas</code>. But I am still getting the error.</p>
<p>What I could gather is that the program has an issue with</p>
<pre class=""lang-none prettyprint-override""><code>Collecting pywavelets (from pyspedas)
  Using cached PyWavelets-1.4.1.tar.gz (4.6 MB)
  Installing build dependencies ... done
</code></pre>
<p>I am using <a href=""https://en.wikipedia.org/wiki/IDLE"" rel=""noreferrer"">IDLE</a> in Windows 11.</p>
",251,"<p>Due to the removal of the long-deprecated pkgutil.ImpImporter class, the pip command may not work for <code>Python 3.12</code>.</p>
<p><strong>You just have to manually install pip for Python 3.12</strong></p>
<pre><code>python -m ensurepip --upgrade
python -m pip install --upgrade setuptools
python -m pip install &lt;module&gt;
</code></pre>
<p>In your virtual environment:</p>
<pre class=""lang-none prettyprint-override""><code>pip install --upgrade setuptools
</code></pre>
<p>Python comes with an <code>ensurepip</code>, which can install pip in a Python environment.</p>
<p><a href=""https://pip.pypa.io/en/stable/installation/"" rel=""noreferrer"">https://pip.pypa.io/en/stable/installation/</a></p>
<p>On <strong>Linux/macOS</strong> terminal:</p>
<pre class=""lang-none prettyprint-override""><code>python -m ensurepip --upgrade
</code></pre>
<p>On <strong>Windows</strong>:</p>
<pre class=""lang-none prettyprint-override""><code>py -m ensurepip --upgrade
</code></pre>
<p>also, make sure to upgrade pip:</p>
<pre><code>py -m pip install --upgrade pip
</code></pre>
<hr />
<hr />
<h1>To install numpy on Python 3.12, you must use numpy version 1.26.4</h1>
<pre><code>pip install numpy==1.26.4
</code></pre>
<p><strong><a href=""https://github.com/numpy/numpy/issues/23808#issuecomment-1722440746"" rel=""noreferrer"">https://github.com/numpy/numpy/issues/23808#issuecomment-1722440746</a></strong></p>
<hr />
<hr />
<p>for Ubuntu</p>
<pre><code>sudo apt install python3.12-dev
</code></pre>
<p>or</p>
<pre><code>python3.12 -m pip install --upgrade setuptools
</code></pre>
","python, numpy, pip, python-3.x"
Oct-23,Oct-23,"<p>Environment:</p>
<pre class=""lang-none prettyprint-override""><code>Python 3.10.11
Flask==2.2.2
</code></pre>
<p>I run my Flask backend code in docker container, with BASE Image:
<code>FROM pytorch/pytorch:2.0.1-cuda11.7-cudnn8-runtime</code></p>
<p>But when I run the pytest with version <code>pytest 7.4.2</code>,</p>
<pre class=""lang-none prettyprint-override""><code>pip install pytest
pytest
</code></pre>
<p>it raised an Error, with logs:</p>
<pre class=""lang-none prettyprint-override""><code>==================================== ERRORS ====================================
_____________ ERROR collecting tests/test_fiftyone_utils_utils.py ______________
ImportError while importing test module '/builds/kw/data-auto-analysis-toolkit-backend/tests/test_fiftyone_utils_utils.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/opt/conda/lib/python3.10/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_fiftyone_utils_utils.py:2: in &lt;module&gt;
    import daat  # noqa: F401
/opt/conda/lib/python3.10/site-packages/daat-1.0.0-py3.10.egg/daat/__init__.py:1: in &lt;module&gt;
    from daat.app import app
/opt/conda/lib/python3.10/site-packages/daat-1.0.0-py3.10.egg/daat/app/__init__.py:6: in &lt;module&gt;
    from flask import Flask, jsonify, request
/opt/conda/lib/python3.10/site-packages/flask/__init__.py:5: in &lt;module&gt;
    from .app import Flask as Flask
/opt/conda/lib/python3.10/site-packages/flask/app.py:30: in &lt;module&gt;
    from werkzeug.urls import url_quote
E   ImportError: cannot import name 'url_quote' from 'werkzeug.urls' (/opt/conda/lib/python3.10/site-packages/werkzeug/urls.py)
</code></pre>
<p>My codes works well when I directly run it with <code>python run.py</code></p>
<p><code>run.py</code> shown below</p>
<pre><code>from daat import app

app.run(host='0.0.0.0')
</code></pre>
<p>I guess it should be the pytest versions issue, because it used to work well without changing any related code, and I use <code>pip install pytest</code> without defined a specific version.</p>
<p>And my backend runs well without pytest.</p>
",318,"<p>I had the same problem. It is because <code>Werkzeug 3.0.0</code> was released and Flask doesn't specify the dependency correctly (requirements says <code>Werkzeug&gt;=2.2.0</code>). This is why, <code>Werkzeug 3.0.0</code> is still installed and <code>Flask 2.2.2</code> isn't made for <code>Werkzeug 3.0.0</code>.</p>
<p><strong>Solution</strong>: Just set a fix version for Werkzeug such as <code>Werkzeug==2.2.2</code> in your <code>requirements.txt</code> and it should work.</p>
","python, werkzeug, pytest, flask"
Oct-23,Oct-23,"<p>I have two dataframes that can both be empty, and I want to concat them.</p>
<p>Before I could just do :</p>
<pre><code>output_df= pd.concat([df1, df2])
</code></pre>
<p>But now I run into</p>
<blockquote>
<p>FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.</p>
</blockquote>
<p>An easy fix would be:</p>
<pre><code>if not df1.empty and not df2.empty:
    result_df = pd.concat([df1, df2], axis=0)
elif not df1.empty:
    result_df = df1.copy()
elif not df2.empty:
    result_df = df2.copy()
else:
    result_df = pd.DataFrame()
</code></pre>
<p>But that seems pretty ugly. Does anyone have a better solution ?</p>
<p>FYI: this appeared after pandas released <a href=""https://pandas.pydata.org/docs/whatsnew/v2.1.0.html#deprecations"" rel=""noreferrer"">v2.1.0</a></p>
",22,"<p>To be precise, <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html"" rel=""noreferrer""><code>concat</code></a> is not deprecated (and won't be IMHO) but I can trigger <a href=""https://github.com/pandas-dev/pandas/blob/a0babcb2c63dd721ea47e75f6229c5fe727b2395/pandas/core/internals/concat.py#L492"" rel=""noreferrer""><em>this</em></a> <code>FutureWarning</code> in <a href=""https://github.com/pandas-dev/pandas/releases/tag/v2.1.1"" rel=""noreferrer"">2.1.1</a> with the following example, while <code>df2</code> being an empty DataFrame with a different <a href=""https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html"" rel=""noreferrer""><code>dtypes</code></a> than <code>df1</code> :</p>
<pre><code>df1 = pd.DataFrame({&quot;A&quot;: [.1, .2, .3]})
df2 = pd.DataFrame(columns=[&quot;A&quot;], dtype=&quot;object&quot;)

out = pd.concat([df1, df2])
print(out)

     A
0  0.1
1  0.2
2  0.3
</code></pre>
<p>As a solution in your case, you can try something like you did :</p>
<pre><code>out = (df1.copy() if df2.empty else df2.copy() if df1.empty
       else pd.concat([df1, df2]) # if both DataFrames non empty
      )
</code></pre>
<p>Or maybe even this one? :</p>
<pre><code>out = pd.concat([df1.astype(df2.dtypes), df2.astype(df1.dtypes)])
</code></pre>
","python, concatenation, dataframe, pandas"
Oct-23,Oct-23,"<p>I have upgraded from <code>org.apache.poi-poi-ooxml-5.2.3</code> to <code>org.apache.poi-poi-ooxml-5.2.4</code> due to <strong>Security Violation Threat</strong> in <code>5.2.3</code></p>
<p>Now, I am facing run time exception as <code>java.lang.NoSuchMethodError</code></p>
<p><strong>Exception:</strong></p>
<pre><code>[ERROR] ErrorPageFilter - Forwarding to error page from request [/reports/myapp/myreport] due to exception ['org.apache.commons.io.output.UnsynchronizedByteArrayOutputStream$Builder org.apache.commons.io.output.UnsynchronizedByteArrayOutputStream.builder()']
java.lang.NoSuchMethodError: 'org.apache.commons.io.output.UnsynchronizedByteArrayOutputStream$Builder org.apache.commons.io.output.UnsynchronizedByteArrayOutputStream.builder()'
    at org.apache.poi.xssf.usermodel.XSSFWorkbook.newPackage(XSSFWorkbook.java:521) ~[poi-ooxml-5.2.4.jar:5.2.4]
    at org.apache.poi.xssf.usermodel.XSSFWorkbook.&lt;init&gt;(XSSFWorkbook.java:231) ~[poi-ooxml-5.2.4.jar:5.2.4]
    at org.apache.poi.xssf.usermodel.XSSFWorkbook.&lt;init&gt;(XSSFWorkbook.java:227) ~[poi-ooxml-5.2.4.jar:5.2.4]
    at org.apache.poi.xssf.usermodel.XSSFWorkbook.&lt;init&gt;(XSSFWorkbook.java:215) ~[poi-ooxml-5.2.4.jar:5.2.4]
    at myapp.reports.service.impl.MyReportsExcelExporter.&lt;init&gt;(MyReportsExcelExporter.java:37) ~[classes/:0.0.1-SNAPSHOT]
</code></pre>
<p><strong>Code:</strong></p>
<pre class=""lang-java prettyprint-override""><code>import org.apache.poi.xssf.usermodel.XSSFWorkbook;

public class MyReportsExcelExporter {
    protected XSSFWorkbook workbook;
    ...
    public MyReportsExcelExporter() {
        this.workbook = new XSSFWorkbook(); //Facing issue here, while initializing the workbook.
    }
    ...
}
</code></pre>
<p>Looking at the version change, it seems like a minor upgrade but now existing code has stopped working.</p>
<p>What's probably wrong?</p>
",35,"<p>You will need to add/upgrade <strong>Apache Commons IO</strong> dependency version <strong>&gt;= 2.12.0</strong>.</p>
<p><strong>Note:</strong> The <code>builder()</code> method present in <code>UnsynchronizedByteArrayOutputStream</code> got introduced from <strong>2.12.0</strong> version of <strong>commons-io</strong> onwards.</p>
<p>I took the latest dependency of <strong>commons-io</strong> which is <strong>2.14.0</strong> at the time of writing the answer.</p>
<p><strong>pom.xml (Maven)</strong>:</p>
<pre><code>&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;commons-io&lt;/groupId&gt;
        &lt;artifactId&gt;commons-io&lt;/artifactId&gt;
        &lt;version&gt;2.14.0&lt;/version&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
<p><strong>build.gradle (Gradle)</strong>:</p>
<pre><code>dependencies {
   implementation 'commons-io:commons-io:2.14.0'
}
</code></pre>
<p>It will work.</p>
","java, spring, apache-poi, spring-boot"
Oct-23,Oct-23,"<p>I've installed <code>scikit-fuzzy</code> but when I <code>import skfuzzy as fuzz</code> I get an error</p>
<pre><code>ModuleNotFoundError: No module named 'distutils'&quot;
</code></pre>
<p>I already tried to <code>pip uninstall distutils</code> and got this output</p>
<pre class=""lang-none prettyprint-override""><code>Note: you may need to restart the kernel to use updated packages.
WARNING: Skipping distutils as it is not installed.
</code></pre>
<p>Then I tried to install it again <code>pip install distutils</code></p>
<pre class=""lang-none prettyprint-override""><code>Note: you may need to restart the kernel to use updated packages.
ERROR: Could not find a version that satisfies the requirement distutils (from versions: none)
ERROR: No matching distribution found for distutils
</code></pre>
<p>Where did I go wrong?</p>
<hr />
<p><sub>This question addresses the problem from the perspective of <em>installing</em> a library. For <em>developing</em> a library, see <a href=""https://stackoverflow.com/questions/69858963"">How can one fully replace distutils, which is deprecated in 3.10?</a>.</sub></p>
",71,"<p>Python 3.12 does not come with a stdlib distutils module (<a href=""https://docs.python.org/3/whatsnew/3.12.html"" rel=""noreferrer"">changelog</a>), because <code>distutils</code> was deprecated in 3.10 and removed in 3.12. See <a href=""https://peps.python.org/pep-0632/"" rel=""noreferrer""><em>PEP 632 ‚Äì Deprecate distutils module</em></a>.</p>
<p>You can still use <code>distutils</code> on Python 3.12+ by installing <code>setuptools</code>.</p>
<p>When that doesn't work, you may need stay on Python &lt; 3.12 until the 3rd-party package (<code>skfuzzy</code> in this case) publishes an updated release for Python 3.12 support.</p>
","python, distutils, setuptools, skfuzzy, python-3.12"
Nov-23,Nov-23,"<p>After updating my OpenAI package to version 1.1.1, I got this error when trying to read the ChatGPT API response:</p>
<blockquote>
<p>'ChatCompletion' object is not subscriptable</p>
</blockquote>
<p>Here is my code:</p>
<pre class=""lang-py prettyprint-override""><code>messages = [
        {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: '''You answer question about some service'''
        },
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: 'The user question is ...'},
    ]
response = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=0
    )
response_message = response[&quot;choices&quot;][0][&quot;message&quot;][&quot;content&quot;]
</code></pre>
<p>How can I resolve this error?</p>
",83,"<p>In the latest OpenAI package the <code>response.choices</code> object type is changed and in this way you must read the response:</p>
<pre><code>print(response.choices[0].message.content)
</code></pre>
<p>The complete working code:</p>
<pre><code>from openai import OpenAI

client = OpenAI(api_key='YourKey')
GPT_MODEL = &quot;gpt-4-1106-preview&quot; #&quot;gpt-3.5-turbo-1106&quot;
messages = [
        {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: 'You answer question about Web  services.'
        },
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: 'the user message'},
    ]
response = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=0
    )
response_message = response.choices[0].message.content
print(response_message )
</code></pre>
<p>See <a href=""https://github.com/openai/openai-python/blob/448ac7d046d12c26064b2050f3ce82bde3a24943/README.md?plain=1#L143"" rel=""noreferrer"">this example</a> in the project README.</p>
","python, typeerror, openai-api, chatgpt-api"
Nov-23,Nov-23,"<p>I am building a new app for testing with angular 17 trying to connect to a simple API rest. I am desperate to get this to work. I have asked chat GPT, reviewed stack's older posts and even download an old application, but with no success.</p>
<p>Here is my app config and the error:</p>
<p><strong>app.module.ts</strong></p>
<pre><code>import {FormsModule, ReactiveFormsModule} from '@angular/forms';
import { BrowserModule } from '@angular/platform-browser';
import { NgModule } from '@angular/core';
import {AppComponent} from &quot;./app.component&quot;;
import {HttpClientModule} from &quot;@angular/common/http&quot;;
import {ClienteService} from &quot;./cliente.service&quot;;
import {ClienteComponent} from &quot;./cliente/cliente.component&quot;;
import {AppRoutingModule} from &quot;./app-routing.module&quot;;



@NgModule({
  declarations: [
    AppComponent,
    ClienteComponent
  ],
  imports: [
    BrowserModule,
    FormsModule,
    ReactiveFormsModule,
    HttpClientModule,
    AppRoutingModule

  ],
  providers: [ClienteService],
  bootstrap: [AppComponent]
})
export class AppModule { }
</code></pre>
<p><strong>app-routing.module.ts</strong></p>
<pre><code>
import { NgModule } from '@angular/core';
import { Routes, RouterModule } from '@angular/router';

import {ClienteComponent} from &quot;./cliente/cliente.component&quot;;

const appRoutes: Routes = [
  { path: '', redirectTo: '/clientes', pathMatch: 'full' },
  { path: 'clientes', component: ClienteComponent}
];

@NgModule({
  imports: [RouterModule.forRoot(appRoutes)],
  exports: [RouterModule]
})
export class AppRoutingModule {

}
</code></pre>
<p><strong>cliente.service.ts</strong></p>
<pre><code>import { Injectable } from '@angular/core';
import { HttpClient } from '@angular/common/http';

@Injectable({
  providedIn: 'root'
})
export class ClienteService {

  private clienteUrl: string;

  constructor(private http: HttpClient) {
    this.clienteUrl = 'http://localhost:8081/clientes';
  }
  getClientes(nombre?: string, telefono?: string, direccion?: string) {
    const params: any = { nombre, telefono, direccion };
    return this.http.get(this.clienteUrl, { params });
  }
</code></pre>
<p><strong>cliente.component.ts</strong></p>
<pre><code>import {Component, OnInit} from '@angular/core';
import { CommonModule } from '@angular/common';
import {ClienteService} from &quot;../cliente.service&quot;;

@Component({
  selector: 'app-cliente',
  standalone: true,
  imports: [CommonModule],
  templateUrl: './cliente.component.html',
  styleUrl: './cliente.component.css'
})
export class ClienteComponent implements OnInit{

  clientes: any[] = [];

  constructor(private clienteService: ClienteService) {

  }

  ngOnInit(): void {
    this.clienteService.getClientes().subscribe((clientesResponse:any) =&gt; {
      console.log('Respuesta del servicio getAllClientes',clientesResponse);
      this.clientes=clientesResponse._embedded.clientes;


    });
  }

}
</code></pre>
<p>The problem is this:</p>
<pre class=""lang-none prettyprint-override""><code>ERROR NullInjectorError: R3InjectorError(Standalone[_AppComponent])[_ClienteService -&gt; _ClienteService -&gt; _HttpClient -&gt; _HttpClient]: 
  NullInjectorError: No provider for _HttpClient!
    at NullInjector.get (core.mjs:5601:27)
    at R3Injector.get (core.mjs:6044:33)
    at R3Injector.get (core.mjs:6044:33)
    at injectInjectorOnly (core.mjs:911:40)
    at Module.…µ…µinject (core.mjs:917:42)
    at Object.ClienteService_Factory [as factory] (cliente.service.ts:7:28)
    at core.mjs:6164:43
    at runInInjectorProfilerContext (core.mjs:867:9)
    at R3Injector.hydrate (core.mjs:6163:17)
    at R3Injector.get (core.mjs:6033:33)
handleError @ core.mjs:11747
</code></pre>
",48,"<p>You are mixing Modules and Standalone Components. As of Angular 17 everything is standalone by default, unless you specify otherwise.</p>
<p>You have 2 options.</p>
<ol>
<li>Don't use stand alone components, make your components part of modules, then the import arrays in the modules should work.</li>
<li>Work without modules and make the app completely standalone. As intended from Angular 17</li>
</ol>
<p>If you started a project in angular 17, I suggest against option number one.</p>
<p>For start, go to <code>main.js</code> and add <code>provideHttpClient(withFetch())</code> to the providers array. Insted of importing HttpClientModule in your AppModule.</p>
<pre><code>bootstrapApplication(AppComponent, {
  providers: [
    provideHttpClient(withFetch()),
  ],
});
</code></pre>
<hr />
<h2>Further Explanation</h2>
<p>The new implementation for Angular 17 might seem obscure compared to the previous versions, so here's a bit more detail.</p>
<h3>Standalone Components vs. Traditional Modules</h3>
<h4>Standalone Components:</h4>
<ul>
<li><strong>Self-contained</strong>: Each component declares its own dependencies and configuration, making it easier to manage and understand.</li>
<li><strong>No Need for NgModules</strong>: You don't have to create separate module files (NgModule), which simplifies your project structure.</li>
</ul>
<h4>Traditional Modules:</h4>
<ul>
<li><strong>Grouped Configuration</strong>: Dependencies are declared in NgModule files, which group together related components, directives, and pipes.</li>
<li><strong>Imports and Declarations</strong>: You use imports and declarations arrays in NgModule to manage dependencies and components.</li>
</ul>
<h3>Implementing Standalone Components</h3>
<ul>
<li><strong>Creating Standalone Components</strong>: When generating a new component, you can specify it as standalone.</li>
</ul>
<pre><code>ng generate component my-component --standalone
</code></pre>
<ul>
<li><strong>Bootstrap Configuration</strong>: Configure your application to use standalone components directly in the main.ts file.</li>
</ul>
<pre><code>import { bootstrapApplication } from '@angular/platform-browser';
import { AppComponent } from './app/app.component';
import { provideHttpClient, withFetch } from '@angular/common/http';

bootstrapApplication(AppComponent, {
  providers: [
    provideHttpClient(withFetch()), // Configure the HttpClient here
    // Add the rest of the providers here
  ],
});
</code></pre>
<h3>Benefits of the Standalone Approach</h3>
<ul>
<li><strong>Simplified Dependency Management</strong>: Standalone components declare their own dependencies, making it easier to manage and understand the required imports and providers.</li>
<li><strong>Reduced Boilerplate</strong>: You no longer need to create and maintain NgModule files, which reduces the amount of boilerplate code in your application.</li>
<li><strong>Efficiency</strong>: Standalone components can lead to better performance by reducing the overhead associated with NgModule resolution.</li>
<li><strong>Flexibility</strong>: Standalone components are more flexible for use in different parts of your application or in other projects.</li>
<li><strong>Future-Proofing</strong>: Angular is moving towards this modular, standalone approach. Adopting it now can make future updates and migrations smoother.</li>
</ul>
","javascript, rest, angular"
Nov-23,Nov-23,"<p>I am using</p>
<ul>
<li>Windows 10</li>
<li>PyCharm 2021.3.3 Professional Edition</li>
<li>python 3.11.5</li>
<li>matplotlib 3.8.1</li>
</ul>
<p>How can I permanently resolve this issue in my development environment?</p>
<pre class=""lang-py prettyprint-override""><code>import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

# Read data from file, skipping the first row (header)
data = np.loadtxt('cm.dat', skiprows=1)

# Initialize reference point
x0, y0, z0 = data[0]

# Compute squared displacement for each time step
SD = [(x - x0)**2 + (y - y0)**2 + (z - z0)**2 for x, y, z in data]

# Compute the cumulative average of SD to get MSD at each time step
MSD = np.cumsum(SD) / np.arange(1, len(SD) + 1)

# Generate time steps
t = np.arange(1, len(SD) + 1)

# Create a log-log plot of MSD versus t
plt.figure(figsize=(8, 6))
plt.loglog(t, MSD, marker='o')

plt.title('Mean Squared Displacement vs Time')
plt.xlabel('Time step')
plt.ylabel('MSD')
plt.grid(True, which=&quot;both&quot;, ls=&quot;--&quot;)
plt.show()
</code></pre>
<pre><code>C:\Users\pc\AppData\Local\Programs\Python\Python311\python.exe C:/git/RouseModel/tau_plot.py
C:\git\RouseModel\tau_plot.py:29: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown
  plt.show()

Process finished with exit code 0

</code></pre>
",59,"<p>I have the same issue. In my case, I installed the PyQt5==5.15.10. After that, I run my code successfully.</p>
<p><code>pip install PyQt5==5.15.10</code> or <code>pip install PyQt5</code> with <code>python==3.11</code></p>
<p>But from 2024, you guys should install version <code>PyQt6</code> or the last version with <code>python==3.12</code> or later.</p>
","python, matplotlib, pycharm"
Nov-23,Nov-23,"<p>I have downloaded with npm the new version of Angular and I haven't seen the <em>app.module.ts</em> file.</p>
<p>Has it been eliminated from the project structure?</p>
<p><img src=""https://i.sstatic.net/4CpjW.png"" alt=""Visual Studio Code files"" />.</p>
<p>I have tried creating a new one. It seems odd.</p>
",173,"<p>From Angular v17 onwards, Standalone is now the new default for the CLI.</p>
<p>So when you create a new project, you won't have any modules in it if you don't specify anything.</p>
<p>However, it is still possible to create a module-based app by using the <code>--no-standalone</code> flag :</p>
<pre class=""lang-bash prettyprint-override""><code>ng new --no-standalone
</code></pre>
<p>Standalone components are a feature introduced in v14. With the change in v17, the Angular team <a href=""https://blog.angular.io/introducing-angular-v17-4d7033312e4b#586d"" rel=""noreferrer"">strongly recommends to use them</a> as they are easier to use, understand and are require less boilerplate.</p>
<p>For tutorials using standalone components, I advise you to get a look at <a href=""https://angular.dev"" rel=""noreferrer"">the new documentation site</a>.</p>
","javascript, typescript, angular"
Nov-23,Nov-23,"<p>This is disassembly of a list comprehension in <a href=""/questions/tagged/python-3.10"" class=""post-tag"" title=""show questions tagged &#39;python-3.10&#39;"" aria-label=""show questions tagged &#39;python-3.10&#39;"" rel=""tag"" aria-labelledby=""tag-python-3.10-tooltip-container"">python-3.10</a>:</p>
<pre class=""lang-py prettyprint-override""><code>Python 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0] on linux
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt; import dis
&gt;&gt;&gt; 
&gt;&gt;&gt; dis.dis(&quot;[True for _ in ()]&quot;)
  1           0 LOAD_CONST               0 (&lt;code object &lt;listcomp&gt; at 0x7fea68e0dc60, file &quot;&lt;dis&gt;&quot;, line 1&gt;)
              2 LOAD_CONST               1 ('&lt;listcomp&gt;')
              4 MAKE_FUNCTION            0
              6 LOAD_CONST               2 (())
              8 GET_ITER
             10 CALL_FUNCTION            1
             12 RETURN_VALUE

Disassembly of &lt;code object &lt;listcomp&gt; at 0x7fea68e0dc60, file &quot;&lt;dis&gt;&quot;, line 1&gt;:
  1           0 BUILD_LIST               0
              2 LOAD_FAST                0 (.0)
        &gt;&gt;    4 FOR_ITER                 4 (to 14)
              6 STORE_FAST               1 (_)
              8 LOAD_CONST               0 (True)
             10 LIST_APPEND              2
             12 JUMP_ABSOLUTE            2 (to 4)
        &gt;&gt;   14 RETURN_VALUE
</code></pre>
<p>From what I understand it creates a code object called <code>listcomp</code> which does the actual iteration and return the result list, and immediately call it.
I can't figure out the need to create a separate function to execute this job. Is this kind of an optimization trick?</p>
",67,"<p>The main logic of creating a function is to <a href=""https://peps.python.org/pep-0709/"" rel=""nofollow noreferrer"">isolate the comprehension‚Äôs iteration variable</a><sup>peps.python.org</sup>.</p>
<p>By creating a function,</p>
<blockquote>
<p>Comprehension iteration variables remain <strong>isolated</strong> and <strong>don‚Äôt overwrite</strong>
a variable of the same name in the outer scope, nor are they visible
after the comprehension</p>
</blockquote>
<p>However, this is <em>inefficient at runtime</em>. Due to this reason, <a href=""/questions/tagged/python-3.12"" class=""s-tag post-tag"" title=""show questions tagged &#39;python-3.12&#39;"" aria-label=""show questions tagged &#39;python-3.12&#39;"" rel=""tag"" aria-labelledby=""tag-python-3.12-tooltip-container"" data-tag-menu-origin=""Unknown"">python-3.12</a> implemented an optimization called <a href=""https://docs.python.org/3/whatsnew/3.12.html#pep-709-comprehension-inlining"" rel=""nofollow noreferrer"">comprehension inlining(PEP 709)</a><sup>peps.python.org</sup> which will no longer <a href=""https://peps.python.org/pep-0709/#specification"" rel=""nofollow noreferrer"">create a separate code object</a><sup>peps.python.org</sup>.</p>
<blockquote>
<p>Dictionary, list, and set comprehensions are now inlined, <strong>rather than
creating a new single-use function object for each execution of the
comprehension.</strong> This <strong>speeds up execution of a comprehension by up to
two times</strong>. See <em>PEP 709</em> for further details.</p>
</blockquote>
<p>Here is the output for the same code disassembled with <a href=""/questions/tagged/python-3.12"" class=""s-tag post-tag"" title=""show questions tagged &#39;python-3.12&#39;"" aria-label=""show questions tagged &#39;python-3.12&#39;"" rel=""tag"" aria-labelledby=""tag-python-3.12-tooltip-container"" data-tag-menu-origin=""Unknown"">python-3.12</a>:</p>
<pre><code>>>> import dis
>>> dis.dis(""[True for _ in ()]"")
  0           0 RESUME                   0

  1           2 LOAD_CONST               0 (())
              4 GET_ITER
              6 <b>LOAD_FAST_AND_CLEAR</b>      0 (_)
              8 SWAP                     2
             10 BUILD_LIST               0
             12 SWAP                     2
        >>   14 FOR_ITER                 4 (to 26)
             18 STORE_FAST               0 (_)
             20 LOAD_CONST               1 (True)
             22 LIST_APPEND              2
             24 JUMP_BACKWARD            6 (to 14)
        >>   26 END_FOR
             28 SWAP                     2
             30 <b>STORE_FAST</b>               0 (_)
             32 RETURN_VALUE
        >>   34 SWAP                     2
             36 POP_TOP
             38 SWAP                     2
             40 STORE_FAST               0 (_)
             42 RERAISE                  0
ExceptionTable:
  10 to 26 -> 34 [2]</code></pre>
<p>As you can see, there is no longer a <code>MAKE_FUNCTION</code> opcode nor a separate <em>code object.</em> Instead <a href=""/questions/tagged/python-3.12"" class=""s-tag post-tag"" title=""show questions tagged &#39;python-3.12&#39;"" aria-label=""show questions tagged &#39;python-3.12&#39;"" rel=""tag"" aria-labelledby=""tag-python-3.12-tooltip-container"" data-tag-menu-origin=""Unknown"">python-3.12</a> uses <a href=""https://docs.python.org/3/library/dis.html#opcode-LOAD_FAST_AND_CLEAR"" rel=""nofollow noreferrer""><code>LOAD_FAST_AND_CLEAR</code></a><sup>docs.python.org</sup>(at offset <code>6</code>) and <code>STORE_FAST</code>(at offset <code>30</code>) opcodes to provide the isolation for the iteration variable.</p>
<p>Quoting from the <a href=""https://peps.python.org/pep-0709/#specification"" rel=""nofollow noreferrer""><em>Specification</em> section</a><sup>peps.python.org</sup> of the PEP 709:</p>
<blockquote>
<p>Isolation of the <code>x</code> iteration variable is achieved by the combination
of the new <code>LOAD_FAST_AND_CLEAR</code> opcode at offset <code>6</code>, which saves any
outer value of <code>x</code> on the stack before running the comprehension, and <code>30</code>
<code>STORE_FAST</code>, which restores the outer value of <code>x</code> (if any) after running
the comprehension.</p>
</blockquote>
<p>In addition to that, in <a href=""/questions/tagged/python-3.12"" class=""s-tag post-tag"" title=""show questions tagged &#39;python-3.12&#39;"" aria-label=""show questions tagged &#39;python-3.12&#39;"" rel=""tag"" aria-labelledby=""tag-python-3.12-tooltip-container"" data-tag-menu-origin=""Unknown"">python-3.12</a> <a href=""https://docs.python.org/3/whatsnew/3.12.html#pep-709-comprehension-inlining"" rel=""nofollow noreferrer""><em>there is no longer a <strong>separate frame</strong> for the comprehension in tracebacks</em></a>.</p>
<div class=""s-table-container""><table class=""s-table"">
<thead>
<tr>
<th>Traceback in &lt;<a href=""/questions/tagged/python-3.12"" class=""s-tag post-tag"" title=""show questions tagged &#39;python-3.12&#39;"" aria-label=""show questions tagged &#39;python-3.12&#39;"" rel=""tag"" aria-labelledby=""tag-python-3.12-tooltip-container"" data-tag-menu-origin=""Unknown"">python-3.12</a></th>
<th>Traceback in <a href=""/questions/tagged/python-3.12"" class=""s-tag post-tag"" title=""show questions tagged &#39;python-3.12&#39;"" aria-label=""show questions tagged &#39;python-3.12&#39;"" rel=""tag"" aria-labelledby=""tag-python-3.12-tooltip-container"" data-tag-menu-origin=""Unknown"">python-3.12</a></th>
</tr>
</thead>
<tbody>
<tr>
<td><pre><code>&gt;&gt;&gt; [1 / 0 for i in range(10)]<br>Traceback (most recent call last):<br> File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;<br> <i>File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;listcomp&gt;</i><br>ZeroDivisionError: division by zero</code></pre></td>
<td><pre><code>&gt;&gt;&gt; [1 / 0 for i in range(10)]<br>Traceback (most recent call last):<br> File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;<br>ZeroDivisionError: division by zero</code></pre></td>
</tr>
</tbody>
</table></div>
<p>And here is the <a href=""https://peps.python.org/pep-0709/#reference-implementation"" rel=""nofollow noreferrer"">benchmark results</a><sup>peps.python.org</sup>(measured with MacOS M2):</p>
<pre><code>$ python3.10 -m pyperf timeit -s 'l = [1]' '[x for x in l]'
Mean +- std dev: 108 ns +- 3 ns
$ python3.12 -m pyperf timeit -s 'l = [1]' '[x for x in l]'
Mean +- std dev: 60.9 ns +- 0.3 ns
</code></pre>
","python, cpython, list-comprehension, python-internals, dis"
Dec-23,Dec-23,"<p>Called with <code>n = 10**8</code>, the simple loop is consistently significantly slower for me than the complex one, and I don't see why:</p>
<pre><code>def simple(n):
    while n:
        n -= 1

def complex(n):
    while True:
        if not n:
            break
        n -= 1
</code></pre>
<p>Some times in seconds:</p>
<pre class=""lang-none prettyprint-override""><code>simple 4.340795516967773
complex 3.6490490436553955
simple 4.374553918838501
complex 3.639145851135254
simple 4.336690425872803
complex 3.624480724334717
Python: 3.11.4 (main, Sep  9 2023, 15:09:21) [GCC 13.2.1 20230801]
</code></pre>
<p>Here's the looping part of the bytecode as shown by <code>dis.dis(simple)</code>:</p>
<pre><code>  6     &gt;&gt;    6 LOAD_FAST                0 (n)
              8 LOAD_CONST               1 (1)
             10 BINARY_OP               23 (-=)
             14 STORE_FAST               0 (n)

  5          16 LOAD_FAST                0 (n)
             18 POP_JUMP_BACKWARD_IF_TRUE     7 (to 6)
</code></pre>
<p>And for <code>complex</code>:</p>
<pre><code> 10     &gt;&gt;    4 LOAD_FAST                0 (n)
              6 POP_JUMP_FORWARD_IF_TRUE     2 (to 12)

 11           8 LOAD_CONST               0 (None)
             10 RETURN_VALUE

 12     &gt;&gt;   12 LOAD_FAST                0 (n)
             14 LOAD_CONST               2 (1)
             16 BINARY_OP               23 (-=)
             20 STORE_FAST               0 (n)

  9          22 JUMP_BACKWARD           10 (to 4)
</code></pre>
<p>So it looks like the complex one does more work per iteration (two jumps instead of one). Then why is it faster?</p>
<p>Seems to be a Python 3.11 phenomenon, see the comments.</p>
<p>Benchmark script (<a href=""https://ato.pxeger.com/run?1=ZZBBDoIwEEXjtocws6MQIBI3hIQ7uHBnTIPahkaYklJUzuKGjR7K0wgUotG_mt--_E7__Vm1JlfYdY_GiCB-LZZCqxKMLDnIslLajDOZ5rqtCTlxAXV_UHCKbkKg1zWXBQe0ZhBCkEJk2aMa2NsPvNUN__BSACrznTDooHl2_ssUSoMAibCzW_jzC3vwYG0TDKTj4tQdraDRyvNiayot0VARMoZZyRnzJxICMC4h9trZjMUkjj98OrxwXUuFrq1pamtu7Q0"" rel=""noreferrer"">Attempt This Online!</a>):</p>
<pre class=""lang-py prettyprint-override""><code>from time import time
import sys

def simple(n):
    while n:
        n -= 1

def complex(n):
    while True:
        if not n:
            break
        n -= 1

for f in [simple, complex] * 3:
    t = time()
    f(10**8)
    print(f.__name__, time() - t)

print('Python:', sys.version)
</code></pre>
",66,"<p>I checked the source code of the bytecode (python 3.11.6) and found that in the decompiled bytecode, it seems that only <code>JUMP_BACKWARD</code> will execute a warmup function, which will trigger <a href=""https://docs.python.org/3.11/whatsnew/3.11.html#pep-659-specializing-adaptive-interpreter"" rel=""noreferrer"">specialization</a> in python 3.11 when executed enough times:</p>
<pre class=""lang-c prettyprint-override""><code>PyObject* _Py_HOT_FUNCTION
_PyEval_EvalFrameDefault(PyThreadState *tstate, _PyInterpreterFrame *frame, int throwflag)
{
    /* ... */
        TARGET(JUMP_BACKWARD) {
            _PyCode_Warmup(frame-&gt;f_code);
            JUMP_TO_INSTRUCTION(JUMP_BACKWARD_QUICK);
        }
    /* ... */
}
</code></pre>
<pre class=""lang-c prettyprint-override""><code>static inline void
_PyCode_Warmup(PyCodeObject *code)
{
    if (code-&gt;co_warmup != 0) {
        code-&gt;co_warmup++;
        if (code-&gt;co_warmup == 0) {
            _PyCode_Quicken(code);
        }
    }
}
</code></pre>
<p><sub>Among <strong>all</strong> bytecodes, only <code>JUMP_BACKWARD</code> and <code>RESUME</code> will call <code>_PyCode_Warmup()</code>.</sub></p>
<p>Specialization appears to speed up multiple bytecodes used, resulting in a significant increase in speed:</p>
<pre class=""lang-c prettyprint-override""><code>void
_PyCode_Quicken(PyCodeObject *code)
{
    /* ... */
            switch (opcode) {
                case EXTENDED_ARG:  /* ... */
                case JUMP_BACKWARD: /* ... */
                case RESUME:        /* ... */
                case LOAD_FAST:     /* ... */
                case STORE_FAST:    /* ... */
                case LOAD_CONST:    /* ... */
            }
    /* ... */
}
</code></pre>
<p>After executing once, the bytecode of <code>complex</code> changed, while <code>simple</code> did not:</p>
<pre><code>In [_]: %timeit -n 1 -r 1 complex(10 ** 8)
2.7 s ¬± 0 ns per loop (mean ¬± std. dev. of 1 run, 1 loop each)

In [_]: dis(complex, adaptive=True)
  5           0 RESUME_QUICK             0

  6           2 NOP

  7           4 LOAD_FAST                0 (n)
              6 POP_JUMP_FORWARD_IF_TRUE     2 (to 12)

  8           8 LOAD_CONST               0 (None)
             10 RETURN_VALUE

  9     &gt;&gt;   12 LOAD_FAST__LOAD_CONST     0 (n)
             14 LOAD_CONST               2 (1)
             16 BINARY_OP_SUBTRACT_INT    23 (-=)
             20 STORE_FAST               0 (n)

  6          22 JUMP_BACKWARD_QUICK     10 (to 4)

</code></pre>
<pre><code>In [_]: %timeit -n 1 -r 1 simple(10 ** 8)
4.78 s ¬± 0 ns per loop (mean ¬± std. dev. of 1 run, 1 loop each)

In [_]: dis(simple, adaptive=True)
  1           0 RESUME                   0

  2           2 LOAD_FAST                0 (n)
              4 POP_JUMP_FORWARD_IF_FALSE     9 (to 24)

  3     &gt;&gt;    6 LOAD_FAST                0 (n)
              8 LOAD_CONST               1 (1)
             10 BINARY_OP               23 (-=)
             14 STORE_FAST               0 (n)

  2          16 LOAD_FAST                0 (n)
             18 POP_JUMP_BACKWARD_IF_TRUE     7 (to 6)
             20 LOAD_CONST               0 (None)
             22 RETURN_VALUE
        &gt;&gt;   24 LOAD_CONST               0 (None)
             26 RETURN_VALUE

</code></pre>
","python, performance, cpython, python-internals, python-3.11"
Dec-23,Dec-23,"<p>I am running on Node.js v18.17.1 and TypeScript v5.</p>
<p>I heard about the new JavaScript method <a href=""https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/groupBy"" rel=""nofollow noreferrer""><code>Object.groupBy()</code></a>.</p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"" data-babel-preset-react=""false"" data-babel-preset-ts=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>const inventory = [
  { name: ""asparagus"", type: ""vegetables"", quantity: 5 },
  { name: ""bananas"", type: ""fruit"", quantity: 0 },
  { name: ""goat"", type: ""meat"", quantity: 23 },
  { name: ""cherries"", type: ""fruit"", quantity: 5 },
  { name: ""fish"", type: ""meat"", quantity: 22 },
];

const result = Object.groupBy(inventory, ({ type }) =&gt; type);
console.log(result)</code></pre>
</div>
</div>
</p>
<p>When I write in my code <code>Object.groupBy()</code>, I get the following TypeScript error:</p>
<pre><code>Property 'groupBy' does not exist on type 'ObjectConstructor'.ts(2339)
</code></pre>
<p>I have the following TypeScript configuration:</p>
<pre class=""lang-json prettyprint-override""><code> &quot;compilerOptions&quot;: {
    &quot;target&quot;: &quot;es5&quot;,
    &quot;lib&quot;: [&quot;dom&quot;, &quot;dom.iterable&quot;, &quot;esnext&quot;],
    // ... etc
</code></pre>
<p>How can I enable <code>Object.groupBy()</code> so that I can use it in my code?</p>
",13,"<p>Here is the PR to enable it: <a href=""https://github.com/microsoft/TypeScript/pull/56805"" rel=""noreferrer"">https://github.com/microsoft/TypeScript/pull/56805</a>. It's in state Open at the moment. Hopefully will be merged soon.</p>
<p>Before it merged you can use a workaround adding these extension interfaces in your project:</p>
<pre><code>/// {projectSrcRoot}/groupBy.d.ts

interface ObjectConstructor {
    /**
     * Groups members of an iterable according to the return value of the passed callback.
     * @param items An iterable.
     * @param keySelector A callback which will be invoked for each item in items.
     */
    groupBy&lt;K extends PropertyKey, T&gt;(
        items: Iterable&lt;T&gt;,
        keySelector: (item: T, index: number) =&gt; K,
    ): Partial&lt;Record&lt;K, T[]&gt;&gt;;
}

interface MapConstructor {
    /**
     * Groups members of an iterable according to the return value of the passed callback.
     * @param items An iterable.
     * @param keySelector A callback which will be invoked for each item in items.
     */
    groupBy&lt;K, T&gt;(
        items: Iterable&lt;T&gt;,
        keySelector: (item: T, index: number) =&gt; K,
    ): Map&lt;K, T[]&gt;;
}

const basic = Object.groupBy([0, 2, 8], x =&gt; x &lt; 5 ? 'small' : 'large');
</code></pre>
","javascript, node.js, typescript"
Dec-23,Dec-23,"<p>I have written the code:</p>
<pre><code>int x = 18;
x *= 0.90; 
System.out.println(x);
</code></pre>
<p>This code printed <code>16</code></p>
<p>However, when I wrote</p>
<pre><code>int x = 18;
x = x * 0.90; 
System.out.println(x);
</code></pre>
<p>it gave me the following error: <code>incompatible types: possible lossy conversion from double to int </code></p>
<p>I expected both of these code examples to result in the exact same error as <code>x *= y;</code> is the same as <code>x = x * y;</code>, but <code>x *= 0.90;</code> somehow works and <code>x = x * 0.90;</code> does not. Why is this the case?</p>
",30,"<p>Because the Java Language Specifcation (JLS) says so. It's a bit odd, but, when using the compound assignment operators (<code>*=</code>, <code>+=</code>, etcetera), the cast is implied.</p>
<p>See <a href=""https://docs.oracle.com/javase/specs/jls/se8/html/jls-15.html#jls-15.26.2"" rel=""noreferrer"">JLS ¬ß15.26.2</a> which clearly shows the cast in the example right at the top of that section.</p>
<p>Why does it do that? Well, I don't think SO is the right place to ask 'what were the designers thinking 30 years ago when this part of the JLS spec was written up'.</p>
<p>EDIT: This answer used to mention 'probably because of C' but as comments show, no, in C neither form requires an explicit cast.</p>
","java, double, integer, multiplication, assignment-operator"
Dec-23,Dec-23,"<p>Is it possible to get the code object of top level code within a module? For example, if you have a python file like this:</p>
<pre><code>myvar = 1
print('hello from top level')

def myfunction():
    print('hello from function')
</code></pre>
<p>and you want to access the code object for <code>myfunction</code>, then you can use <code>myfunction.__code__</code>. For example, <code>myfunction.__code__.co_consts</code> will contain the string <code>'hello from function'</code> etc...</p>
<p>Is there a way to get the code object for the top level code? That is, for the code:</p>
<pre class=""lang-py prettyprint-override""><code>myvar = 1

print('hello from top level')
</code></pre>
<p>I would like something like <code>__main__.__code__.co_consts</code> that will contain <code>'hello from top level'</code>, but I cannot find any way to get this. Does such a thing exist?</p>
",19,"<p>The code that is executed at the top level of a module is not directly accessible as a code object in the same way that functions' code objects are,  because the top-level code is executed immediately when the module is imported or run, and it doesn't exist as a separate entity like a function does.</p>
<p>But when Python runs a script, it compiles it first to bytecode and stores it in a code object. The top-level code (<code>__main__</code> module), have a code object, but it is not directly exposed, so you need to use <code>inspect</code> module to dig deeper:</p>
<pre class=""lang-py prettyprint-override""><code>import inspect

def get_top_level_code_object():
    frame = inspect.currentframe()

    # Go back to the top-level frame
    while frame.f_back:
        frame = frame.f_back

    # The code object is stored in f_code
    return frame.f_code

if __name__ == &quot;__main__&quot;:
    top_level_code_obj = get_top_level_code_object()
    print(top_level_code_obj.co_consts) 
</code></pre>
<p>would yield</p>
<pre><code>(0, None, &lt;code object get_top_level_code_object at 0x7f970ad658f0, file &quot;/tmp/test.py&quot;, line 3&gt;, '__main__')
</code></pre>
","python, toplevel"
Dec-23,Dec-23,"<pre><code>Method Not Allowed (GET): /users/logout/
Method Not Allowed: /users/logout/
[10/Dec/2023 12:46:21] &quot;GET /users/logout/ HTTP/1.1&quot; 405 0
</code></pre>
<p>This is happening when I went to url <a href=""http://127.0.0.1:8000/users/logout/"" rel=""noreferrer"">http://127.0.0.1:8000/users/logout/</a></p>
<p><code>urls.py:</code></p>
<pre><code>from django.contrib.auth import views as auth_views

urlpatterns = [
    ...other urls...
    path('users/logout/', auth_views.LogoutView.as_view(), name='logout'),
]
</code></pre>
<p>I am expecting user to logout</p>
",19,"<p>Since <a href=""/questions/tagged/django-5"" class=""s-tag post-tag"" title=""show questions tagged &#39;django-5&#39;"" aria-label=""show questions tagged &#39;django-5&#39;"" rel=""tag"" aria-labelledby=""tag-django-5-tooltip-container"" data-tag-menu-origin=""Unknown"">django-5</a>, you need to do this through a <strong>POST request</strong>, since it has side-effects. The fact that it worked with a GET request was (likely) a violation of the HTTP protocol: it made it possible for certain scripts to log out users, without the user wanting to. So a POST request also protects against <a href=""https://en.wikipedia.org/wiki/Cross-site_request_forgery"" rel=""noreferrer""><em>cross-site request forgery (CSRF)</em>¬†<sup>[wiki]</sup></a>.</p>
<p>So in the template, work with a mini-form:</p>
<pre><code>&lt;form method=&quot;post&quot; action=&quot;{% url 'logout' %}&quot;&gt;
    {% csrf_token %}
    &lt;button type=&quot;submit&quot;&gt;logout&lt;/button&gt;
&lt;/form&gt;
</code></pre>
<p>Also note that Django's <a href=""https://docs.djangoproject.com/en/stable/topics/auth/default/#django.contrib.auth.views.LogoutView"" rel=""noreferrer""><strong><code>LogoutView</code></strong>¬†<sup>[Django-doc]</sup></a> does <em>not</em> render a page: it only works with a POST request that logs out the user that is making the request, and redirect to the page provided by the <code>?next_page=‚Ä¶</code> parameter, or if such parameter is absent with <a href=""https://docs.djangoproject.com/en/stable/ref/settings/#logout-redirect-url"" rel=""noreferrer""><strong><code>LOGOUT_REDIRECT_URL</code></strong>¬†<sup>[Django-doc]</sup></a>. <em>Visiting</em> the page will thus <em>not</em> work and return a <em>405 Method Not Allowed</em>.</p>
<p>If you thus want to make a page to logout, you add an extra view:</p>
<pre class=""lang-py prettyprint-override""><code>from django.views.generic import TemplateView

urlpatterns = [
    # &hellip;,
    path(
        'do-logout/',
        TemplateView.as_view(template_name='<em>my_template.html</em>'),
        name='do-logout',
    )
]</code></pre>
<p>where the <em><code>my_template.html</code></em> then thus contains such miniform. You can thus visit <code>/do-logout/</code> (or use another path) to render a page with a miniform to log out.</p>
","python, django, django-authentication, python-3.x"
Jan-24,Jan-24,"<p>I'm looking for the recommended way to select an individual row of a <code>polars.DataFrame</code> by row number: something largely equivalent to <code>pandas.DataFrame</code>'s <code>.iloc[[n]]</code> method for a given integer <code>n</code>.</p>
<p>For polars imported as <code>pl</code> and a polars DataFrame <code>df</code>, my current approach would be:</p>
<pre class=""lang-py prettyprint-override""><code># for example
n = 3

# create row index, filter for individual row, drop the row index.
new_df = (
    df.with_row_index()
    .filter(pl.col('index') == n)
    .select(pl.exclude('index'))
)
</code></pre>
<p>I'm migrating from Pandas, and I've read the Pandas-to-Polars <a href=""https://docs.pola.rs/user-guide/migration/pandas/"" rel=""nofollow noreferrer"">migration guide</a>, but a slick solution to this specific case wasn't addressed there. <em>Edit: to clarify, I am looking for an approach that returns a <code>polars.DataFrame</code> object for the chosen row.</em></p>
<p>Does anyone have something slicker?</p>
",16,"<p>This is a very good sheet by: @Liam Brannigan</p>
<p>Credit to them.</p>
<p><strong><a href=""https://www.rhosignal.com/posts/polars-pandas-cheatsheet/"" rel=""noreferrer"">https://www.rhosignal.com/posts/polars-pandas-cheatsheet/</a></strong></p>
<p>A glimse from the sheet:</p>
<p><a href=""https://i.sstatic.net/tKDRO.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/tKDRO.png"" alt=""enter image description here"" /></a></p>
<p><strong>You can find other information related to Filtering Rows using <code>iloc</code> and its equivalent in polars in the sheet.</strong></p>
<p><a href=""https://i.sstatic.net/jsY3g.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/jsY3g.png"" alt=""enter image description here"" /></a></p>
","python, dataframe, python-3.x, pandas, python-polars"
Jan-24,Jan-24,"<p>I'm struggling to show an image from Google Drive on my HTML page using JavaScript. Following online guides hasn't quite solved it for me.</p>
<p><strong>HTML (index.html):</strong></p>
<pre class=""lang-html prettyprint-override""><code>&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;
&lt;head&gt;
  &lt;meta charset=&quot;UTF-8&quot;&gt;
  &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
  &lt;title&gt;Google Drive Image&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;img id=&quot;imageElement&quot; alt=&quot;A lovely image&quot;&gt;
  &lt;script src=&quot;script.js&quot;&gt;&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p><strong>JavaScript (script.js):</strong></p>
<pre class=""lang-js prettyprint-override""><code>const fileId = '1BEW9tkgVKlp_ebUc17LkXDH-mnPc4ome';
const imageElement = document.getElementById('imageElement');

async function fetchGoogleDriveImage(fileId) {
  try {
    const response = await fetch(`https://drive.google.com/uc?id=${fileId}`);
    const url = URL.createObjectURL(await response.blob());
    imageElement.src = url;
  } catch (error) {
    console.error('Error fetching the image:', error);
  }
}

fetchGoogleDriveImage(fileId);
</code></pre>
<p><strong>Context:</strong></p>
<ul>
<li>Image in Google Drive is set to &quot;Anyone with the link can view.&quot;</li>
<li>Despite that, the image doesn't load in the browser, and the console shows an error.</li>
</ul>
<p><strong>Additional HTML (with pure html):</strong></p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;body&gt;
  &lt;img src=""https://drive.google.com/uc?id=1BEW9tkgVKlp_ebUc17LkXDH-mnPc4ome"" alt=""Your Image Alt Text""&gt;
&lt;/body&gt;</code></pre>
</div>
</div>
</p>
<p><strong><a href=""https://codepen.io/raulpenate/pen/NWJRmaN"" rel=""noreferrer"">CodePen Example</a></strong></p>
<p>Any help is appreciated! Thanks.</p>
",2,"<p><em><strong>Official Google dev team final decision:</strong></em></p>
<p><strong>Source:</strong> <a href=""https://issuetracker.google.com/issues/319531488#comment175"" rel=""nofollow noreferrer"">Google Issue Tracker - Comment #175</a></p>
<blockquote>
<p><strong>Status:</strong> Won't Fix (Intended Behavior)</p>
<p>Closing this issue as working as intended. I tried to buy some more time with the team owning this to no avail. Some points:</p>
<ul>
<li>Related to phase out of third party cookies. <a href=""https://workspaceupdates.googleblog.com/2023/10/upcoming-changes-to-third-party-cookies-in-google-drive.htm"" rel=""nofollow noreferrer"">October 2023 Blog Post</a></li>
<li>This was never an officially supported usage. (Same for <code>lh3.google.com</code>, thumbnail links mentioned above, etc)</li>
</ul>
<p><strong>Options going forward:</strong></p>
<ol>
<li>Use the embed pattern described in the above blog post or <a href=""https://justin.poehnelt.com/posts/google-drive-embed-images-403"" rel=""nofollow noreferrer"">here</a></li>
<li>Move files to a location designed for hosting, e.g., Google Cloud Storage or any number of hosting providers for static content</li>
<li>Proxy the files through the Google Drive API using your own infrastructure, e.g., Google Cloud Functions. Watch out for egress costs and hot linking; probably want a CDN too</li>
<li>Use a hosted proxy service as mentioned above</li>
</ol>
</blockquote>
","html, javascript, image"
Jan-24,Jan-24,"<p>The following code snippet runs without error in Java 8.  However, when I run the same code in Java 17 it fails.</p>
<pre class=""lang-java prettyprint-override""><code>import java.time.OffsetDateTime;
import java.time.format.DateTimeFormatter;

public class Main2 {
    public static void main(String[] args) {
DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd'T'HH[:mm[:ss[.SSS]]]X&quot;);
        OffsetDateTime offSetDateTime = OffsetDateTime.parse(&quot;2021-10-09T08:59:00.00Z&quot;, formatter);
        System.out.println(offSetDateTime);
    }
}
</code></pre>
<p>Output when run on Java 17:</p>
<pre class=""lang-none prettyprint-override""><code>Exception in thread &quot;main&quot; java.time.format.DateTimeParseException: Text '2021-10-09T08:59:00.00Z' could not be parsed at index 19
    at java.base/java.time.format.DateTimeFormatter.parseResolved0(DateTimeFormatter.java:2052)
    at java.base/java.time.format.DateTimeFormatter.parse(DateTimeFormatter.java:1954)
    at java.base/java.time.OffsetDateTime.parse(OffsetDateTime.java:404)
    at Main2.main(Main2.java:9)
</code></pre>
<p>However, if I run the same code against Java 8 it gives the following result:</p>
<pre class=""lang-none prettyprint-override""><code>2021-10-09T08:59Z
</code></pre>
<p>If I change the test data from <code>&quot;2021-10-09T08:59:00.00Z&quot;</code> to <code>&quot;2021-10-09T08:59:00.000Z&quot;</code>, it works in Java 17.  Any idea what changes in Java 17 has causes it it fail?</p>
",10,"<p>This behaviour seems to be caused by the fix for <a href=""https://bugs.openjdk.org/browse/JDK-8230136"" rel=""noreferrer"">JDK-8230136</a>.</p>
<p>JDK-8230136 is the issue that the fraction-of-second field does not check its minimum width. If you do <code>appendFraction(NANO_OF_SECOND, 3, 3, false)</code> in a <code>DateTimeFormatterBuilder</code>, 1, 2, or 3 digits will all be accepted by that field.</p>
<p><code>DateTimeFormatter</code> uses <code>DateTimeFormatterBuilder</code> under the hood, and so it is also affected. The <code>SSS</code> in your pattern eventually leads to a call like <code>appendFraction(NANO_OF_SECOND, 3, 3, false)</code> on a <code>DateTimeFormatterBuilder</code>.</p>
<p>If you need the old behaviour, you can call <code>appendFraction</code> with your own minimum digit count.</p>
<pre><code>DateTimeFormatter formatter = new DateTimeFormatterBuilder()
        .appendPattern(&quot;yyyy-MM-dd'T'HH[:mm[:ss[&quot;)
        .appendFraction(ChronoField.NANO_OF_SECOND, 1, 3, true)
        .appendPattern(&quot;]]]X&quot;)
        .toFormatter();
</code></pre>
","java, java-8, java-time, java-17"
Jan-24,Jan-24,"<p>Trying ruff for the first time and I'm not being able to sort imports alphabetically, using default settings. According to docs ruff should be very similar to isort.</p>
<p>Here is a short example with unsorted imports</p>
<pre><code>import os
import collections
</code></pre>
<p>Run ruff command</p>
<pre><code>$ ruff format file.py
1 file left unchanged
</code></pre>
<p>But if I run isort the imports are properly sorted</p>
<pre><code>$ isort file.py 
Fixing .../file.py
</code></pre>
<p>What am I doing wrong?</p>
",16,"<p>According to <a href=""https://github.com/astral-sh/ruff/issues/8926#issuecomment-1834048218"" rel=""noreferrer"">https://github.com/astral-sh/ruff/issues/8926#issuecomment-1834048218</a>:</p>
<blockquote>
<p>In Ruff, import sorting and re-categorization is part of the linter, not the formatter. The formatter will re-format imports, but it won't rearrange or regroup them, because the formatter maintains the invariant that it doesn't modify the program's AST (i.e., its semantics and behavior).</p>
<p>To get isort-like behavior, you'd want to run <code>ruff check --fix</code> with <code>--select I</code> or adding <code>extend-select = [&quot;I&quot;]</code> to your <code>pyproject.toml</code> or <code>ruff.toml</code>.</p>
</blockquote>
","python, isort, ruff"
Jan-24,Jan-24,"<pre class=""lang-py prettyprint-override""><code>import pytest
from moto import mock_s3


@pytest.fixture(scope='module')
def s3():
    with mock_s3():
        os.environ['AWS_ACCESS_KEY_ID'] = 'test'
        os.environ['AWS_SECRET_ACCESS_KEY'] = 'test'
        os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'
        s3 = boto3.resource('s3')
        s3.create_bucket(Bucket='test_bucket')
        yield s3
</code></pre>
<p>This code was working, but is now throwing an exception <code>Cannot import name mock_s3 from moto</code>. What am I doing wrong?</p>
",52,"<p>Simply replace your import of <code>mock_s3</code> with <code>from moto import mock_aws</code> and use <code>with mock_aws():</code> instead.</p>
<p>Moto was recently bumped to version 5.0, and you were probably running 4.x before.</p>
<p><a href=""https://github.com/getmoto/moto/blob/master/CHANGELOG.md"" rel=""noreferrer"">https://github.com/getmoto/moto/blob/master/CHANGELOG.md</a></p>
<p>If you check the change log, you will see that an important breaking change was made:</p>
<blockquote>
<p>All decorators have been replaced with a single decorator: <code>mock_aws</code></p>
</blockquote>
","python, moto"
Feb-24,Feb-24,"<p>I am creating a full stack application with next js 13,
I have created an API that is perfectly working in dev(npm run dev) mode but the problem is when I give the build command(npm run build) then it shows the flowing error.
Please anybody bring me out of the problem.
Error Screenshot - <a href=""https://prnt.sc/VaN1wHifqK_2"" rel=""noreferrer"">https://prnt.sc/VaN1wHifqK_2</a></p>
<pre class=""lang-none prettyprint-override""><code> [Error]: Dynamic server usage: Page couldn't be rendered statically because it used `nextUrl.searchParams`. See more info here: https://nextjs.org/docs/messages/dynamic-server-error
</code></pre>
<p>Here is my code.
This is the API function for getting users from the database using url searchParams</p>
<pre><code>// /backend/apiControllers/getUsers.js

import prisma from &quot;@/prisma/prismaClient&quot;;

export const getUsers = async (request) =&gt; {
  const { nextUrl } = request; // here is the problem, this is working for dev mode but not in production build mode.
  const email = nextUrl.searchParams.get(&quot;email&quot;) || &quot;&quot;;
  const phone = nextUrl.searchParams.get(&quot;phone&quot;) || &quot;&quot;;
  const id = nextUrl.searchParams.get(&quot;id&quot;) || &quot;&quot;;

  let queryParam = {};

  if (email) {
    queryParam = {
      where: {
        ...queryParam.where,
        email: {
          equals: email,
          mode: &quot;insensitive&quot;,
        },
      },
    };
  }
  if (phone) {
    queryParam = {
      where: {
        ...queryParam.where,
        phone: {
          equals: phone,
        },
      },
    };
  }
  if (id) {
    queryParam = {
      where: {
        ...queryParam.where,
        id: {
          equals: id,
        },
      },
    };
  }

  try {
    const users = await prisma.users.findMany(queryParam);
    return users;
  } catch (error) {
    return { apiMessage: { errorMsg: &quot;Unable to find User details&quot; } };
  }
};

</code></pre>
<p>And I have called that function into /app/api/armies/route.js</p>
<pre><code>// /app/api/armies/route.js

import { getUsers } from &quot;@/backend/apiControllers/getUsers&quot;;
import { connectDB } from &quot;@/backend/utils/dbConnect&quot;;
import { NextResponse } from &quot;next/server&quot;;

export const GET = async (request) =&gt; {
  try {
    await connectDB();
    const users = await getUsers(request); //called here
    return NextResponse.json(users);
  } catch (error) {
    console.log(error);
    return NextResponse.json({
      apiMessage: { errorMsg: &quot;Internal Server Error, Please try again later&quot; },
    });
  }
};

</code></pre>
<p>I have tried the following method also &quot;const url = new URL(request.url);&quot; but the same error, Here is the error screenshot - <a href=""https://prnt.sc/Z3D317lDQ3CP"" rel=""noreferrer"">https://prnt.sc/Z3D317lDQ3CP</a></p>
<pre><code>import prisma from &quot;@/prisma/prismaClient&quot;;

export const getUsers = async (request) =&gt; {
  const url = new URL(request.url); // here is the problem, this is working for dev mode but not in production build mode.
  const email = url.searchParams.get(&quot;email&quot;) || &quot;&quot;;
  const phone = url.searchParams.get(&quot;phone&quot;) || &quot;&quot;;
  const id = url.searchParams.get(&quot;id&quot;) || &quot;&quot;;

  let queryParam = {};

  if (email) {
    queryParam = {
      where: {
        ...queryParam.where,
        email: {
          equals: email,
          mode: &quot;insensitive&quot;,
        },
      },
    };
  }
  if (phone) {
    queryParam = {
      where: {
        ...queryParam.where,
        phone: {
          equals: phone,
        },
      },
    };
  }
  if (id) {
    queryParam = {
      where: {
        ...queryParam.where,
        id: {
          equals: id,
        },
      },
    };
  }

  try {
    const users = await prisma.users.findMany(queryParam);
    return users;
  } catch (error) {
    return { apiMessage: { errorMsg: &quot;Unable to find User details&quot; } };
  }
};

</code></pre>
<p>But again the same error</p>
",34,"<p>In Next.js, Every page and route handler<sup>(1)</sup> are static by default then Next.js will (bail out) opt out to dynamic rendering when using Runtime data such as <code>searchParams</code> or <code>headers</code>. The way Next.js knows when dynamic data is used is by throwing custom errors and catch them to switch the renderer method. Simply, when you use the request URL (e.g. <code>request.nextUrl</code>) Next.js internally will throw <code>DynamicServerError</code> and catch it at a top-level.</p>
<blockquote>
<p>While generating static pages, Next.js will throw a DynamicServerError if it detects usage of a dynamic function, and catch it to automatically opt the page into dynamic rendering. However, when it's uncaught, it will result in this build-time error.</p>
<p><a href=""https://nextjs.org/docs/messages/dynamic-server-error"" rel=""noreferrer"">Documentation</a></p>
</blockquote>
<p>Let's look at this snippet from your code:</p>
<pre class=""lang-js prettyprint-override""><code>try {
    const users = await getUsers(request); //called here
    // At the previous line, We used `request.url` / `request.nextUrl`
    // Next.js has thrown a `DynamicServerError`

    return NextResponse.json(users);
  } catch (error) {

    // Wait!
    // We are trying/catching errors here, so any thrown error withen 
    // the try block will no longer be thrown. As a result, 
    // Next.js no longer knows when you use dynamic data
¬†
    return NextResponse.json({
      apiMessage: { errorMsg: &quot;Internal Server Error, Please try again later&quot; },
    });
  }
</code></pre>
<p><strong>Note</strong>: Read the comments in the code block if you haven't</p>
<p>Did you get it?</p>
<h2>How to solve it?</h2>
<p>We have two solutions:</p>
<ol>
<li>Use dynamic data outside of <code>try/catch</code> statments</li>
</ol>
<pre class=""lang-js prettyprint-override""><code>const searchParams = request.nextUrl.searchParams

try {
    const users = await getUsers({ searchParams });
    return NextResponse.json(users);
    // ...
</code></pre>
<p>This way, Next.js will throw its errors and catch them without a stumbling block.</p>
<ol start=""2"">
<li>Re-throw Next.js errors:</li>
</ol>
<p>You can also, catch all errors then re-throw Next.js-specific errors to handle them. Next.js provides some utilities to know the error.</p>
<pre class=""lang-js prettyprint-override""><code>import { isDynamicServerError } from &quot;next/dist/client/components/hooks-server-context&quot;;

// ...

try {
  const {nextUrl} = request;
} catch (error) {
  if (isDynamicServerError(error)) {
    throw error;
  }

  // handle other errors
}
</code></pre>
<p>When using some of Next.js functions inside <code>try</code> you need to re-throw them. for example, <code>isNotFoundError</code> for <code>notFound()</code>, <code>isRedirectError</code> for <code>redirect</code>.</p>
<pre class=""lang-js prettyprint-override""><code>import { isStaticGenBailoutError } from &quot;next/dist/client/components/static-generation-bailout&quot;;
import { isNotFoundError } from &quot;next/dist/client/components/not-found&quot;;
import { isRedirectError } from &quot;next/dist/client/components/redirect&quot;;
import { isDynamicServerError } from &quot;next/dist/client/components/hooks-server-context&quot;;
</code></pre>
<h3>Update:</h3>
<p>There is a <a href=""https://github.com/vercel/next.js/discussions/64076"" rel=""noreferrer"">proposal</a> to introduce a new API <code>rethrow</code> that you can call it in the <code>catch</code> block to rethrow all next.js errors.</p>
<h3>Update:</h3>
<p><a href=""https://github.com/vercel/next.js/pull/65831"" rel=""noreferrer""><code>unstable_rethrow</code></a> is out as of <code>next@15.0.0</code>, you can call it in the <code>catch</code> block to rethrow Next.js specific errors:</p>
<pre class=""lang-js prettyprint-override""><code>try {
  redirect(&quot;/&quot;);
  notFound();
  request.nextUrl.searchParams;

  // ...
  await getData();
} catch (error) {
  unstable_rethrow(error)

  // handle your errors
  console.error(error)
}
</code></pre>
<hr />
<p>(1) Starting from <code>next@15</code>, Route Handlers are dynamic by default.</p>
","javascript, next.js"
Feb-24,Feb-24,"<p>I have a python script that reads in data from a csv file</p>
<p>The code runs fine, but everytime it runs I get this Deprecation message:</p>
<pre><code>DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
</code></pre>
<p>the warning stems from this piece of code:</p>
<pre><code>fprice = df.groupby(['StartDate', 'Commodity', 'DealType']).apply(lambda group: -(group['MTMValue'].sum() - (group['FixedPriceStrike'] * group['Quantity']).sum()) / group['Quantity'].sum()).reset_index(name='FloatPrice')
</code></pre>
<p>to my understanding, I am performing the apply function on my groupings,but then I am disregarding the groupings and not using them anymore to be apart of my dataframe. I am confused about the directions to silence the warning</p>
<p>here is some sample data that this code uses:</p>
<pre><code>TradeID  TradeDate  Commodity  StartDate   ExpiryDate FixedPrice Quantity MTMValue
-------- ---------- ---------  ---------   ---------- ---------- -------- ---------
 aaa   01/01/2024   (com1,com2) 01/01/2024  01/01/2024    10        10      100.00 
 bbb   01/01/2024   (com1,com2) 01/01/2024  01/01/2024    10        10      100.00 
 ccc   01/01/2024   (com1,com2) 01/01/2024  01/01/2024    10        10      100.00  
</code></pre>
<p>and here is the expected output from this data:</p>
<pre><code>TradeID  TradeDate  Commodity  StartDate   ExpiryDate FixedPrice Quantity MTMValue  FloatPrice
-------- ---------- ---------  ---------   ---------- ---------- -------- --------- ----------
 aaa   01/01/2024   (com1,com2) 01/01/2024  01/01/2024    10        10      100.00      0
 bbb   01/01/2024   (com1,com2) 01/01/2024  01/01/2024    10        10      100.00      0
 ccc   01/01/2024   (com1,com2) 01/01/2024  01/01/2024    10        10      100.00      0 
</code></pre>
",48,"<h3>About <code>include_groups</code> parameter</h3>
<p>The <code>include_groups</code> parameter of <a href=""https://pandas.pydata.org/pandas-docs/version/2.2/reference/api/pandas.core.groupby.DataFrameGroupBy.apply.html"" rel=""noreferrer"">DataFrameGroupBy.apply</a> is new in pandas version 2.2.0. It is basically a transition period (2.2.0 -&gt; 3.0) parameter added to help communicating a changing behavior (with warnings) and to tackle <a href=""https://github.com/pandas-dev/pandas/issues/7155"" rel=""noreferrer"">pandas Issue 7155</a>. In most cases you should be able to just set it to <code>False</code> to silent the warning (see below).</p>
<h3>Setup</h3>
<p>Let's say you have a pandas DataFrame <code>df</code> and a dummy function <code>myfunc</code> for apply, and you want to</p>
<ul>
<li>Group by column <code>'c'</code></li>
<li>Apply <code>myfunc</code> on each group</li>
</ul>
<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; df
      a  value     c
0   foo     10  cat1
1   bar     20  cat2
2   baz     30  cat1
3  quux     40  cat2


&gt;&gt;&gt; def myfunc(x):
    print(x, '\n')
    
</code></pre>
<h3>include_groups = True (Old behavior)</h3>
<ul>
<li>This is the default <em>behavior</em> in pandas &lt;2.2.0 (there is no <code>include_groups</code> parameter)</li>
<li>pandas 2.2.0 and above (likely until 3.0) will still default to this but issue a DeprecationWarning.</li>
<li>The grouping column(s), here <code>'c'</code> is included in the <code>DataFrameGroupBy</code></li>
</ul>
<pre><code>&gt;&gt;&gt; df.groupby('c').apply(myfunc)
     a  value     c
0  foo     10  cat1
2  baz     30  cat1 

      a  value     c
1   bar     20  cat2
3  quux     40  cat2 
</code></pre>
<p>Now as mentioned in <a href=""https://github.com/pandas-dev/pandas/issues/7155"" rel=""noreferrer"">Issue 7155</a>, keeping the grouping column <code>c</code> in the dataframe passed to <code>apply</code> is unwanted behavior. Most people will not expect <code>c</code> to be present here. The <a href=""https://stackoverflow.com/a/78030503/3015186"">answer of bue</a> has actually an example how this could lead to bugs; apply on <code>np.mean</code> and expect there be less columns (causes a bug if your grouping column is numerical).</p>
<h3>include_groups = False (new behavior)</h3>
<ul>
<li>This will remove the warning in the pandas &gt; 2.2.0 (&lt;3.0)</li>
<li>This will be the default in future version of pandas (likely 3.0)</li>
<li>This is what you likely would want to have; drop the grouping column <code>'c'</code>:</li>
</ul>
<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; df.groupby('c').apply(myfunc, include_groups=False)
     a  value
0  foo     10
2  baz     30 

      a  value
1   bar     20
3  quux     40 
</code></pre>
<h3>Circumventing need to use <code>include_groups</code> at all</h3>
<h4>Option 1: Explicitly giving column names</h4>
<p>You may also skip the need for using the <code>include_groups</code> parameter at all by explicitly giving the list of the columns (as pointed out by the warning itself; &quot;<em>..or explicitly select the grouping columns after groupby to silence this warning..</em>&quot;,  and Cahit in their <a href=""https://stackoverflow.com/a/78582800/3015186"">answer</a>), like this:</p>
<pre><code>&gt;&gt;&gt; df.groupby('c')[['a', 'value', 'c']].apply(myfunc)
     a  value     c
0  foo     10  cat1
2  baz     30  cat1 

      a  value     c
1   bar     20  cat2
3  quux     40  cat2 

Empty DataFrame
Columns: []
Index: []
</code></pre>
<h4>Option 2: Setting the index before groupby</h4>
<p>You may also set the groupby column to the index, as pointed out by Stefan in the <a href=""https://stackoverflow.com/questions/77969964/deprecation-warning-with-groupby-apply/78100669?noredirect=1#comment138967146_78100669"">comments</a>.</p>
<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; df.set_index('c').groupby(level='c').apply(myfunc)
        a  value
c               
cat1  foo     10
cat1  baz     30 

         a  value
c                
cat2   bar     20
cat2  quux     40 

Empty DataFrame
Columns: []
Index: []

</code></pre>
<hr />
<h3>Details just for this use case</h3>
<p>Your grouping columns are</p>
<pre><code>['StartDate', 'Commodity', 'DealType']
</code></pre>
<p>In the apply function you use the following columns:</p>
<pre><code>['MTMValue',  'FixedPriceStrike', 'Quantity']
</code></pre>
<p>i.e., you do not need any of the <em>grouping columns</em> in your <em>apply</em>, and therefore you can use <code>include_groups=False</code> which also removes the warning.</p>
<pre class=""lang-py prettyprint-override""><code>fprice = df.groupby(['StartDate', 'Commodity', 'DealType']).apply(lambda group: -(group['MTMValue'].sum() - (group['FixedPriceStrike'] * group['Quantity']).sum()) / group['Quantity'].sum(), include_groups=False).reset_index(name='FloatPrice')
</code></pre>
","python, dataframe, pandas"
Feb-24,Feb-24,"<p>In a <code>app-test</code> component I have the following:</p>
<pre><code>  @Input( { transform: booleanAttribute})
  reverse: boolean = false;

  @HostBinding('style.flex-direction')
  direction: string = this.reverse ? 'column-reverse' : 'column';

</code></pre>
<p>And so if the designer applies the <code>reverse</code> attribute to <code>app-test</code> like this:</p>
<pre><code>&lt;app-test reverse&gt;&lt;/app-test&gt;
</code></pre>
<p>Then Angular should set <code>style=&quot;flex-direction: column-reverse&quot;</code> on the <code>app-test</code> element.</p>
<p>And I'm wondering how to use Angular signals so that when <code>reverse</code> is set to true, direction will be set to <code>column-reverse</code>.  Thoughts?</p>
",7,"<p>This is being discussed in <a href=""https://github.com/angular/angular/issues/53888"" rel=""noreferrer"">this issue</a>. Currently the combination of <code>@HostBinding</code> and signals is not supported.</p>
<p>The workaround for this is to use a getter:</p>
<pre><code>reverse = input.required&lt;boolean&gt;();

@HostBinding('attr.style.flex-direction')
get direction() { return this.reverse() ? 'column-reverse' : 'column' }
</code></pre>
","javascript, typescript, angular, angular-signals"
Feb-24,Feb-24,"<p>In a typical servlet environment, each request gets its own thread. Adding logging MDC to generate a unique request ID to the request can be achieved with a simple servlet filter.</p>
<pre><code>public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {
    try {
        String requestId = UUID.randomUUID().toString();
        HttpServletResponse httpServletResponse = (HttpServletResponse)response;
        httpServletResponse.setHeader(&quot;requestId&quot;, requestId);
        MDC.put(&quot;requestId&quot;, requestId);
        chain.doFilter(request, response);
    } finally {
        MDC.remove(&quot;requestId&quot;);
    }
}
</code></pre>
<p>Logging configuration.</p>
<pre><code>&lt;Pattern&gt;%d %-5level %X{requestId} [%t] %C{10}:%L %m%n&lt;/Pattern&gt;
</code></pre>
<p>Sample logging.</p>
<pre><code>2024-02-04 10:29:55,160 INFO  99cd4d64-5d7c-4577-a5d3-cb8d48d1dfd5 [http-nio-8080-exec-6] c.s.q.UserController:65 Deleteing user 'test'
2024-02-04 10:29:55,260 INFO  99cd4d64-5d7c-4577-a5d3-cb8d48d1dfd5 [http-nio-8080-exec-6] c.s.q.UserController:70 Successfully deleted user 'test'
</code></pre>
<p>With Virtual Threads in Java 21+, I'm under the impression a thread can automatically suspended a request while it's waiting on any IO and the thread can begin working on other requests. In this scenario it seems like the logging MDC can &quot;bleed&quot; into other request logs as the thread begins serving other requests. How can I work around this so I can continue to have a unique value added to each request's logging statements?</p>
",11,"<p>If the MDC Adapter you use is the one that uses <code>ThreadLocal</code>, e.g. <code>LogbackMDCAdapter</code>, then the filter you posted will work fine for virtual threads as well as for platform threads. If your virtual thread would be suspended and then <em>continued</em> on another <em>Carrier</em> (platform) thread, then its <code>ThreadLocal</code>s would be correctly transferred (at least Project Loom promises so).</p>
<p><a href=""https://docs.oracle.com/en/java/javase/21/core/virtual-threads.html#GUID-68216B85-7B43-423E-91BA-11489B1ACA61"" rel=""nofollow noreferrer"">&quot;Don't Cache Expensive Reusable Objects in Thread-Local Variables&quot;</a> of Virtual Threads doc says:</p>
<blockquote>
<p>Virtual threads support thread-local variables just as platform threads do</p>
</blockquote>
<p>However, the users of virtual threads are warned against excessive usage of <code>ThreadLocal</code>s on virtual threads (which could be very well understood as these <code>ThreadLocal</code>s have to be transferred between <em>Carrier</em> threads of our virtual thread - this is pretty rough picture of what is going on &quot;under the hood&quot;).</p>
<p>Instead, Project Loom advises to use <code>ScopedValue</code>. However, in the scope of your question, 1) a usage of <code>ScopedValue</code> should be initiated at the point of virtual thread spawning, i.e. somewhere in Servlet Container (if Tomcat is used then it would be a Connector) and 2) a special <code>ScopedValue</code>-oriented <code>MDCAdapter</code> implementation should be used 3) <code>ScopedValue</code> is still a preview in Java 21. Some plans in that direction have been laid out in <a href=""https://stackoverflow.com/questions/77716273/how-to-propagating-context-through-structuredtaskscope-by-scopedvalue-by-the-wa"">How to propagating context through StructuredTaskScope by ScopedValue... how about the MDC ThreadContextMap in StructuredTaskScope?</a>. It seems to me that, as <code>ScopedValue</code> is designed, the efforts should be applied at two levels: Servlet Container, where the virtual thread is spawned, and special <code>MDCAdapter</code> implementation. More on usage of <code>ScopedValue</code>s for MDC on <a href=""https://stackoverflow.com/questions/78142173/logback-availability-of-mdcs-in-forks-created-inside-a-structuredtaskscope/"">Logback: availability of MDCs in forks created inside a StructuredTaskScope</a>.</p>
","java, servlets, virtual-threads"
Feb-24,Feb-24,"<p>Suppose my data looks like this:</p>
<pre class=""lang-py prettyprint-override""><code>data = {
    'value': [1,9,6,7,3, 2,4,5,1,9]
}
</code></pre>
<p>For each row, I would like to find the row number of the latest previous element larger than the current one.</p>
<p>So, my expected output is:</p>
<pre><code>[None, 0, 1, 2, 1, 1, 3, 4, 1, 0]
</code></pre>
<ul>
<li>the first element <code>1</code> has no previous element, so I want <code>None</code> in the result</li>
<li>the next element <code>9</code> is at least as large than all its previous elements, so I want <code>0</code> in the result</li>
<li>the next element <code>6</code>, has its previous element <code>9</code> which is larger than it. The distance between them is <code>1</code>. So, I want <code>1</code> in the result here.</li>
</ul>
<p>I'm aware that I can do this in a loop in Python (or in C / Rust if I write an extension).</p>
<p>My question: is it possible to solve this <strong>using entirely dataframe operations</strong>? pandas or Polars, either is fine. But only dataframe operations.</p>
<p>So, none of the following please:</p>
<ul>
<li><code>apply</code></li>
<li><code>map_elements</code></li>
<li><code>map_rows</code></li>
<li><code>iter_rows</code></li>
<li>Python for loops which loop over the rows and extract elements one-by-one from the dataframes</li>
</ul>
",4,"<p>This iterates only on the range of rows that this should look. It doesn't loop over the rows themselves in python. If your initial <code>bound_range</code> covers all the cases then it won't ever actually do a loop.</p>
<pre><code>lb=0
bound_range=3
df=df.with_columns(z=pl.lit(None, dtype=pl.UInt64))
while True:
    df=df.with_columns(
        z=pl.when(pl.col('value')&gt;=pl.col('value').shift(1).cum_max())
            .then(pl.lit(0, dtype=pl.UInt64))
            .when(pl.col('z').is_null())
            .then(
                pl.coalesce(
                    pl.when(pl.col('value')&lt;pl.col('value').shift(x))
                        .then(pl.lit(x, dtype=pl.UInt64))
                        for x in range(lb, lb+bound_range)
                )
            )
            .otherwise(pl.col('z'))
            )
    if df[1:]['z'].drop_nulls().shape[0]==df.shape[0]-1:
        break
    lb+=bound_range

</code></pre>
<p>For this example I set <code>bound_range</code> to 3 to make sure it loops at least once. I ran this with 1M random integers between 0 and 9(inclusive) and I set the bound_range to 50 and it took under 2 sec. You could make this smarter in between loops by checking things more explicitly but the best approach there would be data dependent.</p>
","python, pandas, python-polars"
Mar-24,Mar-24,"<blockquote>
<p>Logging Error: Failed to initialize logging system. Log messages may be missing. If this issue persists, try setting IDEPreferLogStreaming=YES in the active scheme actions environment variables.</p>
</blockquote>
<p>Has anyone else encountered this message?</p>
<p>Where is <code>IDEPreferLogStreaming</code> located? I don't know what any of this means.</p>
<p>It's building my app successfully but then loading it like its a computer using floppy discs (crazy slow).</p>
<p>Any ideas?</p>
<p>I tried wiping my OS and reinstalling. I've reinstalled Xcode twice now. Nothing.</p>
<p>A colleague of mine is working on the same SwifUI project with no issues.</p>
",118,"<p>To find IDEPreferLogStreaming, you need to go to Product -&gt; Scheme -&gt; Edit Scheme and then add it as a new Environment Variable yourself.</p>
<pre><code>IDEPreferLogStreaming=YES
</code></pre>
<p>For me it didnt solve the issue though --- [<strong>Edit: it works</strong> for me now as well. Probably I was to quick saying it doesnt. Thanks for your feedback.]</p>
<p><a href=""https://i.sstatic.net/fVsPf.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/fVsPf.png"" alt=""Edit Scheme Area"" /></a></p>
","python, xcode, swift"
Mar-24,Mar-24,"<p><img src=""https://i.sstatic.net/4hMVK.png"" alt=""Koda Ula≈üƒ±lamƒ±yor -&gt; Code is unreachable"" /></p>
<blockquote>
<p>Koda Ula≈üƒ±lamƒ±yor -&gt; Code is unreachable</p>
</blockquote>
<p>Visual Studio code is graying out my code and saying it is unreachable after I used <code>pd.concat()</code>.  The IDE seems to run smoothly but it's disturbing and I want my colorful editor back.</p>
<p>How do I disable the editor graying out my code without changing the current language?</p>
",17,"<p>This is a bug currently existing in <code>pandas-stubs</code>.</p>
<p>The matching overload of <code>concat</code> in pandas-stubs currently returns <strong>Never</strong>.</p>
<p>According to <a href=""https://github.com/microsoft/pylance-release/issues/5630"" rel=""noreferrer"">this suggestion in Pylance github</a>, you could work around the pandas-stubs issue by commenting out the Never overload in <code>...\.vscode\extensions\ms-python.vscode-pylance-2024.3.1\dist\bundled\stubs\pandas\core\reshape\concat.pyi</code>.</p>
<pre><code>@overload
def concat(
    objs: Iterable[None] | Mapping[HashableT1, None],
    *,
    axis: Axis = ...,
    join: Literal[&quot;inner&quot;, &quot;outer&quot;] = ...,
    ignore_index: bool = ...,
    keys: Iterable[HashableT2] = ...,
    levels: Sequence[list[HashableT3] | tuple[HashableT3, ...]] = ...,
    names: list[HashableT4] = ...,
    verify_integrity: bool = ...,
    sort: bool = ...,
    copy: bool = ...,
) -&gt; Never: ...
</code></pre>
","python, pandas, visual-studio-code"
Mar-24,Mar-24,"<p>Given a <code>NxN</code> integer lattice, I want to find the clipped circle which maximizes the sum of its interior lattice point values.</p>
<p>Each lattice point <code>(i,j)</code> has a value <code>V(i,j)</code> and are stored in the following matrix <code>V</code>:</p>
<pre><code>      [[ 1,  1, -3,  0,  0,  3, -1,  3, -3,  2],
       [-2, -1,  0,  1,  0, -2,  0,  0,  1, -3],
       [ 2,  2, -3,  2, -2, -1,  2,  2, -2,  0],
       [-2,  0, -3,  3,  0,  2, -1,  1,  3,  3],
       [-1, -2, -1,  2,  3,  3, -3, -3,  2,  0],
       [-3,  3,  2,  0, -3, -2, -1, -3,  0, -3],
       [ 3,  2,  2, -1,  0, -3,  1,  1, -2,  2],
       [-3,  1,  3,  3,  0, -3, -3,  2, -2,  1],
       [ 0, -3,  0,  3,  2, -2,  3, -2,  3,  3],
       [-1,  3, -3, -2,  0, -1, -2, -1, -1,  2]]
</code></pre>
<p>The goal is to maximize the sum of values <code>V(i,j)</code> of the lattice points lying on the boundary and within interior of a (clipped) circle with radius <code>R</code>, with the assumptions and conditions:</p>
<ul>
<li>the circle has center at (0,0)</li>
<li>the circle can have any positive radius (not necessarily an integer radius, i.e., rational).</li>
<li>the circle may be clipped at two lattice points, resulting in a diagonal line as shown in the picture. This diagonal line has a slope of -45 degrees.</li>
</ul>
<p>Some additional details:</p>
<p>The score for a clipped circle is the sum of all the integers that are both within the circle (or on the border) and on the side of the diagonal line including (0,0).   The values on (or near) the border are -3, 1, 3, -1, -3, 3, -1, 2, 0, 3.</p>
<p>Even though the circle can have any radius, we need only consider circles that intersect a grid point precisely so there are n^2 different relevant radiuses. Further, we need only record one position where the circle intersects with the diagonal line to fully specify the clipped circle. Note that this intersection with the diagonal does not need to be at an integer coordinate.</p>
<p>If the optimal solution doesn't have the diagonal clipping the circle at all then we need only return the radius of the circle.</p>
<p>What I have found so far:</p>
<p>If we only wanted to find the optimal circle we could do that quickly in time proportional to the input size with:</p>
<pre><code>import numpy as np
from math import sqrt
np.random.seed(40)

def find_max(A):
    n = A.shape[0]
    sum_dist = np.zeros(2 * n * n, dtype=np.int32)
    for i in range(n):
        for j in range(n):
            dist = i**2 + j**2
            sum_dist[dist] += A[i, j]
    cusum = np.cumsum(sum_dist)
    # returns optimal radius with its score
    return sqrt(np.argmax(cusum)), np.max(cusum)
A = np.random.randint(-3, 4, (10, 10))
print(find_max(A))
</code></pre>
<p>How quickly can the optimal clipped circle be found?</p>
",6,"<p>Start by creating a cumulative frequency table, or a fenwick tree. You'll have a record for each radius of circle, with value corresponding to explored weights at that distance from the origin. Then, begin a BFS from the origin.</p>
<p>For each diagonal &quot;frontier&quot;, you'll need to update your table/tree with the radius:weight key-value pair (add weight to existing value). You'll also need to then query the table/tree for the current cumulative sum at each radius just added, noting the maximum and updating a global running maximum accordingly.</p>
<p>Once your search terminates, you'll have the maximum sum for your clipped-circle. If you want to reconstruct the circle, just store the max radius and BFS depth along with the global max sum itself.</p>
<p>This will give you your solution in <code>O(N^2 log N)</code> time, as there will be N^2 updates and queries, which are <code>O(log N)</code> each.</p>
<p>The intuition behind this solution is that by exploring along this diagonal &quot;frontier&quot; outward, you implicitly clip all your circles you query since the weights above/right of it haven't been added yet. By calculating the max (at each search depth) for just the radii that were just updated, you also enforce the constraint that the circles intersect the clipping line at an integer coordinate.</p>
<p><strong>Update</strong>
Here is python code showing this in action. It needs cleaned up, but at least it shows the process. I opted to use cumulative frequency / max arrays, instead of trees, since that'll probably lend itself to vectorization with numpy for OP.</p>
<pre class=""lang-py prettyprint-override""><code>def solve(matrix):
    n = len(matrix)

    max_radius_sqr = 2 * (n - 1) ** 2
    num_bins = max_radius_sqr.bit_length() + 1

    frontier = [(0, 0)]

    csum_arr = [[0] * 2 ** i for i in range(num_bins)[::-1]]
    cmax_arr = [[0] * 2 ** i for i in range(num_bins)[::-1]]

    max_csum = -float(&quot;inf&quot;)
    max_csum_depth = None
    max_csum_radius_sqr = None

    depth = 0

    while frontier:
        next_frontier = []

        if depth + 1 &lt; n:  # BFS up
            next_frontier.append((0, depth + 1))

        # explore frontier, updating csums and maximums per each
        for x, y in frontier:
            if x + 1 &lt; n:  # BFS right
                next_frontier.append((x + 1, y))

            index = x ** 2 + y ** 2  # index is initially the radius squared

            for i in range(num_bins):
                csum_arr[i][index] += matrix[y][x]  # update csums

                if i != 0:  # skip first, since no children to take max of
                    sum_left  = csum_arr[i-1][index &lt;&lt; 1]  # left/right is tree notation of the array
                    max_left  = cmax_arr[i-1][index &lt;&lt; 1]
                    max_right = cmax_arr[i-1][index &lt;&lt; 1 | 1]
                    cmax_arr[i][index] = max(max_left, sum_left + max_right)  # update csum maximums

                index &gt;&gt;= 1  # shift off last bit, update sums/maxs again, log2 times

        # after entire frontier is explored, query for overall max csum over all radii
        # update running global max and associated values
        if cmax_arr[-1][0] &gt; max_csum:
            max_csum = cmax_arr[-1][0]
            max_csum_depth = depth
            index = 0
            for i in range(num_bins-1)[::-1]:  # reconstruct max radius (this could just as well be stored)
                sum_left  = csum_arr[i][index &lt;&lt; 1]
                max_left  = cmax_arr[i][index &lt;&lt; 1]
                max_right = cmax_arr[i][index &lt;&lt; 1 | 1]

                index &lt;&lt;= 1
                if sum_left + max_right &gt; max_left:
                    index |= 1
            max_csum_radius_sqr = index

        depth += 1
        frontier = next_frontier

    # total max sum, dx + dy of diagonal cut, radius ** 2
    return max_csum, max_csum_depth, max_csum_radius_sqr
</code></pre>
<p>Calling this with the given test case produces the expected output:</p>
<pre><code>    matrix = [
        [-1,  3, -3, -2,  0, -1, -2, -1, -1,  2],
        [ 0, -3,  0,  3,  2, -2,  3, -2,  3,  3],
        [-3,  1,  3,  3,  0, -3, -3,  2, -2,  1],
        [ 3,  2,  2, -1,  0, -3,  1,  1, -2,  2],
        [-3,  3,  2,  0, -3, -2, -1, -3,  0, -3],
        [-1, -2, -1,  2,  3,  3, -3, -3,  2,  0],
        [-2,  0, -3,  3,  0,  2, -1,  1,  3,  3],
        [ 2,  2, -3,  2, -2, -1,  2,  2, -2,  0],
        [-2, -1,  0,  1,  0, -2,  0,  0,  1, -3],
        [ 1,  1, -3,  0,  0,  3, -1,  3, -3,  2],
    ][::-1]
    print(solve(matrix))

# output: 13 9 54
</code></pre>
<p>In other words, it says the maximum total sum is <code>13</code>, with a diagonal cut stagger (dx + dy) of <code>9</code>, and radius squared of <code>54</code>.</p>
<p>If I have some time tonight or this weekend, I'll clean up the code a bit.</p>
","python, algorithm, optimization, performance"
Mar-24,Mar-24,"<p>I often work in very small projects which do not have config file. How do I use <code>ruff</code> in place of <code>isort</code> to sort the imports? I know that the following command is roughly equivalent to <code>black</code>:</p>
<pre class=""lang-bash prettyprint-override""><code>ruff format .
</code></pre>
<p>The format command do not sort the imports. How do I do that?</p>
",25,"<p>According to the <a href=""https://docs.astral.sh/ruff/formatter/#sorting-imports"" rel=""noreferrer"">documentation</a>:</p>
<blockquote>
<p>Currently, the Ruff formatter does not sort imports. In order to both sort imports and format, call the Ruff linter and then the formatter:</p>
</blockquote>
<pre class=""lang-none prettyprint-override""><code>ruff check --select I --fix .
ruff format .
</code></pre>
","python, isort, ruff"
Mar-24,Mar-24,"<p>I sorted four similar lists. List <code>d</code> consistently takes much longer than the others, which all take about the same time:</p>
<pre class=""lang-none prettyprint-override""><code>a:  33.5 ms
b:  33.4 ms
c:  36.4 ms
d: 110.9 ms
</code></pre>
<p>Why is that?</p>
<p>Test script (<a href=""https://ato.pxeger.com/run?1=fZHBasMwDEDZ1V8h2CHxSNM4YbAY-iUhFLtxWkPsBMc9jNIv2aWX7Sf2J_uayUkaGIwadBDSexbSx9fw7k-9vd0-z77dvP08fbeuN-C1UdqDNkPvPDg1KOEJsbCDfJ9lWQgiMKs0bLfAoO0daNAWnLBHFVtaAzxDlSXAEsgTKBJI0xSzfVmWIWoiVzx_gM-GWZIvklVxQIWoON8w7P_noWL9cGGLSYO-rCYN4vIx_hfO7zCbBkMFCZNbYVQYPhLy0EScBLYbPdqPXS9FN8a0Cj31VAmrxZLRNp73GnfCyEZwGHHXqokRpQnYs5HK7RilEzU4bX3cRpcgunK4BM0LUwXw15S1VzBjROcbLqe8n_QX"" rel=""noreferrer"">Attempt This Online!</a>):</p>
<pre class=""lang-py prettyprint-override""><code>from timeit import repeat

n = 2_000_000
a = [i // 1 for i in range(n)]  # [0, 1, 2, 3, ..., 1_999_999]
b = [i // 2 for i in range(n)]  # [0, 0, 1, 1, 2, 2, ..., 999_999]
c = a[::-1]                     # [1_999_999, ..., 3, 2, 1, 0]
d = b[::-1]                     # [999_999, ..., 2, 2, 1, 1, 0, 0]

for name in 'abcd':
    lst = globals()[name]
    time = min(repeat(lambda: sorted(lst), number=1))
    print(f'{name}: {time*1e3 :5.1f} ms')
</code></pre>
",43,"<p>As alluded to in the comments by btilly and Amadan, this is due to how the <a href=""https://en.wikipedia.org/wiki/Timsort"" rel=""noreferrer"">Timsort</a> sorting algorithm works. Detailed description of the algorithm is <a href=""https://bugs.python.org/file4451/timsort.txt"" rel=""noreferrer"">here</a>.</p>
<p>Timsort speeds up operation on partially sorted arrays by identifying runs of sorted elements.</p>
<blockquote>
<p>A run is either
&quot;ascending&quot;, which means non-decreasing:</p>
<p>a0 &lt;= a1 &lt;= a2 &lt;= ...</p>
<p>or &quot;descending&quot;, which means strictly decreasing:</p>
<p>a0 &gt; a1 &gt; a2 &gt; ...</p>
<p>Note that a run is always at least 2 long, unless we start at the array's
last element.</p>
</blockquote>
<p>Your arrays <strong>a</strong>, <strong>b</strong> and <strong>c</strong> each consist of just one run.
The array <strong>d</strong> has 1 million runs.</p>
<p>The reason why the descending run cannot be <code>&gt;=</code> is to make the sort stable, i.e. keep the order of equal elements:</p>
<blockquote>
<p>The definition of descending is strict, because the main routine reverses
a descending run in-place, transforming a descending run into an ascending
run.  Reversal is done via the obvious fast &quot;swap elements starting at each
end, and converge at the middle&quot; method, and that can violate stability if
the slice contains any equal elements.  Using a strict definition of
descending ensures that a descending run contains distinct elements.</p>
</blockquote>
<p>Python 3.11 has slightly improved version of timsort, sometimes called <a href=""https://www.i-programmer.info/news/216-python/15954-python-now-uses-powersort.html"" rel=""noreferrer"">powersort</a>, but it uses the same run detection and thus has the same performance.</p>
","python, sorting, algorithm, performance, time-complexity"
Apr-24,Apr-24,"<p>I am trying to use Gensim, but running <code>import gensim</code> raises this error:</p>
<pre class=""lang-none prettyprint-override""><code>Traceback (most recent call last):
  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;
  File &quot;/usr/local/lib/python3.10/dist-packages/gensim/__init__.py&quot;, line 11, in &lt;module&gt;
    from gensim import parsing, corpora, matutils, interfaces, models, similarities, utils  # noqa:F401
  File &quot;/usr/local/lib/python3.10/dist-packages/gensim/corpora/__init__.py&quot;, line 6, in &lt;module&gt;
    from .indexedcorpus import IndexedCorpus  # noqa:F401 must appear before the other classes
  File &quot;/usr/local/lib/python3.10/dist-packages/gensim/corpora/indexedcorpus.py&quot;, line 14, in &lt;module&gt;
    from gensim import interfaces, utils
  File &quot;/usr/local/lib/python3.10/dist-packages/gensim/interfaces.py&quot;, line 19, in &lt;module&gt;
    from gensim import utils, matutils
  File &quot;/usr/local/lib/python3.10/dist-packages/gensim/matutils.py&quot;, line 20, in &lt;module&gt;
    from scipy.linalg import get_blas_funcs, triu
ImportError: cannot import name 'triu' from 'scipy.linalg' (/usr/local/lib/python3.10/dist-packages/scipy/linalg/__init__.py)
</code></pre>
<p>Why is this happening and how can I fix it?</p>
",63,"<p>I found the issue.</p>
<blockquote>
<p>The <a href=""https://docs.scipy.org/doc/scipy/reference/linalg.html#module-scipy.linalg"" rel=""noreferrer""><code>scipy.linalg</code></a> functions <code>tri</code>, <code>triu</code> &amp; <code>tril</code> are deprecated and will be removed in SciPy 1.13.</p>
<p>‚Äî <a href=""https://docs.scipy.org/doc/scipy/release/1.11.0-notes.html#deprecated-features"" rel=""noreferrer"">SciPy 1.11.0 Release Notes ¬ß Deprecated features</a></p>
</blockquote>
<p>So, I installed SciPy v1.10.1 instead of the latest version and it was working well.</p>
<pre class=""lang-bash prettyprint-override""><code>pip install scipy==1.10.1
</code></pre>
","python, scipy, gensim"
Apr-24,Apr-24,"<p>I have to migrate this Spring Boot code to latest version. After Spring 6+ <code>setReadTimeout</code> is deprecated.</p>
<pre><code>HttpComponentsClientHttpRequestFactory factory = new 
HttpComponentsClientHttpRequestFactory();
factory.setReadTimeout(20);
factory.setConnectTimeout(20);
factory.setConnectionRequestTimeout(20);
return new RestTemplate(factory);
</code></pre>
<p>According to the JavaDoc: <a href=""https://www.javadoc.io/static/org.springframework/spring-web/6.0.8/org/springframework/http/client/HttpComponentsClientHttpRequestFactory.html#setReadTimeout(int)"" rel=""noreferrer"">https://www.javadoc.io/static/org.springframework/spring-web/6.0.8/org/springframework/http/client/HttpComponentsClientHttpRequestFactory.html#setReadTimeout(int)</a></p>
<p>I have to use <code>setSoTimeout</code> but I can't find this method. What should the proper way to migrate this code?</p>
",12,"<p>The <code>SocketConfig</code> object, where the timeout is set, is then assigned to a <code>PoolingHttpClientConnectionManager</code>, which then gets assigned to a <code>HttpClient</code>, which is then used to initialize a <code>HttpComponentsClientHttpRequestFactory</code>. The complete <code>RestTemplate</code> bean initialization code would look something like the below:</p>
<pre class=""lang-java prettyprint-override""><code>import org.apache.hc.client5.http.classic.HttpClient;
import org.apache.hc.client5.http.config.ConnectionConfig;
import org.apache.hc.client5.http.config.RequestConfig;
import org.apache.hc.client5.http.impl.classic.HttpClientBuilder;
import org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager;
import org.apache.hc.core5.http.io.SocketConfig;
import org.apache.hc.core5.util.Timeout;
import org.springframework.boot.web.client.RestTemplateBuilder;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.http.client.HttpComponentsClientHttpRequestFactory;
import org.springframework.web.client.RestTemplate;

@Configuration
public class RestTemplateConfig {

    @Bean
    public RestTemplate restTemplate(RestTemplateBuilder restTemplateBuilder) {
        RestTemplate restTemplate = restTemplateBuilder.build();

        // Connect timeout
        ConnectionConfig connectionConfig = ConnectionConfig.custom()
                .setConnectTimeout(Timeout.ofMilliseconds(20))
                .build();

        // Socket timeout
        SocketConfig socketConfig = SocketConfig.custom()
                .setSoTimeout(Timeout.ofMilliseconds(20))
                .build();

        // Connection request timeout
        RequestConfig requestConfig = RequestConfig.custom()
                .setConnectionRequestTimeout(Timeout.ofMilliseconds(20))
                .build();

        PoolingHttpClientConnectionManager connectionManager = new PoolingHttpClientConnectionManager();
        connectionManager.setDefaultSocketConfig(socketConfig);
        connectionManager.setDefaultConnectionConfig(connectionConfig);

        HttpClient httpClient = HttpClientBuilder.create()
                .setConnectionManager(connectionManager)
                .setDefaultRequestConfig(requestConfig)
                .build();
        restTemplate.setRequestFactory(new HttpComponentsClientHttpRequestFactory(httpClient));

        return restTemplate;
    }
}
</code></pre>
<p>You would also need the <code>httpclient5</code> dependency:</p>
<pre><code>implementation group: 'org.apache.httpcomponents.client5', name: 'httpclient5', version: '5.2.3'
</code></pre>
","java, spring, spring-boot"
Apr-24,Apr-24,"<p>To my understanding one of the reasons to switch to a reactive (e.g. <a href=""https://projectreactor.io/docs/core/release/reference/#_blocking_can_be_wasteful"" rel=""noreferrer"">Project Reactor</a>, RxJava, <a href=""https://vertx.io/introduction-to-vertx-and-reactive/"" rel=""noreferrer"">Vert-X</a>) or actor (Akka) framework is because of the cost of thread switching is high.  Looking at <a href=""https://stackoverflow.com/questions/78094984/difference-between-platform-thread-carrier-thread-and-virtual-thread-in-context"">Difference between platform thread, carrier thread and virtual thread in context of Java 21 and later</a> and other information about virtual threads I was wondering...</p>
<p>Do Virtual Threads remove the reason to switch to a different paradigm because it will just swap out the blocking virtual thread to a different thread on the carrier?</p>
",29,"<h2>Yes, virtual threads eliminate the need for reactive approach</h2>
<p>Platform threads in Java are mapped directly to a thread host operating system thread. Those OS threads are ‚Äúexpensive‚Äù in terms of memory and CPU.</p>
<p>Virtual threads, in contrast, are managed within the JVM. As a result, virtual threads are extremely ‚Äúcheap‚Äù, meaning they are quite efficient in both memory and CPU. With virtual threads, you can reasonable expect to run even millions of tasks simultaneously on common computer hardware.</p>
<p>Yes, most, if not all, of the work done as reactive code can be done instead with Java virtual threads. The coding is <strong>vastly simpler to write, comprehend, trace, and debug</strong>. Reactive approach was invented to get around the performance problems of over-using platform threads.</p>
<p><a href=""https://youtu.be/9si7gK94gLo?si=Z5IhQgQE0xxUKPCy&amp;t=1145"" rel=""nofollow noreferrer"">See video</a> of <a href=""https://inside.java/u/BrianGoetz/"" rel=""nofollow noreferrer"">Brian Goetz</a> being asked what he sees as the future of reactive programming after the arrival of <a href=""https://wiki.openjdk.org/display/loom/Main"" rel=""nofollow noreferrer""><em>Project Loom</em></a> and virtual threads:</p>
<blockquote>
<p>I think Loom is going to kill reactive programming ‚Ä¶ reactive programming was a transitional technology ‚Ä¶</p>
</blockquote>
<p>Making reactive programming unnecessary was one of the major motivations for inventing virtual threads in Java.</p>
<h3>Virtual threads are for blocking code</h3>
<p>Caveat‚Ä¶ Virtual threads are contra-indicated for tasks that are <a href=""https://en.wikipedia.org/wiki/CPU-bound"" rel=""nofollow noreferrer"">CPU-bound</a> such as video encoding/decoding. Use <strong>virtual threads only for code that involves <a href=""https://en.wikipedia.org/wiki/Blocking_(computing)"" rel=""nofollow noreferrer"">blocking</a></strong>, such logging, file I/O, accessing databases, network calls. That would cover nearly all Java business apps.</p>
<h2>Cheap threads can perform expensive tasks</h2>
<p>Of course, the tasks performed by these many cheap virtual threads may involve significant resources. Those resources might include consumption of large amounts of memory, tying up a limited number of network ports, overloading a database with too many connections, and so on.</p>
<p>In the old days, Java programmers learned that the small number of platform threads that were practical for multi-threading indirectly acted as a throttle on excessive use of resources by the executing tasks. Now, with potentially millions of virtual threads, you may need to add explicit throttling of expensive tasks to conserve precious resources. You can use throttling mechanisms such as <a href=""https://docs.oracle.com/en%2Fjava%2Fjavase%2F22%2Fdocs%2Fapi%2F%2F/java.base/java/util/concurrent/Semaphore.html"" rel=""nofollow noreferrer""><code>Semaphore</code></a> permits or <a href=""https://docs.oracle.com/en%2Fjava%2Fjavase%2F22%2Fdocs%2Fapi%2F%2F/java.base/java/util/concurrent/locks/ReentrantLock.html"" rel=""nofollow noreferrer""><code>ReentrantLock</code></a>.</p>
<p>For more discussion, see <a href=""https://stackoverflow.com/a/78318336/642706"">Answer by Teddy</a>.</p>
<h2>Pinning</h2>
<p>A weakness in the current implementation of virtual threads is that in some cases the virtual thread is ‚Äúpinned‚Äù to its carrier platform thread, meaning it cannot be set aside while blocked for that carrier platform thread to be assigned another virtual thread. Pinning defeats the performance of virtual threads.</p>
<p>As of Java 22, pinning happens in at least two scenarios:</p>
<ul>
<li><code>synchronized</code> code.</li>
<li><a href=""https://en.wikipedia.org/wiki/Native_(computing)#Machine_code"" rel=""nofollow noreferrer"">Native code</a>, called via a mechanism such as <a href=""https://en.wikipedia.org/wiki/Java_Native_Interface"" rel=""nofollow noreferrer"">JNI</a>.</li>
</ul>
<p>To be clear: You <em>can</em> use <code>synchronized</code> and native code in your virtual threads. But if the task being executed includes significantly long periods of such work, then assign that task to a platform thread rather than a virtual threads. Or in the case of long code protected by <code>synchronized</code> (<em>long-running</em> code, not <em>all</em> code), replace with a <a href=""https://docs.oracle.com/en%2Fjava%2Fjavase%2F22%2Fdocs%2Fapi%2F%2F/java.base/java/util/concurrent/locks/ReentrantLock.html"" rel=""nofollow noreferrer""><code>ReentrantLock</code></a>. Excessive pinning impairs the efficiency and effectiveness of other virtual thread usages.</p>
<p>The <a href=""https://wiki.openjdk.org/display/loom/Main"" rel=""nofollow noreferrer""><em>Project Loom</em></a> team continues their work. They are looking into ways to decrease situations resulting in pinning. So the situation will likely change in future versions of Java. See 2024-10 update in <a href=""https://youtu.be/3BFcYTpHwHw?si=GP6iHG_vHoohxkWi"" rel=""nofollow noreferrer"">video by Alan Bateman</a>.</p>
<p>You can easily detect protracted pinning. Java will emit a new <a href=""https://en.wikipedia.org/wiki/JDK_Flight_Recorder"" rel=""nofollow noreferrer""><em>JDK Flight Recorder (JFR)</em></a> event, <code>jdk.VirtualThreadPinned</code>, every time a Virtual Thread gets pinned, with a threshold of 20ms by default.</p>
<h2>For more info</h2>
<p>For details, see firstly the official document, <a href=""https://openjdk.org/jeps/444"" rel=""nofollow noreferrer""><em>JEP 444: Virtual Threads</em></a>. See also the official <a href=""https://wiki.openjdk.org/display/loom/Main"" rel=""nofollow noreferrer""><em>Project Loom</em></a> site.</p>
<p>Then see the more recent videos of presentations by <a href=""https://inside.java/u/RonPressler/"" rel=""nofollow noreferrer"">Ron Pressler</a>, <a href=""https://inside.java/u/AlanBateman/"" rel=""nofollow noreferrer"">Alan Bateman</a>, or <a href=""https://inside.java/u/JosePaumard/"" rel=""nofollow noreferrer"">Jos√© Paumard</a>. Publicly available on YouTube, etc.</p>
<p>See an entire presentation focused on this topic: <a href=""https://youtu.be/zPhkg8dYysY?si=Ti9_bxnX1ckYkeck"" rel=""nofollow noreferrer""><em>Are Virtual Threads Going to Make Reactive Programming Irrelevant?</em></a>, 2024-10, by Jos√© Paumard.</p>
<p>If you <em>really</em> want to understand how the impressive performance gains were made, see the talk on <a href=""https://en.wikipedia.org/wiki/Continuation"" rel=""nofollow noreferrer"">Continuations</a> by Ron Pressler: <a href=""https://youtu.be/6nRS6UiN7X0?si=iVwh35oGJ2BzzGF3"" rel=""nofollow noreferrer""><em>Continuations - Under the Covers</em></a>. To be clear: This understanding is entirely optional, unnecessary to making effective use of virtual threads. But if you need to satisfy your geek curiosity, you‚Äôll enjoy that particular talk by Pressler.</p>
","java, multithreading, virtual-threads"
Apr-24,Apr-24,"<p>Trying to generate a number using MAX_SAFE_INTEGER I noticed something strange, I'm sure it has to do with the way numbers are stored in JavaScript, but I don't understand what exactly it is.</p>
<pre><code>// Always returns an odd number
Math.floor(Math.random() * Number.MAX_SAFE_INTEGER)

// Returns an odd number 75% of the time
Math.floor(Math.random() * (Number.MAX_SAFE_INTEGER - 1))

// Has a 50/50 chance to return odd or even
Math.ceil(Math.random() * Number.MAX_SAFE_INTEGER)
</code></pre>
<p>How can this behavior be explained and what would be the largest integer you can use in <code>Math.floor</code> to get a 50/50 ratio?</p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>let evenCount = 0, oddCount = 0;

for (let i = 0; i &lt; 10000; i++) {
  const randomNumber = Math.floor(Math.random() * Number.MAX_SAFE_INTEGER);
  if (randomNumber % 2 === 0) {
    evenCount++;
  } else {
    oddCount++;
  }
}

console.log(""Number of even numbers:"", evenCount);
console.log(""Number of odd numbers:"", oddCount);</code></pre>
</div>
</div>
</p>
",25,"<p>First, you should multiply by 2<sup>53</sup> (<code>Number.MAX_SAFE_INTEGER + 1</code>) to get all 53 bits from a <code>Math.random</code> implementation that uses the full double precision. 2<sup>53</sup>‚àí1 doesn‚Äôt hurt much (it maps both 0 and 2<sup>‚àí53</sup> to 0, producing a tiny bias), but it‚Äôs better to pick the solution that‚Äôs obviously correct.</p>
<p>But then what‚Äôs the issue? Well, your original code works fine on Firefox and Safari! It‚Äôs just that V8 (i.e. Chrome and derivatives) uses 52 bits instead of 53.</p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>let mostBits = 0;

for (let i = 0; i &lt; 10000; i++) {
    const bits = Math.random().toString(2).slice(2).length;
    if (bits &gt; mostBits) {
        mostBits = bits;
    }
}

console.log(""Most bits:"", mostBits);</code></pre>
</div>
</div>
</p>
<p>(Firefox, Safari)</p>
<blockquote>
<p>Most bits: 53</p>
</blockquote>
<p>(Chrome)</p>
<blockquote>
<p>Most bits: 52</p>
</blockquote>
<p>(The reason that you can store 53 bits accurately with a significand with 52 bits of storage is that the integer part is implicitly a 1 that can be scaled to the right place by the exponent, same as why <code>Number.MAX_SAFE_INTEGER</code> is what it is.)</p>
<p>Looking at <a href=""https://github.com/v8/v8/blob/fa10a1917f41dc1028c9f55fb92e7fcc33c34b79/src/base/utils/random-number-generator.h#L111-L116"" rel=""noreferrer"">the relevant part of V8‚Äôs implementation</a>, I assume the only reason it does this is for performance ‚Äì by fixing the exponent to make the range [1, 2), it can insert the random bits directly into the double instead of having to perform a multiplication.</p>
<blockquote>
<pre class=""lang-cpp prettyprint-override""><code>static inline double ToDouble(uint64_t state0) {
  // Exponent for double values for [1.0 .. 2.0)
  static const uint64_t kExponentBits = uint64_t{0x3FF0000000000000};
  uint64_t random = (state0 &gt;&gt; 12) | kExponentBits;
  return base::bit_cast&lt;double&gt;(random) - 1;
}
</code></pre>
</blockquote>
<p>Why does multiplying a number in the final result‚Äôs range by 2<sup>53</sup>‚àí1 and then flooring it always produce an odd number?</p>
<ul>
<li><p>(2<sup>53</sup>‚àí1)x = 2<sup>53</sup> x ‚àí x (exactly)</p>
</li>
<li><p>2<sup>53</sup> x is always even</p>
</li>
<li><p>In order for 2<sup>53</sup> x ‚àí x to round to the exact floating-point value 2<sup>53</sup> x (and therefore be an even number), x has to be smaller than 2<sup>53</sup> x‚Äôs ULP (unit in the last place) ‚Äì which it never can be! x‚Äôs ULP is 1/2<sup>53</sup> of the value of its most significant bit, which is ‚â§ x.</p>
</li>
</ul>
<p>So to answer your question,</p>
<blockquote>
<p>what would be the largest integer you can use in <code>Math.floor</code> to get a 50/50 ratio?</p>
</blockquote>
<p>At most 2<sup>52</sup>, but I wouldn‚Äôt <em>count</em> on <code>Math.random</code> having more than 32 bits of randomness unless you‚Äôre only targeting one engine (V8 changed to 52 <a href=""https://v8.dev/blog/math-random"" rel=""noreferrer"">in 2015</a>, for example), or even on it being good enough randomness for a particular purpose ‚Äì none of this stuff is in <a href=""https://tc39.es/ecma262/#sec-math.random"" rel=""noreferrer"">the spec</a>.</p>
<blockquote>
<p>This function returns a Number value with positive sign, greater than or equal to +0 but strictly less than 1, chosen randomly or pseudo randomly with approximately uniform distribution over that range, <strong>using an implementation-defined algorithm or strategy</strong>.</p>
</blockquote>
<p>You might want to consider implementing a known PRNG in JavaScript and seeding it with strong randomness from <a href=""https://developer.mozilla.org/en-US/docs/Web/API/Crypto/getRandomValues"" rel=""noreferrer""><code>crypto.getRandomValues</code></a>.</p>
","javascript, v8"
Apr-24,Apr-24,"<p>When I run this simple code snippet of a JavaFX TextField element, I type something into the text field, and then StringIndexOutOfBoundsException is thrown periodically.</p>
<h3>versions</h3>
<pre><code>JDK: 21.0.0, 21.0.2, 1.8
JavaFX: 
`javafx.runtime.version=8.0.65 javafx.runtime.build=b17`
`javafx.version=21 javafx.runtime.version=21+31 javafx.runtime.build=31`
Windows:
`Edition=Windows 11 Pro, Version=23H2`
</code></pre>
<h2>Error Message</h2>
<pre><code>Exception in thread &quot;JavaFX Application Thread&quot; java.lang.StringIndexOutOfBoundsException: Range [1, -2147483648) out of bounds for length 1
    at java.base/jdk.internal.util.Preconditions$1.apply(Preconditions.java:55)
    at java.base/jdk.internal.util.Preconditions$1.apply(Preconditions.java:52)
    at java.base/jdk.internal.util.Preconditions$4.apply(Preconditions.java:213)
    at java.base/jdk.internal.util.Preconditions$4.apply(Preconditions.java:210)
    at java.base/jdk.internal.util.Preconditions.outOfBounds(Preconditions.java:98)
    at java.base/jdk.internal.util.Preconditions.outOfBoundsCheckFromToIndex(Preconditions.java:112)
    at java.base/jdk.internal.util.Preconditions.checkFromToIndex(Preconditions.java:349)
    at java.base/java.lang.String.checkBoundsBeginEnd(String.java:4861)
    at java.base/java.lang.String.substring(String.java:2830)
    at javafx.graphics@21/com.sun.glass.ui.win.WinTextRangeProvider.GetText(WinTextRangeProvider.java:367)
    at javafx.graphics@21/com.sun.glass.ui.win.WinApplication._runLoop(Native Method)
    at javafx.graphics@21/com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:185)
    at java.base/java.lang.Thread.run(Thread.java:1583)
</code></pre>
<h2>source code</h2>
<pre class=""lang-java prettyprint-override""><code>package comp3111.qsproject;

// Java program to create a textfield and add it to stage
import javafx.application.Application;
import javafx.scene.Scene;
import javafx.scene.control.*;
import javafx.scene.layout.StackPane;
import javafx.stage.Stage;

public class TextFieldTest extends Application {

    // launch the application
    public void start(Stage s)
    {
        // set title for the stage
        s.setTitle(&quot;creating TextField&quot;);

        // create a textfield
        TextField b = new TextField();

        // create a stack pane
        StackPane r = new StackPane();

        // add textfield
        r.getChildren().add(b);

        // create a scene
        Scene sc = new Scene(r, 200, 200);

        // set the scene
        s.setScene(sc);

        s.show();
    }

    public static void main(String args[])
    {
        // launch the application
        launch(args);
    }
}
</code></pre>
<p>This problem was not resolved when I reinstalled my JDK.</p>
",5,"<p>Workaround: <strong>Close other running apps</strong>.</p>
<p><strong>Update</strong>: There is an official issue for this: <a href=""https://bugs.openjdk.org/browse/JDK-8330462"" rel=""nofollow noreferrer"">https://bugs.openjdk.org/browse/JDK-8330462</a>.</p>
<p>At <a href=""https://github.com/JabRef/jabref/issues/11151#issuecomment-2060779820"" rel=""nofollow noreferrer"">JabRef#11151</a> it was reported that the <a href=""https://www.deepl.com/en/app/"" rel=""nofollow noreferrer"">DeepL Windows App</a> caused the issue. I tried it on my Windows 10 machine. Having DeepL running: Error appears. DeepL closed: Error gone.</p>
<hr />
<p>For the others to reproduce:</p>
<ol>
<li>Go to <a href=""https://www.deepl.com/en/app/"" rel=""nofollow noreferrer"">https://www.deepl.com/en/app/</a></li>
<li>Download the app</li>
<li>Install the app for the current user</li>
<li>Start the app</li>
<li>Mark some text</li>
<li>Press <kbd>Ctrl</kbd>+<kbd>C</kbd>+<kbd>C</kbd> to check that DeepL really runs</li>
<li>Switch to a JavaFX appp</li>
<li>Enter something in a text field</li>
<li>You should see the exception</li>
</ol>
<p>If you could reproduce (or not), please share details at <a href=""https://github.com/koppor/jfx/pull/2"" rel=""nofollow noreferrer"">https://github.com/koppor/jfx/pull/2</a>. It seems that not all persons can reproduce and there could be some specific setups. - I personally fired up a fresh Windows on Azure, created another user login (without (!) admin rights), logged in with that user and could reproduce. The issue does not appear if logged in as administrator!</p>
","java, javafx, indexoutofboundsexception, gluon"
May-24,May-24,"<p>I am following the example for <code>useActionState</code> <a href=""https://react.dev/reference/react/useActionState"" rel=""noreferrer"">found here</a>. I am using nextjs and typescript.</p>
<p><code>app/page.tsx</code>:</p>
<pre><code>&quot;use client&quot;;

import { useActionState } from &quot;react&quot;;
import { createUser } from &quot;../components/actions&quot;;

const initialState = {
  message: &quot;&quot;,
};

export default function App() {
  const [state, formAction] = useActionState(createUser, initialState);

  return (
    &lt;form action={formAction}&gt;
      &lt;label htmlFor=&quot;email&quot;&gt;Email&lt;/label&gt;
      &lt;input type=&quot;text&quot; id=&quot;email&quot; name=&quot;email&quot; required /&gt;
      {/* ... */}
      &lt;p aria-live=&quot;polite&quot; className=&quot;sr-only&quot;&gt;
        {state?.message}
      &lt;/p&gt;
      &lt;button&gt;Sign up&lt;/button&gt;
    &lt;/form&gt;
  );
}
</code></pre>
<p><code>../components/actions.ts</code>:</p>
<pre><code>'use server'
 
export default async function createUser(prevState: any, formData: FormData) {
  return {
    message: 'Please enter a valid email',
  }
}
</code></pre>
<p>When I run the example, I get:
<code>Error: (0 , react__WEBPACK_IMPORTED_MODULE_1__.useActionState) is not a function or its return value is not iterable</code></p>
<p>My package.json looks like:</p>
<pre><code>{
  &quot;scripts&quot;: {
    &quot;dev&quot;: &quot;next dev&quot;,
    &quot;build&quot;: &quot;next build&quot;,
    &quot;start&quot;: &quot;next start&quot;,
    &quot;lint&quot;: &quot;next lint&quot;,
    &quot;db:migrate&quot;: &quot;TS_NODE_COMPILER_OPTIONS='{ \&quot;module\&quot;: \&quot;commonjs\&quot; }' knex migrate:latest&quot;,
    &quot;db:migrate:undo&quot;: &quot;TS_NODE_COMPILER_OPTIONS='{ \&quot;module\&quot;: \&quot;commonjs\&quot; }' knex migrate:down&quot;,
    &quot;db:migrate:make&quot;: &quot;TS_NODE_COMPILER_OPTIONS='{ \&quot;module\&quot;: \&quot;commonjs\&quot; }' knex migrate:make&quot;
  },
  &quot;dependencies&quot;: {
    &quot;react&quot;: &quot;canary&quot;,
    &quot;react-dom&quot;: &quot;canary&quot;,
    &quot;react-scripts&quot;: &quot;^5.0.0&quot;
  },
  &quot;main&quot;: &quot;/index.js&quot;,
  &quot;devDependencies&quot;: {}
}

</code></pre>
<p>My <code>tsconfig.json</code>:</p>
<pre><code>{
  &quot;compilerOptions&quot;: {
    &quot;target&quot;: &quot;es2015&quot;,
    &quot;lib&quot;: [&quot;dom&quot;, &quot;dom.iterable&quot;, &quot;esnext&quot;],
    &quot;allowJs&quot;: true,
    &quot;skipLibCheck&quot;: true,
    &quot;strict&quot;: true,
    &quot;noEmit&quot;: true,
    &quot;esModuleInterop&quot;: true,
    &quot;module&quot;: &quot;esnext&quot;,
    &quot;moduleResolution&quot;: &quot;Node&quot;,
    &quot;resolveJsonModule&quot;: true,
    &quot;isolatedModules&quot;: true,
    &quot;jsx&quot;: &quot;preserve&quot;,
    &quot;incremental&quot;: true,
    &quot;plugins&quot;: [
      {
        &quot;name&quot;: &quot;next&quot;
      }
    ],
    &quot;paths&quot;: {
      &quot;@/*&quot;: [&quot;./*&quot;]
    }
  },
  &quot;include&quot;: [&quot;next-env.d.ts&quot;, &quot;**/*.ts&quot;, &quot;**/*.tsx&quot;, &quot;.next/types/**/*.ts&quot;],
  &quot;exclude&quot;: [&quot;node_modules&quot;]
}
</code></pre>
",14,"<p>Next.js added support for React 19 features, specifically <code>useActionState</code> in <a href=""https://github.com/vercel/next.js/pull/65058"" rel=""noreferrer"">PR 65058</a>. The <code>create-next-app</code> template added the same support in <a href=""https://github.com/vercel/next.js/pull/65058"" rel=""noreferrer"">PR 65478</a>. Versions 14.3.0-canary.45 and 14.3.0-canary.46, respectively.</p>
<p>Thus you can get support for <code>useActionState</code> in Next.js by running <code>npx create-next-app@14.3.0-canary.46</code>, or any greater version.</p>
","javascript, node.js, typescript, reactjs, next.js"
May-24,May-24,"<p>I have a code with a one-liner <code>while</code> and a <code>try</code>-<code>except</code> statement which behaves weirdly.</p>
<p>This prints 'a' on Ctrl+C:</p>
<pre class=""lang-py prettyprint-override""><code>try:
    while True:
        pass
except KeyboardInterrupt:
    print(&quot;a&quot;)
</code></pre>
<p>and this too:</p>
<pre class=""lang-py prettyprint-override""><code>try:
    i = 0
    while True: pass
except KeyboardInterrupt:
    print(&quot;a&quot;)
</code></pre>
<p>but this doesn't, and it throws a traceback:</p>
<pre class=""lang-py prettyprint-override""><code>try:
    while True: pass
except KeyboardInterrupt:
    print(&quot;a&quot;)
</code></pre>
<p>and neither does this code:</p>
<pre class=""lang-py prettyprint-override""><code>try:
    while True: pass
    i = 0
except KeyboardInterrupt:
    print(&quot;a&quot;)
</code></pre>
<p>Addition some additional details.</p>
<p>In 3.11, the instruction <code>JUMP_BACKWARD</code> was added and seems invloved with this issue see: <a href=""https://docs.python.org/3/library/dis.html#opcode-JUMP_BACKWARD"" rel=""nofollow noreferrer"">Disassembler for Python bytecode</a></p>
<p>In 3.12 when the code in the first and the 3rd blocks are disassembled the results are:</p>
<p><strong>Cannot be caught:</strong></p>
<pre><code>  0           0 RESUME                   0

  2           2 NOP

  3     &gt;&gt;    4 JUMP_BACKWARD            1 (to 4)
        &gt;&gt;    6 PUSH_EXC_INFO

  4           8 LOAD_NAME                0 (KeyboardInterrupt)
             10 CHECK_EXC_MATCH
             12 POP_JUMP_IF_FALSE       11 (to 36)
             14 POP_TOP

  5          16 PUSH_NULL
             18 LOAD_NAME                1 (print)
             20 LOAD_CONST               1 ('a')
             22 CALL                     1
             30 POP_TOP
             32 POP_EXCEPT
             34 RETURN_CONST             2 (None)

  4     &gt;&gt;   36 RERAISE                  0
        &gt;&gt;   38 COPY                     3
             40 POP_EXCEPT
             42 RERAISE                  1
ExceptionTable:
  4 to 4 -&gt; 6 [0]
  6 to 30 -&gt; 38 [1] lasti
  36 to 36 -&gt; 38 [1] lasti
None
</code></pre>
<p><strong>Can be caught:</strong></p>
<pre><code>  0           0 RESUME                   0

  2           2 NOP

  3           4 NOP

  4     &gt;&gt;    6 NOP

  3           8 JUMP_BACKWARD            2 (to 6)
        &gt;&gt;   10 PUSH_EXC_INFO

  5          12 LOAD_NAME                0 (KeyboardInterrupt)
             14 CHECK_EXC_MATCH
             16 POP_JUMP_IF_FALSE       11 (to 40)
             18 POP_TOP

  6          20 PUSH_NULL
             22 LOAD_NAME                1 (print)
             24 LOAD_CONST               1 ('a')
             26 CALL                     1
             34 POP_TOP
             36 POP_EXCEPT
             38 RETURN_CONST             2 (None)

  5     &gt;&gt;   40 RERAISE                  0
        &gt;&gt;   42 COPY                     3
             44 POP_EXCEPT
             46 RERAISE                  1
ExceptionTable:
  4 to 8 -&gt; 10 [0]
  10 to 34 -&gt; 42 [1] lasti
  40 to 40 -&gt; 42 [1] lasti
None
</code></pre>
<p>The main differences that jump out are the two additional <code>NOP</code> and the different targets for <code>JUMP_BACKWARD</code>.</p>
<p><strong>Note:</strong> the exception really cannot be caught as this will also throw the exception in 3.12</p>
<pre><code>try:
    try:
        while True: pass
    except KeyboardInterrupt:
        print(&quot;a&quot;)
except Exception:
    print(&quot;b&quot;)
</code></pre>
",7,"<p>Its a <a href=""https://github.com/python/cpython/issues/108214"" rel=""nofollow noreferrer"">known CPython bug</a> introduced in <code>3.11</code> and exists in <code>3.12</code>.</p>
<p>One of comments of the bug, mentioned that partial backport of <a href=""https://github.com/python/cpython/pull/106141"" rel=""nofollow noreferrer"">this pull request</a> looks to be the right direction to fix the bug.</p>
<p>I built and tested following CPython versions from source using pyenv on Arch Linux with GCC 14.1.1 compiler:</p>
<ul>
<li><code>3.11-dev</code>: <code>Python 3.11.9+ (heads/3.11:ba43157, May 20 2024, 04:40:02)</code></li>
<li><code>3.12-dev</code>: <code>Python 3.12.3+ (heads/3.12:30c687c, May 20 2024, 04:38:13)</code></li>
<li><code>3.13.0b1</code>: <code>Python 3.13.0b1 (main, May 20 2024, 04:14:35)</code></li>
<li><code>3.13-dev</code>: <code>Python 3.13.0b1+ (heads/3.13:27b61c1, May 20 2024, 04:24:49)</code></li>
<li><code>3.14-dev</code>: <code>Python 3.14.0a0 (heads/main:0abf997, May 20 2024, 08:25:05)</code></li>
</ul>
<p>In <code>3.13.0b1</code>, <code>3.13-dev</code> and <code>3.14-dev</code> the bug is fixed üòÄüëç and exception handling works as expected.</p>
<p>But <code>3.11-dev</code> and <code>3.12-dev</code> still have the bug.</p>
<p>I hope it will be backport to existing stable <code>3.11</code> and <code>3.12</code> versions (in-time for inclusion in the next <code>3.11.10</code> and <code>3.12.4</code> bug-fix releases respectively).</p>
<p><strong>EDIT 1:</strong> <code>3.12.4</code> released in 2024-06-06: the bug didn't fixed.</p>
<p><strong>EDIT 2:</strong> <code>3.12.5</code> released in 2024-08-06: the bug didn't fixed.</p>
","python, try-catch"
May-24,May-24,"<p>I'm trying to train a model with Yolov8. Everything was good but today I suddenly notice getting this warning apparently related to <code>PyTorch</code> and <code>cuDNN</code>. In spite the warning, the training seems to be progressing though. I'm not sure if it has any negative effects on the training progress.</p>
<pre><code>site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
</code></pre>
<p><strong>What is the problem and how to address this?</strong></p>
<p>Here is the output of <code>collect_env</code>:</p>
<pre><code>Collecting environment information...
PyTorch version: 2.3.0+cu118
Is debug build: False
CUDA used to build PyTorch: 11.8
ROCM used to build PyTorch: N/A
OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
Clang version: Could not collect
CMake version: version 3.29.3
Libc version: glibc-2.31
Python version: 3.9.7 | packaged by conda-forge | (default, Sep  2 2021, 17:58:34)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.15.0-69-generic-x86_64-with-glibc2.31
Is CUDA available: True
CUDA runtime version: 11.8.89
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: 
GPU 0: NVIDIA A100 80GB PCIe
Nvidia driver version: 515.105.01
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.8.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.8.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.8.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.8.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.8.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.8.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.8.0
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True
CPU:
Architecture:                    x86_64

Versions of relevant libraries:
[pip3] numpy==1.26.4
[pip3] onnx==1.16.0
[pip3] onnxruntime==1.17.3
[pip3] onnxruntime-gpu==1.17.1
[pip3] onnxsim==0.4.36
[pip3] optree==0.11.0
[pip3] torch==2.3.0+cu118
[pip3] torchaudio==2.3.0+cu118
[pip3] torchvision==0.18.0+cu118
[pip3] triton==2.3.0
[conda] numpy                     1.24.4                   pypi_0    pypi
[conda] pytorch-quantization      2.2.1                    pypi_0    pypi
[conda] torch                     2.1.1+cu118              pypi_0    pypi
[conda] torchaudio                2.1.1+cu118              pypi_0    pypi
[conda] torchmetrics              0.8.0                    pypi_0    pypi
[conda] torchvision               0.16.1+cu118             pypi_0    pypi
[conda] triton                    2.1.0                    pypi_0    pypi

</code></pre>
",4,"<p><strong>June 2024 Solution</strong>: Upgrade torch version to 2.3.1 to fix it:</p>
<p><code>pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118</code></p>
","python, nvidia, cudnn, pytorch, torchvision"
May-24,May-24,"<p>Normally, if you try to pass multiple values for the same keyword argument, you get a TypeError:</p>
<pre><code>In [1]: dict(id=1, **{'id': 2})
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Input In [1], in &lt;cell line: 1&gt;()
----&gt; 1 dict(id=1, **{'id': 2})

TypeError: dict() got multiple values for keyword argument 'id'
</code></pre>
<p>But if you do it <em>while handling another exception</em>, you get a KeyError instead:</p>
<pre><code>In [2]: try:
   ...:     raise ValueError('foo') # no matter what kind of exception
   ...: except:
   ...:     dict(id=1, **{'id': 2}) # raises: KeyError: 'id'
   ...: 
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Input In [2], in &lt;cell line: 1&gt;()
      1 try:
----&gt; 2     raise ValueError('foo') # no matter what kind of exception
      3 except:

ValueError: foo

During handling of the above exception, another exception occurred:

KeyError                                  Traceback (most recent call last)
Input In [2], in &lt;cell line: 1&gt;()
      2     raise ValueError('foo') # no matter what kind of exception
      3 except:
----&gt; 4     dict(id=1, **{'id': 2})

KeyError: 'id'
</code></pre>
<p>What's going on here? How could a completely unrelated exception affect what kind of exception <code>dict(id=1, **{'id': 2})</code> throws?</p>
<p>For context, I discovered this behavior while investigating the following bug report: <a href=""https://github.com/tortoise/tortoise-orm/issues/1583"" rel=""noreferrer"">https://github.com/tortoise/tortoise-orm/issues/1583</a></p>
<p>This has been reproduced on CPython 3.11.8, 3.10.5, and 3.9.5.</p>
",48,"<p>This looks like a Python bug.</p>
<p>The code that's supposed to raise the <code>TypeError</code> works by detecting and replacing an initial <code>KeyError</code>, but this code doesn't work right. When the exception occurs in the middle of another exception handler, the code that should raise the <code>TypeError</code> fails to recognize the <code>KeyError</code>. It ends up letting the <code>KeyError</code> through, instead of replacing it with a <code>TypeError</code>.</p>
<p>The bug appears to be gone on 3.12, due to changes in the exception implementation.</p>
<hr />
<p>Here's the deep dive, for the CPython 3.11.8 source code. Similar code exists on 3.10 and 3.9.</p>
<p>As we can see by using the <a href=""https://docs.python.org/3/library/dis.html"" rel=""noreferrer""><code>dis</code></a> module to examine the bytecode for <code>dict(id=1, **{'id': 2})</code>:</p>
<pre><code>In [1]: import dis

In [2]: dis.dis(&quot;dict(id=1, **{'id': 2})&quot;)
  1           0 LOAD_NAME                0 (dict)
              2 LOAD_CONST               3 (())
              4 LOAD_CONST               0 ('id')
              6 LOAD_CONST               1 (1)
              8 BUILD_MAP                1
             10 LOAD_CONST               0 ('id')
             12 LOAD_CONST               2 (2)
             14 BUILD_MAP                1
             16 DICT_MERGE               1
             18 CALL_FUNCTION_EX         1
             20 RETURN_VALUE
</code></pre>
<p>Python uses the <code>DICT_MERGE</code> opcode to merge two dicts, to build the final keyword argument dict.</p>
<p>The relevant part of the <code>DICT_MERGE</code> <a href=""https://github.com/python/cpython/blob/v3.11.8/Python/ceval.c#L3432-L3436"" rel=""noreferrer"">code</a> is as follows:</p>
<pre><code>            if (_PyDict_MergeEx(dict, update, 2) &lt; 0) {
                format_kwargs_error(tstate, PEEK(2 + oparg), update);
                Py_DECREF(update);
                goto error;
            }
</code></pre>
<p>It uses <code>_PyDict_MergeEx</code> to attempt to merge two dicts, and if that fails (and raises an exception), it uses <code>format_kwargs_error</code> to try to raise a <em>different</em> exception.</p>
<p>When the third argument to <code>_PyDict_MergeEx</code> is <code>2</code>, that function will raise a <code>KeyError</code> for duplicate keys, inside the <a href=""https://github.com/python/cpython/blob/v3.11.8/Objects/dictobject.c#L2815"" rel=""noreferrer""><code>dict_merge</code></a> helper function. This is where the <code>KeyError</code> comes from.</p>
<p>Once the <code>KeyError</code> is raised, <code>format_kwargs_error</code> has the job of replacing it with a <code>TypeError</code>. It tries to do so with <a href=""https://github.com/python/cpython/blob/v3.11.8/Python/ceval.c#L7711-L7714"" rel=""noreferrer"">the following code</a>:</p>
<pre><code>    else if (_PyErr_ExceptionMatches(tstate, PyExc_KeyError)) {
        PyObject *exc, *val, *tb;
        _PyErr_Fetch(tstate, &amp;exc, &amp;val, &amp;tb);
        if (val &amp;&amp; PyTuple_Check(val) &amp;&amp; PyTuple_GET_SIZE(val) == 1) {
</code></pre>
<p>but this code is looking for an <em>unnormalized</em> exception, an internal way of representing exceptions that isn't exposed to Python-level code. It expects the exception value to be a 1-element tuple containing the key that the KeyError was raised for, instead of an actual exception object.</p>
<p>Exceptions raised inside C code are usually unnormalized, but not if they occur while Python is handling another exception. Unnormalized exceptions cannot handle <a href=""https://docs.python.org/3/tutorial/errors.html#exception-chaining"" rel=""noreferrer"">exception chaining</a>, which occurs automatically for exceptions raised inside an exception handler. In this case, the internal <code>_PyErr_SetObject</code> routine will <a href=""https://github.com/python/cpython/blob/v3.11.8/Python/errors.c#L123-L128"" rel=""noreferrer"">automatically normalize</a> the exception:</p>
<pre><code>    exc_value = _PyErr_GetTopmostException(tstate)-&gt;exc_value;
    if (exc_value != NULL &amp;&amp; exc_value != Py_None) {
        /* Implicit exception chaining */
        Py_INCREF(exc_value);
        if (value == NULL || !PyExceptionInstance_Check(value)) {
            /* We must normalize the value right now */
</code></pre>
<p>Since the <code>KeyError</code> has been normalized, <code>format_kwargs_error</code> doesn't understand what it's looking at. It lets the <code>KeyError</code> through, instead of raising the <code>TypeError</code> it's supposed to.</p>
<hr />
<p>On Python 3.12, things are different. The internal exception representation has been changed, so any raised exception is <em>always</em> normalized. Thus, the Python 3.12 version of <a href=""https://github.com/python/cpython/blob/v3.12.3/Python/ceval.c#L2682-L2685"" rel=""noreferrer""><code>format_kwargs_error</code></a> looks for a normalized exception instead of an unnormalized exception, and if <code>_PyDict_MergeEx</code> has raised a <code>KeyError</code>, the code will recognize it:</p>
<pre><code>    else if (_PyErr_ExceptionMatches(tstate, PyExc_KeyError)) {
        PyObject *exc = _PyErr_GetRaisedException(tstate);
        PyObject *args = ((PyBaseExceptionObject *)exc)-&gt;args;
        if (exc &amp;&amp; PyTuple_Check(args) &amp;&amp; PyTuple_GET_SIZE(args) == 1) {
</code></pre>
","python, cpython"
May-24,May-24,"<pre class=""lang-py prettyprint-override""><code>import typing

a: dict[int, int] = {}
b: dict[int, int | str] = a
c: typing.Mapping[int, int | str] = a
d: typing.Mapping[int | str, int] = a
</code></pre>
<p>Pylance reports an error for <code>b: dict[int, int | str] = a</code>:</p>
<pre class=""lang-none prettyprint-override""><code>Expression of type &quot;dict[int, int]&quot; is incompatible with declared type &quot;dict[int, int | str]&quot;
  &quot;dict[int, int]&quot; is incompatible with &quot;dict[int, int | str]&quot;
    Type parameter &quot;_VT@dict&quot; is invariant, but &quot;int&quot; is not the same as &quot;int | str&quot;
    Consider switching from &quot;dict&quot; to &quot;Mapping&quot; which is covariant in the value type
</code></pre>
<p>But <code>c: typing.Mapping[int, int | str] = a</code> is OK.</p>
<p>Additionally, <code>d: typing.Mapping[int | str, int] = a</code> also gets an error:</p>
<pre class=""lang-none prettyprint-override""><code>Expression of type &quot;dict[int, int]&quot; is incompatible with declared type &quot;Mapping[int | str, int]&quot;
  &quot;dict[int, int]&quot; is incompatible with &quot;Mapping[int | str, int]&quot;
    Type parameter &quot;_KT@Mapping&quot; is invariant, but &quot;int&quot; is not the same as &quot;int | str&quot;
</code></pre>
<p>Why are these types hint incompatible?<br />
If a function declares a parameter of type <code>dict[int, int | str]</code>, how can I pass a <code>dict[int, int]</code> object as its parameter?</p>
",29,"<p><code>dict</code> type was designed to be completely <em><strong>invariant</strong></em> on key and value. Hence when you assign <code>dict[int, <b>int</b>]</code> to <code>dict[int, <b>int | str</b>]</code>, you make the type system raise errors. <sup>[1]</sup></p>
<p><code>Mapping</code> type on the other hand wasn‚Äôt designed to be completely invariant but rather is <em><strong>invariant on key</strong></em> and <em><strong>covariant on value</strong></em>. Hence you can assign one <code>Mapping</code> type (<code>dict[int, <b>int</b>]</code>) to another (<code>Mapping[int, <b>int | str</b>]</code>) if they are both covariant on value. if they are invariant on key, you can assign them else you cannot. Hence when you assign <code>dict[<b>int</b>, int]</code> to <code>Mapping[<b>int | str</b>, int]</code>, you make the type system raise errors. <sup>[2][3]</sup></p>
<p>There is a good reason for the above design in the type system and I will give a few:</p>
<p><em><strong>1</strong></em>. <code>dict</code> type is a concrete type so it will actually get used in a program.</p>
<p><em><strong>2</strong></em>. Because of the above mentioned, it was designed the way it was to avoid things like this:</p>
<pre><code>a: dict[int, int] = {}
b: dict[int, int | str] = a
b[0] = <b>0xDEADBEEF</b>
b[1] = <b>""Bull""</b></code></pre>
<p><em><strong><code>dict</code>s are assigned by reference</strong></em> <sup>[4]</sup> hence any mutation to <code>b</code> is actually a mutation to <code>a</code>. So if one reads <code>a</code> as follows:</p>
<pre><code>x: int = a[0]
assert isinstance(x, int)
y: int = a[1]
assert isinstance(y, int)</code></pre>
<p>One gets unexpected results. <code>x</code> passes but <code>y</code> doesn‚Äôt. It then seems like the type system is contradicting itself. This can cause worse problems in a program.</p>
<p><em>For posterity, to correctly type a dictionary in Python, use <code>Mapping</code> type to denote a readonly dictionary and use <code>MutableMapping</code> type to denote a read-write dictionary</em>.</p>
<hr/>
<p><sub><sup>[1]</sup> Of course Python‚Äôs type system doesn‚Äôt influence program‚Äôs running behaviour but at least linters have some use of this.</sub></p>
<p><sub><sup>[2]</sup> <code>dict</code> type is a <code>Mapping</code> type but <code>Mapping</code> type is not a <code>dict</code> type.</sub></p>
<p><sub><sup>[3]</sup> Keep in mind that the <em>ordering of types</em> is important in type theory.</sub></p>
<p><sub><sup>[4]</sup> <strong>All variable names in Python are references to values</strong>.</sub></p>
","python, type-theory, python-typing"
Jun-24,Jun-24,"<h2>MRE</h2>
<pre><code>pip install pandas==2.1.1 numpy==2.0.0
</code></pre>
<p><code>Python 3.10</code> on Google Colab</p>
<p>Output</p>
<pre><code>Collecting pandas==2.1.1
  Downloading pandas-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)
     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12.3/12.3 MB 44.7 MB/s eta 0:00:00
Collecting numpy==2.0.0
  Using cached numpy-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.1) (2.8.2)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.1) (2023.4)
Requirement already satisfied: tzdata&gt;=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.1) (2024.1)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.8.2-&gt;pandas==2.1.1) (1.16.0)
Installing collected packages: numpy, pandas
  Attempting uninstall: numpy
    Found existing installation: numpy 1.26.4
    Uninstalling numpy-1.26.4:
      Successfully uninstalled numpy-1.26.4
  Attempting uninstall: pandas
    Found existing installation: pandas 2.0.3
    Uninstalling pandas-2.0.3:
      Successfully uninstalled pandas-2.0.3

Successfully installed numpy-2.0.0 pandas-2.1.1
</code></pre>
<p>When I do :</p>
<pre><code>import pandas
</code></pre>
<p>I get this error:</p>
<pre><code>Traceback (most recent call last):  File &quot;/usr/lib/python3.10/runpy.py&quot;, line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File &quot;/usr/lib/python3.10/runpy.py&quot;, line 86, in _run_code
    exec(code, run_globals)
  File &quot;/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py&quot;, line 37, in &lt;module&gt;
    ColabKernelApp.launch_instance()
  File &quot;/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py&quot;, line 992, in launch_instance
    app.start()
  File &quot;/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py&quot;, line 619, in start
    self.io_loop.start()
  File &quot;/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py&quot;, line 195, in start
    self.asyncio_loop.run_forever()
  File &quot;/usr/lib/python3.10/asyncio/base_events.py&quot;, line 603, in run_forever
    self._run_once()
  File &quot;/usr/lib/python3.10/asyncio/base_events.py&quot;, line 1909, in _run_once
    handle._run()
  File &quot;/usr/lib/python3.10/asyncio/events.py&quot;, line 80, in _run
    self._context.run(self._callback, *self._args)
  File &quot;/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py&quot;, line 685, in &lt;lambda&gt;
    lambda f: self._run_callback(functools.partial(callback, future))
  File &quot;/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py&quot;, line 738, in _run_callback
    ret = callback()
  File &quot;/usr/local/lib/python3.10/dist-packages/tornado/gen.py&quot;, line 825, in inner
    self.ctx_run(self.run)
  File &quot;/usr/local/lib/python3.10/dist-packages/tornado/gen.py&quot;, line 786, in run
    yielded = self.gen.send(value)
  File &quot;/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py&quot;, line 361, in process_one
    yield gen.maybe_future(dispatch(*args))
  File &quot;/usr/local/lib/python3.10/dist-packages/tornado/gen.py&quot;, line 234, in wrapper
    yielded = ctx_run(next, result)
  File &quot;/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py&quot;, line 261, in dispatch_shell
    yield gen.maybe_future(handler(stream, idents, msg))
  File &quot;/usr/local/lib/python3.10/dist-packages/tornado/gen.py&quot;, line 234, in wrapper
    yielded = ctx_run(next, result)
  File &quot;/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py&quot;, line 539, in execute_request
    self.do_execute(
  File &quot;/usr/local/lib/python3.10/dist-packages/tornado/gen.py&quot;, line 234, in wrapper
    yielded = ctx_run(next, result)
  File &quot;/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py&quot;, line 302, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File &quot;/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py&quot;, line 539, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py&quot;, line 2975, in run_cell
    result = self._run_cell(
  File &quot;/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py&quot;, line 3030, in _run_cell
    return runner(coro)
  File &quot;/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py&quot;, line 78, in _pseudo_sync_runner
    coro.send(None)
  File &quot;/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py&quot;, line 3257, in run_cell_async
    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,
  File &quot;/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py&quot;, line 3473, in run_ast_nodes
    if (await self.run_code(code, result,  async_=asy)):
  File &quot;/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py&quot;, line 3553, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &quot;&lt;ipython-input-1-38d4b0363d82&gt;&quot;, line 1, in &lt;cell line: 1&gt;
    import pandas
  File &quot;/usr/local/lib/python3.10/dist-packages/pandas/__init__.py&quot;, line 23, in &lt;module&gt;
    from pandas.compat import (
  File &quot;/usr/local/lib/python3.10/dist-packages/pandas/compat/__init__.py&quot;, line 27, in &lt;module&gt;
    from pandas.compat.pyarrow import (
  File &quot;/usr/local/lib/python3.10/dist-packages/pandas/compat/pyarrow.py&quot;, line 8, in &lt;module&gt;
    import pyarrow as pa
  File &quot;/usr/local/lib/python3.10/dist-packages/pyarrow/__init__.py&quot;, line 65, in &lt;module&gt;
    import pyarrow.lib as _lib
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
AttributeError: _ARRAY_API not found
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-1-38d4b0363d82&gt; in &lt;cell line: 1&gt;()
----&gt; 1 import pandas

2 frames
/usr/local/lib/python3.10/dist-packages/pandas/_libs/__init__.py in &lt;module&gt;
     16 import pandas._libs.pandas_parser  # noqa: E501 # isort: skip # type: ignore[reportUnusedImport]
     17 import pandas._libs.pandas_datetime  # noqa: F401,E501 # isort: skip # type: ignore[reportUnusedImport]
---&gt; 18 from pandas._libs.interval import Interval
     19 from pandas._libs.tslibs import (
     20     NaT,

interval.pyx in init pandas._libs.interval()

ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject
</code></pre>
",47,"<p>I found a solution for now:</p>
<h2>I need to downgrade <code>numpy</code> to version <code>1.26.4</code></h2>
<pre><code>pip install numpy==1.26.4
</code></pre>
<p>or</p>
<pre><code>pip install &quot;numpy&lt;2&quot;
</code></pre>
<p>Restart session after downgrading <code>numpy</code></p>
<p><a href=""https://i.sstatic.net/re3JVkZ1.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/re3JVkZ1.png"" alt=""enter image description here"" /></a></p>
<p>Was able to successfully import pandas.</p>
<p><a href=""https://i.sstatic.net/82p8a0KT.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/82p8a0KT.png"" alt=""enter image description here"" /></a></p>
<hr />
<p>Related  git : <strong><a href=""https://github.com/numpy/numpy/issues/26710"" rel=""noreferrer"">https://github.com/numpy/numpy/issues/26710</a></strong></p>
","python, numpy, pip, python-3.x, pandas"
Jun-24,Jun-24,"<p>Attached is a picture with curved lines, how can you find the <strong>Baseline</strong> of the text?</p>
<p><a href=""https://i.sstatic.net/269aSnEM.jpg"" rel=""noreferrer""><img src=""https://i.sstatic.net/269aSnEM.jpg"" alt=""enter image description here"" /></a></p>
<p>The goal is to get lines like I drew by hand in the following picture:
<a href=""https://i.sstatic.net/A29bR6t8.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/A29bR6t8.png"" alt=""enter image description here"" /></a></p>
<p>I tried the following code, but letters like g p q y and similar break the line.</p>
<pre class=""lang-py prettyprint-override""><code>import cv2 as cv
import numpy as np

src = cv.imread(&quot;boston_cooking_a.jpg&quot;, cv.IMREAD_GRAYSCALE)
src = cv.adaptiveThreshold(src=src, maxValue=255, blockSize=55, C=11, thresholdType=cv.THRESH_BINARY, adaptiveMethod=cv.ADAPTIVE_THRESH_MEAN_C)
src = cv.dilate(src, cv.getStructuringElement(ksize=(3, 3), shape=cv.MORPH_RECT))
src = cv.erode(src, cv.getStructuringElement(ksize=(50, 3), shape=cv.MORPH_RECT))
src = cv.Sobel(src, ddepth=0, dx=0, dy=1, ksize=5)
cv.imwrite(&quot;test.jpg&quot;, src)
cv.imshow(&quot;src&quot;, src)
cv.waitKey(0)
</code></pre>
<p><a href=""https://i.sstatic.net/4gtjsiLj.jpg"" rel=""noreferrer""><img src=""https://i.sstatic.net/4gtjsiLj.jpg"" alt=""enter image description here"" /></a></p>
<p><strong>EDIT:</strong></p>
<p>Attached is another image to test your answer on, so we can make sure the answer doesn't suffer from &quot;overfitting&quot; to a single image.</p>
<p><a href=""https://i.sstatic.net/bZzzEeCU.jpg"" rel=""noreferrer""><img src=""https://i.sstatic.net/bZzzEeCU.jpg"" alt=""enter image description here"" /></a></p>
",10,"<p>I found an approach which is a possibility to find your lines in ‚Äûpure‚Äú opencv. The  suggested solution is not perfect, but demonstrates a first direction.
Maybe you should use <a href=""https://pypi.org/project/pytesseract/"" rel=""noreferrer"">pytesseract</a> to follow up your overall goal ?
In general the suggested solution below is quite
sensitive to the parameters of the first filter A.
The basics pseudo code steps are:</p>
<ul>
<li>A) apply filters to merge letters to words</li>
<li>B) select contours of words (filter by: ratio heights vs widths , area size)</li>
<li>C) get random points from word-contours using gaussian distribution and the center point centroid of contour</li>
<li>D) use linear regression to find middle line of word-contours</li>
<li>E) merge all word-contours which are neighbors to line-contours (outer middle line points are close together)</li>
<li>F) do polynomial regression 2nd order to estimate middle line of line-contours</li>
<li>G) write the found merged lines from our estimaded group line</li>
</ul>
<p>The main output for example 2 shows robust output but still has some artifacts from step 1 merge all letter to words.
<a href=""https://i.sstatic.net/T6hCiWJj.jpg"" rel=""noreferrer""><img src=""https://i.sstatic.net/T6hCiWJj.jpg"" alt=""enter image description here"" /></a></p>
<pre class=""lang-py prettyprint-override""><code>import cv2
import math
import uuid
import numpy as np
from scipy import stats

def resizeImageByPercentage(img,scalePercent = 60):
    width = int(img.shape[1] * scalePercent / 100)
    height = int(img.shape[0] * scalePercent / 100)
    dim = (width, height)
    # resize image
    return cv2.resize(img, dim, interpolation = cv2.INTER_AREA)

def calcMedianContourWithAndHeigh(contourList):
    hs = list()
    ws = list()
    for cnt in contourList:
        (x, y, w, h) = cv2.boundingRect(cnt)
        ws.append(w)
        hs.append(h)
    return np.median(ws),np.median(hs)

def calcCentroid(contour):
    houghMoments = cv2.moments(contour)
    # calculate x,y coordinate of centroid
    if houghMoments[&quot;m00&quot;] != 0: #case no contour could be calculated
        cX = int(houghMoments[&quot;m10&quot;] / houghMoments[&quot;m00&quot;])
        cY = int(houghMoments[&quot;m01&quot;] / houghMoments[&quot;m00&quot;])
    else:
    # set values as what you need in the situation
        cX, cY = -1, -1
    return cX,cY

def applyDilateImgFilter(img,kernelSize= 3,iterations=1):
    img_bin = 255 - img #invert
    kernel = np.ones((kernelSize,kernelSize),np.uint8)
    img_dilated = cv2.dilate(img_bin, kernel, iterations = iterations)
    return (255- img_dilated) #invert back

def randomColor():
    return tuple(np.random.randint(0, 255, 3).tolist())

def drawGaussianValuesInsideRange(start, end, center, stdDev, amountValues):
    values = []
    if center &lt; 0:
        return values
    if start &gt; end:
        return values
    while len(values) &lt; amountValues:
        valueListPotencial = np.random.normal(center, stdDev, amountValues)
        valueListFiltered = [value for value in valueListPotencial if start &lt;= value &lt;= end]
        values.extend(valueListFiltered)
    return values[:amountValues]

def drawRandomPointsInPolygon(amountPoints, cntFactObj):
    pointList = list()
    if not isinstance(cntFactObj, ContourFacts):
        return pointList
    #we calc basic parameter from random point selection
    horizontalStart = cntFactObj.x
    horizontalEnd = cntFactObj.x + cntFactObj.w
    verticalStart = cntFactObj.y
    verticalEnd = cntFactObj.y + cntFactObj.h  
    #calc std deviation connected to length and ratio
    horitonalStdDeviation = 1 / cntFactObj.ratioHeightoWidth * (horizontalEnd-horizontalStart)
    verticalStdDeviation = 1 / cntFactObj.ratioHeightoWidth * (verticalEnd-verticalStart)
    while len(pointList)&lt;amountPoints:
        if cntFactObj.centoird[0] &lt; 0 or cntFactObj.centoird[1] &lt; 0:
            return pointList
        drawXValues = drawGaussianValuesInsideRange(horizontalStart, horizontalEnd, cntFactObj.centoird[0],
                                          horitonalStdDeviation, amountPoints)
        drawYValues = drawGaussianValuesInsideRange(verticalStart, verticalEnd, cntFactObj.centoird[1], 
                                         verticalStdDeviation, amountPoints)
        #we create the points and check if they are inside the polygon
        for i in range(0,len(drawXValues)):
            #create points
            point = (drawXValues[i],drawYValues[i])
            # check if the point is inside the polygon
            if cv2.pointPolygonTest(cntFactObj.contour, point, False) &gt; 0:
                pointList.append(point)
    return pointList[:amountPoints]

def drawCountourOn(img,contours,color=None):
    imgContour = img.copy()
    for i in range(len(contours)):
        if color is None:
            color = randomColor()
        cv2.drawContours(imgContour, contours, i, color, 2)
    return imgContour

DEBUGMODE = True
fileIn = &quot;bZzzEeCU.jpg&quot;#&quot;269aSnEM.jpg&quot;
img = cv2.imread(fileIn)

## A) apply filters to merge letters to words
# prepare img load
imgGrey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
#gaussian filter
imgGaussianBlur = cv2.GaussianBlur(imgGrey,(3,3),1)
#make binary img, black and white via filter
_, imgBinThres = cv2.threshold(imgGaussianBlur, 140, 230, cv2.THRESH_BINARY)
if DEBUGMODE:
    cv2.imwrite(&quot;img01bw.jpg&quot;,resizeImageByPercentage(imgBinThres,30))

## 3 steps merged by helper class ContourFacts
## B) select contours of words (filter by: ratio heights vs widths , area size)
## C) get random points from wordcontours with gaussian distribution and center point centroid of contour
## D) use linear regression to find middle line of wordcontours

#apply dilate filter to merge letter to words
imgDilated = applyDilateImgFilter(imgBinThres,5,3)
if DEBUGMODE:
    cv2.imwrite(&quot;img02dilated.jpg&quot;,resizeImageByPercentage(imgDilated,30))

# detect contours
contourList, _ = cv2.findContours(imgDilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
if DEBUGMODE:
    imgContour = drawCountourOn(img,contourList)
    cv2.imwrite(&quot;img03contourAll.jpg&quot;,resizeImageByPercentage(imgContour,30))
    
#do a selection of contours by rule
#A) ratio h vs w
#B) area size
mediaWordWidth, medianWordHigh = calcMedianContourWithAndHeigh(contourList)
print(&quot;median word width: &quot;, mediaWordWidth)
print(&quot;median word high: &quot;, medianWordHigh)
contourSelectedByRatio=list()
#we calc for every contour ratio h vs w
ratioThresholdHeightToWidth = 1.1 #thresold ratio should be a least be 1 to 1
# e.g word to --&gt;  10 pixel / 13 pixel

#helper class for contour atrributess
class ContourFacts:
    def __init__(self,contour):
        if contour is None:
            return
        self.uid = uuid.uuid4()
        (self.x, self.y, self.w, self.h) = cv2.boundingRect(contour)
        self.minRect = cv2.minAreaRect(contour)
        self.angle = self.minRect[-1]
        _, (rectWidth, rectHeight), _ = self.minRect
        self.minRectArea = rectWidth * rectHeight
        self.ratioHeightoWidth = self.h / self.w
        self.contour = contour
        self.centoird = calcCentroid(contour)
        self.randomPoinsInCnt = self.DrawRandomPoints()
        if len(self.randomPoinsInCnt) &gt; 0:
            (self.bottomSlope, self.bottomIntercept) = self.EstimateCenterLineViaLinearReg()
            self.bottomMinX = min([x for x,y in self.randomPoinsInCnt])
            self.bottomMaxX = max([x for x,y in self.randomPoinsInCnt])

    def EstimateCenterLineViaLinearReg(self):
        if self.contour is None:
            return (0,0)
        slope = 0
        intercept = 0
        #model = slope (x) + intercept
        xValues = [x for x,y in self.randomPoinsInCnt]
        yValues = [y for x,y in self.randomPoinsInCnt]
        if len(xValues) &lt; 2:
            return (0,0)
        elif len(xValues) ==2:
            #we calc a line with 2 points
            # y = m*x + b
            deltaX = xValues[1]-xValues[0]
            if deltaX == 0:
                return (0,0)
            slope = (yValues[1]-yValues[0])/(deltaX)
            intercept = yValues[0] - (slope*xValues[0])
        else:
            #normal linear regression above 2 points
            slope, intercept, r, p, std_err = stats.linregress(xValues, yValues)
        #TODO check std_err
        return slope, intercept
    
    def DrawRandomPoints(self,pointFactor=2):
        pointList = list()
        #calc area to amount point relation  -&gt; bigger area more points
        amountPointsNeeded = int(self.minRectArea/pointFactor)
        pointList = drawRandomPointsInPolygon(amountPointsNeeded,self)
        return pointList
    
    def GetCenterLineLeftCorner(self):
        if self.contour is None or len(self.randomPoinsInCnt) == 0:
            return (0,0)    
        # calc via  y = m*x + b with min
        return (int(self.bottomMinX), int(self.bottomSlope*self.bottomMinX + self.bottomIntercept))
    def GetCenterLineRightCorner(self):
        if self.contour is None or len(self.randomPoinsInCnt) == 0:
            return (0,0)    
        # calc via via y = m*x + b with max
        return (int(self.bottomMaxX), int(self.bottomSlope*self.bottomMaxX + self.bottomIntercept))
    def __eq__(self, other):
        if isinstance(other, ContourFacts):
            return self.uid == other.uid
        return False
    def __hash__(self):
        return hash(self.uid)



#calc mean area size from area size
vectorOfAreaSize = np.array([cv2.contourArea(cnt) for cnt in contourList])
meanAreaSize = np.mean(vectorOfAreaSize)
print(&quot;mean area size: &quot;, meanAreaSize)
stdDevAreaSize = np.std(vectorOfAreaSize)
print(&quot;std dev area size: &quot;, stdDevAreaSize)
thresoldDiffAreaSize = stdDevAreaSize/4
#we iterate all contours and select by ratio and size
for cnt in contourList:
    #construct helper class instance
    contourFactObj = ContourFacts(cnt)
    #calc abs diff to mean area size
    diffArea = abs(cv2.contourArea(cnt) - meanAreaSize)
    if contourFactObj.ratioHeightoWidth &lt; ratioThresholdHeightToWidth and diffArea &lt; (thresoldDiffAreaSize):
        contourSelectedByRatio.append(contourFactObj)

#debug print 
if DEBUGMODE:
    #we print words
    imgContourSelection = img.copy() 
    for cnt in contourSelectedByRatio:
        contourColor = randomColor()
        imgContourSelection = drawCountourOn(imgContourSelection,[cnt.contour],contourColor)
        #we print centroid 
        cv2.circle(imgContourSelection, cnt.centoird, 5, (0, 0, 255), -1)
        p1 = cnt.GetCenterLineLeftCorner()
        p2 = cnt.GetCenterLineRightCorner()
        if p1 != (0,0) or p2 != (0,0):
            cv2.circle(imgContourSelection, p1, 5, (0, 0, 255), -1)
            cv2.circle(imgContourSelection, p2, 5, (0, 0, 255), -1)
            cv2.line(imgContourSelection, p1, p2, (0, 255, 0), 2)
    cv2.imwrite(&quot;img04contourSelection.jpg&quot;,resizeImageByPercentage(imgContourSelection,30))


## E) merge all wordcontours which are neighbours to linecontours (outer middle line points are close together)  
#define distance function, differences in height is negativ weighted
def euclidianDistanceWithNegativHeightWeight(cnt1,cnt2,negativeHeightWeight=2.0):
    if cnt1 is None or cnt2 is None:
        return 1000000
    if not isinstance(cnt1, ContourFacts) or not isinstance(cnt2, ContourFacts):
        return 1000000
    p1 = cnt1.GetCenterLineRightCorner()
    p2 = cnt2.GetCenterLineLeftCorner()
    return math.sqrt((p2[0] - p1[0])**2 + (negativeHeightWeight*(p2[1] - p1[1]))**2)

# helper class to group contours
class ContourGroup:
    def __init__(self):
        self.uuid = uuid.uuid4()
        self.contourList = list()
    def GetLastElement(self):
        if len(self.contourList) == 0:
            return None
        return self.contourList[-1]
    def Add(self,cnt):
        self.contourList.append(cnt)   
    def __eq__(self, other):
        if isinstance(other, ContourGroup):
            return self.uuid == other.uuid
        return False
    
groupMap = dict()
lineGroupList = list()
## we grouping the contours to lines
maxDistanceThresholNextWord= medianWordHigh *0.9 #TODO get better estimate
#recursive function to get nearest neighbors
def getNearestNeighbors(cnt1,depthCounter,contourSelectedByRatio,maxDistanceThresholNextWord):
    maxDepth = 10 #var for max recursion depth 
    nearestCnt = None
    nearestDist = maxDistanceThresholNextWord
    for j in range(0,len(contourSelectedByRatio)):
        cnt2 = contourSelectedByRatio[j]
        if cnt1 == cnt2:#skip same
            continue
        dist = euclidianDistanceWithNegativHeightWeight(cnt1,cnt2)
        if dist &lt; nearestDist:
            nearestDist = dist
            nearestCnt = cnt2
    if nearestCnt is not None:#call recursive
        nearaestListWeHave = [nearestCnt] #new list
        depthCounter += 1
        if depthCounter &lt; maxDepth:# all to call
            nearListWeGet =getNearestNeighbors(nearestCnt,depthCounter,contourSelectedByRatio,maxDistanceThresholNextWord)
            if nearListWeGet is None:
                return nearaestListWeHave
            else:
                nearListWeGet.extend(nearaestListWeHave)   
                return nearListWeGet
        else:#limit reached of recursion skip
            return nearaestListWeHave
    else:      
        return None
## E) merge all wordcontours which are neighbours to linecontours (outer middle line points are close together)      
#we group all contours
for i in range(0,len(contourSelectedByRatio)):
    cnt1 = contourSelectedByRatio[i]
    if cnt1 in groupMap:
        continue
    lineGroup = ContourGroup()
    lineGroup.Add(cnt1)
    groupMap[cnt1] = lineGroup
    depthCounter = 0
    nearaestList = getNearestNeighbors(cnt1,depthCounter,
                                       contourSelectedByRatio,maxDistanceThresholNextWord)
    if nearaestList is None:
        lineGroupList.append(lineGroup) #no neighbor found
        continue
    for cnt in nearaestList:
        groupMap[cnt] = lineGroup
        lineGroup.Add(cnt)
    lineGroupList.append(lineGroup)

if DEBUGMODE:
    imgContourGroup = img.copy()
    for group in lineGroupList:
        #print(f&quot;group({group.uuid} size: {len(group.contourList)}&quot;)
        #we print all corner points
        for cnt in group.contourList:
            leftCorner = cnt.GetCenterLineLeftCorner()
            rigthCorner = cnt.GetCenterLineRightCorner()
            cv2.circle(imgContourGroup, leftCorner, 5, (0, 0, 255), -1)
            cv2.circle(imgContourGroup, rigthCorner, 5, (140, 0, 0), -1)
        #we print estimated underlines
        for cnt in group.contourList:
            leftCorner = cnt.GetCenterLineLeftCorner()
            rigthCorner = cnt.GetCenterLineRightCorner()
            cv2.line(imgContourGroup, leftCorner, rigthCorner, (0, 255, 0), 2)
        # we print all contours
        groupColor = randomColor()
        cntList = [cnt.contour for cnt in group.contourList]
        imgContourGroup = drawCountourOn(imgContourGroup,cntList,groupColor)
    cv2.imwrite(&quot;img05contourGroup.jpg&quot;,resizeImageByPercentage(imgContourGroup,30))

## F) do polynomial regression 2nd order to estimate middle line of linecontours
# calc line from stable group points
minAmountRegressionElements = 12
movingWindowSize = 3
letterCenterOffset = medianWordHigh * 0.5
lineListCollection = list()
for group in lineGroupList:
    stablePoints = list()
    for cnt in group.contourList:
        stablePoints.extend(cnt.randomPoinsInCnt)
    if len(stablePoints) &gt;= minAmountRegressionElements :
        xValues = [x for x,y in stablePoints]
        yValues = [y for x,y in stablePoints]
        # perform polynomial regression of degree 2
        coefffientValues = np.polyfit(np.array(xValues), np.array(yValues), 2)
        # create a polynomial function with the coefficients
        polynomial = np.poly1d(coefffientValues)
        #we filter to build something like a line
        xValuesNewLineFilter = list()
        xMin =int( min(xValues))
        xMax = int(max(xValues))
        for xNew in range(xMin,xMax,movingWindowSize):
                xValuesNewLineFilter.append(xNew)
        #we predict new points with all old x values
        yValuesNew = polynomial(xValuesNewLineFilter)
        yValuesNewHighCorrect =np.array(yValuesNew) + letterCenterOffset
        lineList = list()
        #we create a list of points
        for i in range(0,len(xValuesNewLineFilter)):
            pointInt = (int(xValuesNewLineFilter[i]),int(yValuesNewHighCorrect[i]))
            lineList.append(pointInt)
        lineListCollection.append(lineList)
## G) write the lines 
imgLines = img.copy()
for lineList in lineListCollection:
    p1 = lineList[0]
    for j in range(1,len(lineList)):
        p2 = lineList[j]
        #cv2.circle(imgLines, p2Int, 5, (0, 0, 255), -1)
        cv2.line(imgLines, p1, p2, (0, 255, 0), 2)
        p1 = p2
cv2.imwrite(&quot;img06Lines.jpg&quot;,resizeImageByPercentage(imgLines,30))

if DEBUGMODE:
    cv2.waitKey(0)
</code></pre>
<p>more debug output is:
<a href=""https://i.sstatic.net/7omI1lce.jpg"" rel=""noreferrer""><img src=""https://i.sstatic.net/7omI1lce.jpg"" alt=""filter black and white"" /></a>
<a href=""https://i.sstatic.net/65O4jXhB.jpg"" rel=""noreferrer""><img src=""https://i.sstatic.net/65O4jXhB.jpg"" alt=""blur all letter to words"" /></a>
<a href=""https://i.sstatic.net/Fx7osvVo.jpg"" rel=""noreferrer""><img src=""https://i.sstatic.net/Fx7osvVo.jpg"" alt=""enter image description here"" /></a>
The picture below shows word contours with green middle lines and red outer points for neighborhood analysis.
<a href=""https://i.sstatic.net/E0KsfcZP.jpg"" rel=""noreferrer""><img src=""https://i.sstatic.net/E0KsfcZP.jpg"" alt=""enter image description here"" /></a>
<a href=""https://i.sstatic.net/n7JaWBPN.jpg"" rel=""noreferrer""><img src=""https://i.sstatic.net/n7JaWBPN.jpg"" alt=""enter image description here"" /></a></p>
","python, algorithm, ocr, opencv, image-processing"
Jun-24,Jun-24,"<p>I installed numpy 2.0.0</p>
<p><a href=""https://i.sstatic.net/4aB0aWDL.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/4aB0aWDL.png"" alt=""enter image description here"" /></a></p>
<pre><code>pip install numpy==2.0.0

import numpy as np
np.__version__
#2.0.0
</code></pre>
<p>then I installed:</p>
<pre><code>pip install opencv-python

Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)
Requirement already satisfied: numpy&gt;=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (2.0.0)
</code></pre>
<p>Then I did:</p>
<pre><code>import cv2
</code></pre>
<p>I am getting this error:</p>
<hr />
<pre><code>A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.0 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11&gt;=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy&lt;2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File &quot;/usr/lib/python3.10/runpy.py&quot;, line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File &quot;/usr/lib/python3.10/runpy.py&quot;, line 86, in _run_code
    exec(code, run_globals)
  File &quot;/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py&quot;, line 37, in &lt;module&gt;
    ColabKernelApp.launch_instance()
  File &quot;/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py&quot;, line 992, in launch_instance
    app.start()
  File &quot;/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py&quot;, line 619, in start
    self.io_loop.start()
  File &quot;/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py&quot;, line 195, in start
    self.asyncio_loop.run_forever()
  File &quot;/usr/lib/python3.10/asyncio/base_events.py&quot;, line 603, in run_forever
    self._run_once()
  File &quot;/usr/lib/python3.10/asyncio/base_events.py&quot;, line 1909, in _run_once
    handle._run()
  File &quot;/usr/lib/python3.10/asyncio/events.py&quot;, line 80, in _run
    self._context.run(self._callback, *self._args)
  File &quot;/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py&quot;, line 685, in &lt;lambda&gt;
    lambda f: self._run_callback(functools.partial(callback, future))
  File &quot;/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py&quot;, line 738, in _run_callback
    ret = callback()
  File &quot;/usr/local/lib/python3.10/dist-packages/tornado/gen.py&quot;, line 825, in inner
    self.ctx_run(self.run)
  File &quot;/usr/local/lib/python3.10/dist-packages/tornado/gen.py&quot;, line 786, in run
    yielded = self.gen.send(value)
  File &quot;/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py&quot;, line 361, in process_one
    yield gen.maybe_future(dispatch(*args))
  File &quot;/usr/local/lib/python3.10/dist-packages/tornado/gen.py&quot;, line 234, in wrapper
    yielded = ctx_run(next, result)
  File &quot;/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py&quot;, line 261, in dispatch_shell
    yield gen.maybe_future(handler(stream, idents, msg))
  File &quot;/usr/local/lib/python3.10/dist-packages/tornado/gen.py&quot;, line 234, in wrapper
    yielded = ctx_run(next, result)
  File &quot;/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py&quot;, line 539, in execute_request
    self.do_execute(
  File &quot;/usr/local/lib/python3.10/dist-packages/tornado/gen.py&quot;, line 234, in wrapper
    yielded = ctx_run(next, result)
  File &quot;/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py&quot;, line 302, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File &quot;/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py&quot;, line 539, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py&quot;, line 2975, in run_cell
    result = self._run_cell(
  File &quot;/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py&quot;, line 3030, in _run_cell
    return runner(coro)
  File &quot;/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py&quot;, line 78, in _pseudo_sync_runner
    coro.send(None)
  File &quot;/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py&quot;, line 3257, in run_cell_async
    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,
  File &quot;/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py&quot;, line 3473, in run_ast_nodes
    if (await self.run_code(code, result,  async_=asy)):
  File &quot;/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py&quot;, line 3553, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &quot;&lt;ipython-input-4-c8ec22b3e787&gt;&quot;, line 1, in &lt;cell line: 1&gt;
    import cv2
  File &quot;/usr/local/lib/python3.10/dist-packages/google/colab/_import_hooks/_cv2.py&quot;, line 78, in load_module
    cv_module = imp.load_module(name, *module_info)
  File &quot;/usr/lib/python3.10/imp.py&quot;, line 245, in load_module
    return load_package(name, filename)
  File &quot;/usr/lib/python3.10/imp.py&quot;, line 217, in load_package
    return _load(spec)
  File &quot;/usr/local/lib/python3.10/dist-packages/cv2/__init__.py&quot;, line 181, in &lt;module&gt;
    bootstrap()
  File &quot;/usr/local/lib/python3.10/dist-packages/cv2/__init__.py&quot;, line 153, in bootstrap
    native_module = importlib.import_module(&quot;cv2&quot;)
  File &quot;/usr/lib/python3.10/importlib/__init__.py&quot;, line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File &quot;/usr/local/lib/python3.10/dist-packages/google/colab/_import_hooks/_cv2.py&quot;, line 78, in load_module
    cv_module = imp.load_module(name, *module_info)
  File &quot;/usr/lib/python3.10/imp.py&quot;, line 243, in load_module
    return load_dynamic(name, filename, file)
  File &quot;/usr/lib/python3.10/imp.py&quot;, line 343, in load_dynamic
    return _load(spec)
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
AttributeError: _ARRAY_API not found
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
&lt;ipython-input-4-c8ec22b3e787&gt; in &lt;cell line: 1&gt;()
----&gt; 1 import cv2

8 frames
/usr/lib/python3.10/imp.py in load_dynamic(name, path, file)
    341         spec = importlib.machinery.ModuleSpec(
    342             name=name, loader=loader, origin=path)
--&gt; 343         return _load(spec)
    344 
    345 else:

ImportError: numpy.core.multiarray failed to import

---------------------------------------------------------------------------
NOTE: If your import is failing due to a missing package, you can
manually install dependencies using either !pip or !apt.

To view examples of installing some common dependencies, click the
&quot;Open Examples&quot; button below.
</code></pre>
<hr />
",34,"<p>There are two solutions for this error:</p>
<h2>1. downgrade your numpy to 1.26.4</h2>
<pre><code>pip install numpy==1.26.4
</code></pre>
<p>or</p>
<pre><code>pip install &quot;numpy&lt;2.0&quot; 
</code></pre>
<h3>Make sure to restart your kernel after downgrading numpy</h3>
<hr />
<hr />
<p>Another option is:</p>
<h2>2. install the latest version of the module which is failing*</h2>
<p>I had an old version of <strong><code>opencv-python 4.8.0.76</code></strong></p>
<p>I was able to get this working by installing the latest version of <strong><code>opencv-python</code></strong> by</p>
<pre><code>pip install opencv-python==4.10.0.84
</code></pre>
<p>*Some modules may still not work with <strong><code>numpy 2.0</code></strong></p>
<blockquote>
<p>'We expect that some modules will need time to support NumPy 2'</p>
</blockquote>
","python, numpy, pip, python-3.x, numpy-2.x"
Jun-24,Jun-24,"<p>I want to call my Python module from the Matlab. I received the error:</p>
<pre><code>Error using numpy_ops&gt;init thinc.backends.numpy_ops
</code></pre>
<p>Python Error:</p>
<pre><code> ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject.
</code></pre>
<p>The Python script is as follows</p>
<pre><code>import spacy
def text_recognizer(model_path, text):
try:
    # Load the trained model
    nlp = spacy.load(model_path)
    print(&quot;Model loaded successfully.&quot;)
    
    # Process the given text
    doc = nlp(text)
    ent_labels = [(ent.text, ent.label_) for ent in doc.ents]
        return ent_labels
</code></pre>
<p>The Matlab script is as follows</p>
<pre><code>% Set up the Python environment
pe = pyenv;
py.importlib.import_module('final_output');

% Add the directory containing the Python script to the Python path
path_add = fileparts(which('final_output.py'));
if count(py.sys.path, path_add) == 0
    insert(py.sys.path, int64(0), path_add);
end
% Define model path and text to process
model_path = 'D:\trained_model\\output\\model-best';
text = 'Roses are red';
% Call the Python function
pyOut = py.final_output.text_recognizer(model_path, text);
% Convert the output to a MATLAB cell array
entity_labels = cell(pyOut);
disp(entity_labels);
</code></pre>
<p>I found one solution to update Numpy, what I did, but nothing changed. I am using Python 3.9 and Numpy version 2.0.0</p>
<p>The error was received when I tried to call the Python module using a Matlab script.</p>
<p>How can I fix the issue?</p>
",155,"<p>The reason is that <code>pandas</code> defines its <code>numpy</code> dependency freely as &quot;anything newer than certain version of numpy&quot;.
The problem occured, when <code>numpy==2.0.0</code> has been released on June 16th 2024, because it is no longer compatible with your pandas version.</p>
<p>The solution is to pin down the <code>numpy</code> version to any before the <code>2.0.0</code>. Today it could be (this is the most recent <code>numpy 1</code> release):</p>
<pre><code>numpy==1.26.4
</code></pre>
<p>To be added in your requirements or to the pip command you use (but together with installing pandas).</p>
<p>Nowadays <code>pip</code> is very flexible and can handle the issue flawesly. You just need to ask it to install both <code>pandas</code> and <code>numpy</code> of given versions in the same <code>pip install</code> invocation.</p>
","python, matlab, numpy, spacy"
Jun-24,Jun-24,"<p>Received a warning in the Play Console saying the following</p>
<blockquote>
<p>Update your Play Core Maven dependency to an Android 14 compatible version! Your current Play Core library is incompatible with targetSdkVersion 34 (Android 14), which introduces a backwards-incompatible change to broadcast receivers to improve user security. As a reminder, from August 31, Google Play requires all new app releases to target Android 14. Update to the latest Play Core library version dependency to avoid app crashes</p>
</blockquote>
<p>I would like to know, what can I possibly do to solve this problem?</p>
<p>My app is a complete native app, using Java/Kotlin and XML/Jetpack Compose</p>
",20,"<p>First and foremost, it's important to see that they've included a <a href=""https://developer.android.com/guide/playcore#playcore-migration"" rel=""noreferrer"">Migration link in the warning</a>. So we need to migrate the <code>Tasks</code> class as per that</p>
<p>Later, we can split the monolithic <code>play-core</code> SDK into the required dependencies, as per the app requirement. The alternative SDKs can be found <a href=""https://developer.android.com/reference/com/google/android/play/core/release-notes#partitioned-apis"" rel=""noreferrer"">here</a></p>
<p>In my case, had to get the In-App Review and In-App updates SDK, seperately</p>
<p>EDIT:</p>
<p>For hybrid apps, we can go the <code>android</code> folder</p>
<pre><code>cd android
</code></pre>
<p>And run the following command to check all the dependencies listed in the app, and check which one has the <code>com.google.android.play:core</code> dependency, by exporting all the dependencies to a text file <code>dependencies.txt</code></p>
<pre><code>./gradlew app:dependencies &gt; dependencies.txt
</code></pre>
<p>Once you figure out, which of your dependencies uses the play core library, you can actually update it</p>
","java, android, kotlin, google-play-console"
Jul-24,Jul-24,"<p><strong>undetected_chromedriver</strong> with <strong>webdriver_manager</strong> was working well few days ago for scraping websites but out of nowhere it started throwing the error:</p>
<pre><code>OSError: [Errno 8] Exec format error: 
'/Users/pd/.wdm/drivers/chromedriver/mac64/127.0.6533.72/chromedriver-mac-x64/THIRD_PARTY_NOTICES.chromedriver'
</code></pre>
<p>I am guessing it is related to recent update of <strong>webdriver_manager</strong>.</p>
<p>This is the code:</p>
<pre class=""lang-py prettyprint-override""><code>import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support import expected_conditions as EC

def get_driver():
    options = uc.ChromeOptions()
    # options.add_argument(&quot;--headless&quot;)
    options.add_argument(&quot;--no-sandbox&quot;)
    options.add_argument(&quot;--disable-dev-sim-usage&quot;)
    options.add_argument(&quot;--start-maximized&quot;)
    options.add_argument('--disable-popup-blocking')
    driver = uc.Chrome(driver_executable_path=ChromeDriverManager().install(), options=options, version_main=116)
    driver.maximize_window()
    return driver
</code></pre>
<p>It would be really great if someone can help me on this, Thanks.</p>
",28,"<p>The command <code>ChromeDriverManager().install()</code>:</p>
<ol>
<li>creates a new folder without the executable and</li>
<li>it retrieves the wrong file.</li>
</ol>
<p><a href=""https://i.sstatic.net/MrzvCEpB.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/MrzvCEpB.png"" alt=""enter image description here"" /></a></p>
<p>First, you need to <strong>remove</strong> the <strong><code>.wdm</code></strong> folder and then reinstall <strong><code>webdriver-manager</code></strong>:</p>
<p><strong>Windows Location:</strong>
<code>r&quot;C:\Users\{user}\.wdm&quot;</code></p>
<p><strong>Linux Location:</strong>
<code>/home/{user}/.wdm</code></p>
<p><strong>Mac Location:</strong>
<code>/Users/{user}/.wdm</code></p>
<pre><code>rm -rf /home/user/.wdm
pip uninstall webdriver-manager
pip install webdriver-manager
</code></pre>
<p>Now, after executing <code>ChromeDriverManager().install()</code>, you should only see a single folder with the executable:</p>
<p><a href=""https://i.sstatic.net/wj2RSGwY.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/wj2RSGwY.png"" alt=""enter image description here"" /></a></p>
<p>It check if there is really a <code>chromedriver</code> executable inside this folder.</p>
<p>Second, it makes a correction to the file name:</p>
<pre><code>if 'THIRD_PARTY_NOTICES.chromedriver' in chromedriver_path:
    chromedriver_path = chromedriver_path.replace('THIRD_PARTY_NOTICES.chromedriver', 'chromedriver')
</code></pre>
","python, web-scraping, selenium-webdriver, undetected-chromedriver"
Jul-24,Jul-24,"<p>All of my Selenium scripts are raising errors after Chrome updated to version 127 because I always have to select a default search engine when the browser is being launched.</p>
<p>I use ChromeDriver 127.0.6533.72.</p>
<p>How to fix it?</p>
",61,"<p>You need to add this Chrome Option to disable the <em>'choose your search engine'</em> screen:</p>
<pre><code>options.addArguments(&quot;--disable-search-engine-choice-screen&quot;);
</code></pre>
<p>If you are using selenium with Python, you'll have to use:</p>
<pre><code>options.add_argument(&quot;--disable-search-engine-choice-screen&quot;)
</code></pre>
","python, selenium-webdriver"
Jul-24,Jul-24,"<p>Examples:</p>
<ol>
<li>For <strong>0123123123</strong>, <strong>1</strong> should be matched since the 2nd <strong>1</strong> appears before the repetition of any other digit.</li>
<li>For <strong>01234554321</strong>, <strong>5</strong> should be matched since the 2nd <strong>5</strong> appears before the repetition of any other digit.</li>
</ol>
<p>Some regexes that I have tried:</p>
<ol>
<li>The below works for the 1st but not the 2nd example. It matches <strong>1</strong> instead because <strong>1</strong> is the first digit that appears in the string which is subsequently repeated.</li>
</ol>
<pre class=""lang-py prettyprint-override""><code>import re
m = re.search(r&quot;(\d).*?\1&quot;, string)
print(m.group(1))
</code></pre>
<ol start=""2"">
<li>The below works for the 2nd but not the 1st example. It matches <strong>3</strong> instead - in particular the 2nd and 3rd occurrence of the digit. I do not know why it behaves that way.</li>
</ol>
<pre class=""lang-py prettyprint-override""><code>import re
m = re.search(r&quot;(\d)(?!(\d).*?\2).*?\1&quot;, string)
print(m.group(1))
</code></pre>
",12,"<p>One idea: capture the end of the string and add it in the negative lookahead (group 2 here):</p>
<pre><code>(\d)(?=.*?\1(.*))(?!.*?(\d).*?\3.+?\2$)
</code></pre>
<p>This way you can control where the subpattern <code>.*?(\d).*?\3</code> in the negative lookahead ends. If <code>.+?\2$</code> succeeds, that means there's an other digit that is repeated before the one in group 1.</p>
<p>I anchored the pattern for the <a href=""https://regex101.com/r/hlcne9/2"" rel=""noreferrer"">regex101 demo</a> with <code>^.*?</code>, but you don't need to do that with the <code>re.search</code> method.</p>
<hr />
<p>Other way: reverse the string and find the last repeated digit:</p>
<pre><code>re.search(r'^.*(\d).*?\1', string[::-1]).group(1)
</code></pre>
","python, regex"
Jul-24,Jul-24,"<p>The following code with <code>callback</code> argument runs faster in the first loop.</p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>const fn = (length, label, callback) =&gt; {
  console.time(label);
  for (let i = 0; i &lt; length; i++) {
    callback &amp;&amp; callback(i);
  }
  console.timeEnd(label);
};

const length = 100000000;
fn(length, ""1"", () =&gt; {})  // very few intervals
fn(length, ""2"", () =&gt; {})  // regular
fn(length, ""3"", () =&gt; {})  // regular</code></pre>
</div>
</div>
</p>
<p>and then I removed the third argument <code>callback</code>, and their execution times are very near:</p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>const fn = (length, label, callback) =&gt; {
  console.time(label);
  for (let i = 0; i &lt; length; i++) {
    callback &amp;&amp; callback(i);
  }
  console.timeEnd(label);
};

const length = 100000000;
fn(length, ""1"")  // regular
fn(length, ""2"")  // regular
fn(length, ""3"")  // regular</code></pre>
</div>
</div>
</p>
<p>Why?</p>
",18,"<p>In short: it's due to inlining.</p>
<p>When a call such as <code>callback()</code> has seen only one target function being called, and the containing function (&quot;<code>fn</code>&quot; in this case) is optimized, then the optimizing compiler will (usually) decide to inline that call target. So in the fast version, no actual call is performed, instead the empty function is inlined.<br />
When you then call different callbacks, the old optimized code needs to be thrown away (&quot;deoptimized&quot;), because it is now incorrect (if the new callback has different behavior), and upon re-optimization a little while later, the inlining heuristic decides that inlining multiple possible targets probably isn't worth the cost (because inlining, while sometimes enabling great performance benefits, also has certain costs), so it doesn't inline anything. Instead, generated optimized code will now perform actual calls, and you'll see the cost of that.</p>
<p>As @0stone0 observed, when you pass <em>the same</em> callback on the second call to <code>fn</code>, then deoptimization isn't necessary, so the originally generated optimized code (that inlined this callback) can continue to be used. Defining three different callbacks all with the same (empty) source code doesn't count as &quot;the same callback&quot;.</p>
<p>FWIW, this effect is most pronounced in microbenchmarks; though sometimes it's also visible in more real-world-ish code. It's certainly a common trap for microbenchmarks to fall into and produce confusing/misleading results.</p>
<p>In the second experiment, when there is no <code>callback</code>, then of course the <code>callback &amp;&amp;</code> part of the expression will already bail out, and none of the three calls to <code>fn</code> will call (or inline) any callbacks, because there are no callbacks.</p>
","javascript, for-loop, v8, callback"
Jul-24,Jul-24,"<p>Trying to upgrade to TypeScript 5.6 Beta, I get the following error messages in <code>node_modules</code>. I didn't make any other change, so what should I do to fix these errors?</p>
<pre><code>node_modules/@types/node/buffer.d.ts:632:19 - error TS2430: Interface 'Buffer' incorrectly extends interface 'Uint8Array'.
  The types returned by 'reverse()' are incompatible between these types.
    Type 'this' is not assignable to type 'Uint8Array'.
      Type 'Buffer' is not assignable to type 'Uint8Array'.
        The types returned by 'slice(...).entries()' are incompatible between these types.
          Type 'IterableIterator&lt;[number, number]&gt;' is missing the following properties from type 'BuiltinIterator&lt;[number, number], undefined, any&gt;': map, filter, take, drop, and 8 more.

632         interface Buffer extends Uint8Array {
                      ~~~~~~
</code></pre>
<pre><code>node_modules/@types/node/fs/promises.d.ts:56:66 - error TS2344: Type 'Buffer' does not satisfy the constraint 'ArrayBufferView'.
  Type 'Buffer' is not assignable to type 'Uint8Array | DataView'.
    Type 'Buffer' is not assignable to type 'Uint8Array'.
      The types returned by 'entries()' are incompatible between these types.
        Type 'IterableIterator&lt;[number, number]&gt;' is missing the following properties from type 'BuiltinIterator&lt;[number, number], undefined, any&gt;': map, filter, take, drop, and 8 more.

56     interface FileReadOptions&lt;T extends NodeJS.ArrayBufferView = Buffer&gt; {
                                                                    ~~~~~~
</code></pre>
<pre><code>node_modules/@types/node/fs/promises.d.ts:238:49 - error TS2344: Type 'Buffer' does not satisfy the constraint 'ArrayBufferView'.
  Type 'Buffer' is not assignable to type 'Uint8Array | DataView'.
    Type 'Buffer' is not assignable to type 'Uint8Array'.
      The types returned by 'entries()' are incompatible between these types.
        Type 'IterableIterator&lt;[number, number]&gt;' is missing the following properties from type 'BuiltinIterator&lt;[number, number], undefined, any&gt;': map, filter, take, drop, and 8 more.

238         read&lt;T extends NodeJS.ArrayBufferView = Buffer&gt;(options?: FileReadOptions&lt;T&gt;): Promise&lt;FileReadResult&lt;T&gt;&gt;;
                                                    ~~~~~~
</code></pre>
<p>Note: when I used a newer version of TypeScript 5.6, mentions of <code>BuiltinIterator&lt;[number, number], ...&gt;</code> seem replaced with <code>ArrayIterator&lt;number&gt;</code>.</p>
",22,"<h1>Short Answer</h1>
<p>You need a new version of the Node.js types.</p>
<pre><code>npm update @types/node --save

# or if you need a specific version
npm install -D @types/node@16
npm install -D @types/node@18
npm install -D @types/node@20
npm install -D @types/node@22
</code></pre>
<h1>Long Answer</h1>
<p>First, <code>IterableIterator</code> describes a type that is both <code>Iterable</code> (it can create an <code>Iterator</code> by calling <code>someValue[Symbol.iterator()]</code>), and is itself an <code>Iterator</code> (you can call things like <code>next()</code> on it over and over until it's out of values).</p>
<p><code>Iterable</code>s (and <code>IterableIterator</code>s) are nice because they can be used in all sorts of places in JavaScript - but a lot of people found themselves missing methods on <code>Array</code>s like <code>map</code>, <code>filter</code>, etc. So a recent proposal was brought forward in JavaScript/ECMAScript to bring many useful methods from <code>Array</code> (plus a few more). You can adapt any existing <code>Iterable</code>s into this new type with <code>Iterable.from</code>:</p>
<pre><code>Iterator.from(...).filter(someFunction);
</code></pre>
<p>Now whenever a built-in method, or a generator, produces one of these <code>IterableIterator</code>s, it is backed by the methods on <code>Iterator.prototype</code>, and you can call something like <code>map</code>, <code>filter</code>, etc.</p>
<pre><code>new Uint8Array(100).entries().map(x =&gt; x)
</code></pre>
<p>Notice though that we're talking about a new <strong>runtime value</strong> called <code>Iterator</code>. You can reference <code>Iterator</code> and <code>Iterator.prototype</code> as actual values in JavaScript. This is a bit awkward since TypeScript defines its own thing called <code>Iterator</code> that exists purely for type-checking. So due to this unfortunate name clash, TypeScript needs to introduce a separate type to describe these built-in iterable iterators.</p>
<p>TypeScript 5.6 introduces a new type called <code>IteratorObject</code> (and a few subtypes like <code>ArrayIterator</code>). Lots of built-in collections and methods produce this type, so many methods had to be updated to produce it.</p>
<p>So how does this cause problems in Node.js? Well in <code>@types/node</code>, <code>Buffer</code> is basically a subtype of <code>Uint8Array</code>. <code>Buffer</code> unnecessarily redeclared the <code>entries()</code> method in a way that copied the <em>old</em> signature:</p>
<pre><code>    /**
     * Returns an array of key, value pairs for every entry in the array
     */
    entries(): IterableIterator&lt;[number, number]&gt;;
}
</code></pre>
<p>However, in TypeScript 5.6, <code>Uint8Array</code> has been updated to use a signature like:</p>
<pre><code>    entries(): ArrayIterator&lt;number&gt;;
}
</code></pre>
<p>This caused the two to diverge in slightly incompatible ways.</p>
<p>So recently, <code>@types/node</code> has been updated to avoid the issue entirely.</p>
","javascript, upgrade, node.js, typescript"
Aug-24,Aug-24,"<p>After updating VS code to v1.92, the Python extension consistently fails to launch, indefinitely showing a spinner next to ‚ÄúReactivating terminals‚Ä¶‚Äù on the status bar.</p>
<p>Selecting <code>OUTPUT &gt; Python</code> reveals the error <code>Failed to resolve env &quot;/mnt/data-linux/miniconda3&quot;</code>.</p>
<p>Here‚Äôs the error trace:</p>
<pre><code>2024-08-07 18:35:35.873 [error] sendStartupTelemetry() failed. s [Error]: Failed to resolve env &quot;/mnt/data-linux/miniconda3&quot;
    at ae (/home/user/.vscode-insiders/extensions/ms-python.python-2024.12.2-linux-x64/out/client/extension.js:2:1968174)
    at oe (/home/user/.vscode-insiders/extensions/ms-python.python-2024.12.2-linux-x64/out/client/extension.js:2:1966134)
    at Immediate.&lt;anonymous&gt; (/home/user/.vscode-insiders/extensions/ms-python.python-2024.12.2-linux-x64/out/client/extension.js:2:1962428)
    at processImmediate (node:internal/timers:478:21) {
  code: -4,
  data: undefined
}
</code></pre>
<p>How do I fix this? Restarting worked, but that's not sustainable.</p>
",12,"<p><em>Update: <strong>Extension version <code>2024.14.1</code> has likely fixed the issue.</strong> If you encounter this issue, rather than doing the workaround in the answer below, first try updating your extension as the workaround pins to legacy which is not something you'll want to have moving forward</em></p>
<p>This appears to be a bug related to the new &quot;native&quot; Python locator - I think VS Code recently switched more people from the old to the new locator.</p>
<p>You can go back to the old working version by <strong>adding</strong> the following line to the user settings JSON (until the bug in the native locator is fixed):</p>
<pre class=""lang-js prettyprint-override""><code>&quot;python.locator&quot;: &quot;js&quot;,
</code></pre>
<p>There are already plenty of Github issues, hopefully a fix is on its way:</p>
<ul>
<li><a href=""https://github.com/microsoft/vscode-python/issues/23922"" rel=""nofollow noreferrer"">https://github.com/microsoft/vscode-python/issues/23922</a></li>
<li><a href=""https://github.com/microsoft/vscode-python/issues/23963"" rel=""nofollow noreferrer"">https://github.com/microsoft/vscode-python/issues/23963</a></li>
<li><a href=""https://github.com/microsoft/vscode-python/issues/23956"" rel=""nofollow noreferrer"">https://github.com/microsoft/vscode-python/issues/23956</a></li>
</ul>
","python, visual-studio-code"
Aug-24,Aug-24,"<p>Assume I have this dataframe</p>
<pre class=""lang-py prettyprint-override""><code>import polars as pl

df = pl.DataFrame({
    'item':         ['CASH', 'CHECK', 'DEBT', 'CHECK', 'CREDIT', 'CASH'],
    'quantity':     [100, -20, 0, 10, 0, 0],
    'value':        [99, 47, None, 90, None, 120],
    'value_other':  [97, 57, None, 91, None, 110],
    'value_other2': [94, 37, None, 93, None, 115],
})
</code></pre>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ item   ‚îÜ quantity ‚îÜ value ‚îÜ value_other ‚îÜ value_other2 ‚îÇ
‚îÇ ---    ‚îÜ ---      ‚îÜ ---   ‚îÜ ---         ‚îÜ ---          ‚îÇ
‚îÇ str    ‚îÜ i64      ‚îÜ i64   ‚îÜ i64         ‚îÜ i64          ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ CASH   ‚îÜ 100      ‚îÜ 99    ‚îÜ 97          ‚îÜ 94           ‚îÇ
‚îÇ CHECK  ‚îÜ -20      ‚îÜ 47    ‚îÜ 57          ‚îÜ 37           ‚îÇ
‚îÇ DEBT   ‚îÜ 0        ‚îÜ null  ‚îÜ null        ‚îÜ null         ‚îÇ
‚îÇ CHECK  ‚îÜ 10       ‚îÜ 90    ‚îÜ 91          ‚îÜ 93           ‚îÇ
‚îÇ CREDIT ‚îÜ 0        ‚îÜ null  ‚îÜ null        ‚îÜ null         ‚îÇ
‚îÇ CASH   ‚îÜ 0        ‚îÜ 120   ‚îÜ 110         ‚îÜ 115          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<p>Now I want to set all value columns to <code>0</code> for all rows where <code>value is null</code> and <code>quantity == 0</code>.</p>
<p>Right now I have this solution</p>
<pre class=""lang-py prettyprint-override""><code>cols = ['value', 'value_other', 'value_other2']
df   = df.with_columns([
    pl.when(pl.col('value').is_null() &amp; (pl.col('quantity') == 0))
    .then(0)
    .otherwise(pl.col(col))
    .alias(col)
    for col in cols
])
</code></pre>
<p>which correctly gives</p>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ item   ‚îÜ quantity ‚îÜ value ‚îÜ value_other ‚îÜ value_other2 ‚îÇ
‚îÇ ---    ‚îÜ ---      ‚îÜ ---   ‚îÜ ---         ‚îÜ ---          ‚îÇ
‚îÇ str    ‚îÜ i64      ‚îÜ i64   ‚îÜ i64         ‚îÜ i64          ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ CASH   ‚îÜ 100      ‚îÜ 99    ‚îÜ 97          ‚îÜ 94           ‚îÇ
‚îÇ CHECK  ‚îÜ -20      ‚îÜ 47    ‚îÜ 57          ‚îÜ 37           ‚îÇ
‚îÇ DEBT   ‚îÜ 0        ‚îÜ 0     ‚îÜ 0           ‚îÜ 0            ‚îÇ
‚îÇ CHECK  ‚îÜ 10       ‚îÜ 90    ‚îÜ 91          ‚îÜ 93           ‚îÇ
‚îÇ CREDIT ‚îÜ 0        ‚îÜ 0     ‚îÜ 0           ‚îÜ 0            ‚îÇ
‚îÇ CASH   ‚îÜ 0        ‚îÜ 120   ‚îÜ 110         ‚îÜ 115          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<p>However, I feel this is very inefficient as my <code>when</code> condition is executed for every value column. Is there a way to achieve this using only polar internal functions &amp; without the native for-loop?</p>
",6,"<p>You can pass list of column names into <code>pl.col()</code> and <a href=""https://docs.pola.rs/docs/python/dev/reference/expressions/api/polars.when.html"" rel=""nofollow noreferrer""><code>when\then\otherwise</code></a> accepts <code>Expr</code> which can contain multiple columns.</p>
<pre class=""lang-py prettyprint-override""><code>cols = ['value', 'value_other', 'value_other2']

df.with_columns(
    pl
    .when((pl.col.quantity != 0) | pl.col.value.is_not_null())
    .then(pl.col(cols))
    .otherwise(0)
)

# or

df.with_columns(
    pl
    .when(pl.col.quantity != 0).then(pl.col(cols))
    .when(pl.col.value.is_not_null()).then(pl.col(cols))
    .otherwise(0)
)
</code></pre>
<pre class=""lang-py prettyprint-override""><code>shape: (6, 5)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ item   ‚îÜ quantity ‚îÜ value ‚îÜ value_other ‚îÜ value_other2 ‚îÇ
‚îÇ ---    ‚îÜ ---      ‚îÜ ---   ‚îÜ ---         ‚îÜ ---          ‚îÇ
‚îÇ str    ‚îÜ i64      ‚îÜ i64   ‚îÜ i64         ‚îÜ i64          ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ CASH   ‚îÜ 100      ‚îÜ 99    ‚îÜ 97          ‚îÜ 94           ‚îÇ
‚îÇ CHECK  ‚îÜ -20      ‚îÜ 47    ‚îÜ 57          ‚îÜ 37           ‚îÇ
‚îÇ DEBT   ‚îÜ 0        ‚îÜ 0     ‚îÜ 0           ‚îÜ 0            ‚îÇ
‚îÇ CHECK  ‚îÜ 10       ‚îÜ 90    ‚îÜ 91          ‚îÜ 93           ‚îÇ
‚îÇ CREDIT ‚îÜ 0        ‚îÜ 0     ‚îÜ 0           ‚îÜ 0            ‚îÇ
‚îÇ CASH   ‚îÜ 0        ‚îÜ 120   ‚îÜ 110         ‚îÜ 115          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
","python, dataframe, python-polars"
Aug-24,Aug-24,"<p>I am working on a project where I generate an EC private key using Java and then import it in the browser using JavaScript. The key imports successfully in Chrome, but it fails in Safari.Here‚Äôs my JavaScript code for importing private key:</p>
<p>[Try running this html file in browser]</p>
<pre class=""lang-js prettyprint-override""><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;title&gt;ECDH Key Pair Generation&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt; 
  &lt;script&gt;

//Utils
function _extractRawKeyMaterial(pem, type) {
  const pemHeader = `-----BEGIN ${type} KEY-----`;
  const pemFooter = `-----END ${type} KEY-----`;

  const endingIndex = pem.indexOf(pemFooter);
  const startingIndex = pem.indexOf(pemHeader) + pemHeader.length;

  const pemContents = pem.substring(startingIndex, endingIndex);
  var return_object = convertBase64StringToArrayBuffer(pemContents.trim());
  return return_object;
}

 const convertBase64StringToArrayBuffer = base64String =&gt; {
  const text = window.atob(base64String);
  return convertStringToArrayBuffer(text);
};

 const convertStringToArrayBuffer = str =&gt; {
  const buf = new ArrayBuffer(str.length);
  const bufView = new Uint8Array(buf);
  for (let i = 0, strLen = str.length; i &lt; strLen; i++) {
    bufView[i] = str.charCodeAt(i);
  }
  return buf;
};


// private key
var privateKeyGenerated = `-----BEGIN PRIVATE KEY-----
ME4CAQAwEAYHKoZIzj0CAQYFK4EEACIENzA1AgEBBDAMvyd7HU0FwJxgs5N87NVw
MPOR60umJXnhPjdtn0O0RHgx2J0sVnvw7B6ue1Wb5uQ=
-----END PRIVATE KEY-----`

// Pass the loaded private key to your function
_loadEccPrivateKey(privateKeyGenerated);

// Code working in chrome but fails in safari with an error : Data provided to an operation does not meet requirements
 async function _loadEccPrivateKey(pemKey) {
  try {
     const rawKey = _extractRawKeyMaterial(pemKey.trim(), &quot;PRIVATE&quot;);

    //console.log(rawKey)
    const key = await window.crypto.subtle.importKey(
      &quot;pkcs8&quot;, // Format for private keys
      rawKey,
      {
        name: &quot;ECDH&quot;,
        namedCurve: &quot;P-384&quot;,
      },
      true,
      [&quot;deriveBits&quot;, &quot;deriveKey&quot;] // Key usages
    );

    console.log('Imported Private Key:', key);
    return key;
  } catch (e) {
    console.error('Error importing private key:', e);
    throw e;
  }
}

&lt;/script&gt; 
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p>The code works perfectly in Chrome but throws an error in Safari. The error message is
&quot;DATA PROVIDED TO AN OPERATION DOES NOT MEET REQUIREMENTS&quot;</p>
<p>Here is my JAVA CODE for more information:</p>
<pre class=""lang-java prettyprint-override""><code>
import org.bouncycastle.jce.provider.BouncyCastleProvider;

import java.io.FileOutputStream;
import java.io.IOException;
import java.security.*;
import java.security.spec.ECGenParameterSpec;
import java.util.Base64;

public class TestApplication {

    private static final String CURVE = &quot;secp384r1&quot;; // P-384 curve

    public static void main(String[] args) {
        try {
            // Add BouncyCastle Provider
            Security.addProvider(new BouncyCastleProvider());

            // Generate EC key pair
            ECGenParameterSpec parameterSpec = new ECGenParameterSpec(CURVE);
            KeyPairGenerator keyPairGenerator = KeyPairGenerator.getInstance(&quot;EC&quot;, &quot;BC&quot;);
            keyPairGenerator.initialize(parameterSpec, new SecureRandom());
            KeyPair keyPair = keyPairGenerator.generateKeyPair();

            // Extract and print private key
            PrivateKey privateKey = keyPair.getPrivate();
            String privateKeyPem = convertToPem(privateKey);
            System.out.println(&quot;Private Key in PEM format:\n&quot; + privateKeyPem);

            // Save the private key in binary format to a file (optional)
            String privateKeyFilePath = &quot;private_key.bin&quot;;
            saveKeyToBinaryFile(privateKey, privateKeyFilePath);

        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    // Convert private key to PEM format
    private static String convertToPem(PrivateKey privateKey) {
        String base64Key = Base64.getEncoder().encodeToString(privateKey.getEncoded());
        return &quot;-----BEGIN PRIVATE KEY-----\n&quot; +
                base64Key +
                &quot;\n-----END PRIVATE KEY-----&quot;;
    }

    // Save the private key in binary format
    private static void saveKeyToBinaryFile(PrivateKey privateKey, String filePath) {
        try (FileOutputStream fos = new FileOutputStream(filePath)) {
            fos.write(privateKey.getEncoded());
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}


</code></pre>
<p>If you want to try it yourself, just run this Java POC: <a href=""https://github.com/ChetanTailor/JavaPrivateKeyPOC"" rel=""nofollow noreferrer"">https://github.com/ChetanTailor/JavaPrivateKeyPOC</a></p>
",5,"<p>This is a known <a href=""https://bugs.webkit.org/show_bug.cgi?id=233705"" rel=""nofollow noreferrer"">Safari</a> and <a href=""https://bugzilla.mozilla.org/show_bug.cgi?id=1743583"" rel=""nofollow noreferrer"">Firefox</a> bug where <strong><code>importKey</code> requires EC keys to include the public component</strong> as well as the private.</p>
<p>Here's a working P-384 private key (generated with <code>openssl ecparam -genkey -name prime256v1 -noout</code> and ASCII armor tweaked to match the expected header):</p>
<pre class=""lang-js prettyprint-override""><code>var privateKeyGenerated = `-----BEGIN PRIVATE KEY-----
MIG2AgEAMBAGByqGSM49AgEGBSuBBAAiBIGeMIGbAgEBBDBoZCuF4gA0MozAQFtE
lm+zCPikEs5JeMFyZRVPpXEHYsQQFZc71KYFNdAA0uazYHWhZANiAAQkQ/kYHu/y
F9Ec2QPkQxtqRWKgi8U2ZIqo6SeJfgs/4g7P3EaFgx/T2BAGw1HIrwfO1kiAJi/f
tkdHqte8uf88Oo8vq1YSniBNV8E4kC4VbsrHNrYcBPk0XfyL1B4pJ8M=
-----END PRIVATE KEY-----`
</code></pre>
<p>You can compare the <a href=""https://lapo.it/asn1js/#MIG2AgEAMBAGByqGSM49AgEGBSuBBAAiBIGeMIGbAgEBBDBoZCuF4gA0MozAQFtElm-zCPikEs5JeMFyZRVPpXEHYsQQFZc71KYFNdAA0uazYHWhZANiAAQkQ_kYHu_yF9Ec2QPkQxtqRWKgi8U2ZIqo6SeJfgs_4g7P3EaFgx_T2BAGw1HIrwfO1kiAJi_ftkdHqte8uf88Oo8vq1YSniBNV8E4kC4VbsrHNrYcBPk0XfyL1B4pJ8M"" rel=""nofollow noreferrer"">ASN.1 parsing of this key</a>:</p>
<pre><code>PrivateKeyInfo SEQUENCE (3 elem)

    version Version INTEGER 0
    privateKeyAlgorithm AlgorithmIdentifier SEQUENCE (2 elem)
        algorithm OBJECT IDENTIFIER 1.2.840.10045.2.1 ecPublicKey (ANSI X9.62 public key type)
        parameters ANY OBJECT IDENTIFIER 1.3.132.0.34 secp384r1 (SECG (Certicom) named elliptic curve)
    privateKey PrivateKey OCTET STRING (158 byte) 30819B020101043068642B85E20034328CC0405B44966FB308F8A412CE4978C172651‚Ä¶
        SEQUENCE (3 elem)
            INTEGER 1
            OCTET STRING (48 byte) 68642B85E20034328CC0405B44966FB308F8A412CE4978C17265154FA5710762C41015‚Ä¶
            [1] (1 elem)
                BIT STRING (776 bit) 0000010000100100010000111111100100011000000111101110111111110010000101‚Ä¶
</code></pre>
<p>with the <a href=""https://lapo.it/asn1js/#ME4CAQAwEAYHKoZIzj0CAQYFK4EEACIENzA1AgEBBDAMvyd7HU0FwJxgs5N87NVwMPOR60umJXnhPjdtn0O0RHgx2J0sVnvw7B6ue1Wb5uQ"" rel=""nofollow noreferrer"">key you provided</a>:</p>
<pre><code>PrivateKeyInfo SEQUENCE (3 elem)

    version Version INTEGER 0
    privateKeyAlgorithm AlgorithmIdentifier SEQUENCE (2 elem)
        algorithm OBJECT IDENTIFIER 1.2.840.10045.2.1 ecPublicKey (ANSI X9.62 public key type)
        parameters ANY OBJECT IDENTIFIER 1.3.132.0.34 secp384r1 (SECG (Certicom) named elliptic curve)
    privateKey PrivateKey OCTET STRING (55 byte) 303502010104300CBF277B1D4D05C09C60B3937CECD57030F391EB4BA62579E13E376D‚Ä¶
        SEQUENCE (2 elem)
            INTEGER 1
            OCTET STRING (48 byte) 0CBF277B1D4D05C09C60B3937CECD57030F391EB4BA62579E13E376D9F43B4447831D8‚Ä¶
</code></pre>
<p>Note that the second one is missing an element at the end, representing the public key.</p>
<hr />
<p>You can fix your Java code by passing the private key through <a href=""https://javadoc.io/static/org.bouncycastle/bcprov-jdk15on/1.70/org/bouncycastle/asn1/pkcs/PrivateKeyInfo.html"" rel=""nofollow noreferrer""><code>PrivateKeyInfo</code></a>, which is the <a href=""https://datatracker.ietf.org/doc/html/rfc5208#section-5"" rel=""nofollow noreferrer"">ASN.1 structure</a> expected by browsers. Unfortunately BouncyCastle's implementation introduces new, unsupported structures, like a public key identifier, so you must manually re-encode it with only the parts you want.</p>
<p>This way you can create an encoded key that exactly matches the OpenSSL structures:</p>
<pre><code>PrivateKeyInfo originalKeyInfo = PrivateKeyInfo.getInstance(keyPair.getPrivate().getEncoded());

ASN1Sequence oldPrivateKeySequence = DERSequence
        .getInstance(originalKeyInfo.getPrivateKey().getOctets());
DERSequence newPrivateKeySequence = new DERSequence(new ASN1Encodable[] {
        // Version (1).
        oldPrivateKeySequence.getObjectAt(0),

        // Private key bytes.
        oldPrivateKeySequence.getObjectAt(1),

        // Public key algorithm. Accepted by Firefox but not Safari, so must be skipped.
        // oldPrivateKeySequence.getObjectAt(2),

        // Public key bytes, tagged [1].
        oldPrivateKeySequence.getObjectAt(3),
});

// Re-create PrivateKeyInfo with only the structures we want.
ASN1EncodableVector v = new ASN1EncodableVector();

// Version fixed to zero.
v.add(new ASN1Integer(BigIntegers.ZERO));
v.add(originalKeyInfo.getPrivateKeyAlgorithm());
v.add(new DEROctetString(newPrivateKeySequence));

byte[] keyPairEncoded = new DERSequence(v).getEncoded();
</code></pre>
<p>Here's the full source code:</p>
<pre><code>import org.bouncycastle.asn1.ASN1Encodable;
import org.bouncycastle.asn1.ASN1EncodableVector;
import org.bouncycastle.asn1.ASN1Integer;
import org.bouncycastle.asn1.ASN1Primitive;
import org.bouncycastle.asn1.ASN1Sequence;
import org.bouncycastle.asn1.ASN1Set;
import org.bouncycastle.asn1.DEROctetString;
import org.bouncycastle.asn1.DERSequence;
import org.bouncycastle.asn1.DERTaggedObject;
import org.bouncycastle.asn1.pkcs.PrivateKeyInfo;
import org.bouncycastle.asn1.x509.AlgorithmIdentifier;
import org.bouncycastle.jce.provider.BouncyCastleProvider;
import org.bouncycastle.util.BigIntegers;

import java.io.FileOutputStream;
import java.io.IOException;
import java.security.*;
import java.security.spec.ECGenParameterSpec;
import java.util.Base64;

public class TestApplication {

    private static final String CURVE = &quot;secp384r1&quot;; // P-384 curve

    public static void main(String[] args) {
        try {
            // Add BouncyCastle Provider
            Security.addProvider(new BouncyCastleProvider());

            // Generate EC key pair
            ECGenParameterSpec parameterSpec = new ECGenParameterSpec(CURVE);
            KeyPairGenerator keyPairGenerator = KeyPairGenerator.getInstance(&quot;EC&quot;, &quot;BC&quot;);
            keyPairGenerator.initialize(parameterSpec, new SecureRandom());
            KeyPair keyPair = keyPairGenerator.generateKeyPair();

            // Encode with Safari-compatible ASN.1 structure.
            byte[] keyPairBytes = encodeKeyPair(keyPair);

            // Extract and print key pair
            String privateKeyPem = convertToPem(keyPairBytes);
            System.out.println(&quot;Private Key in PEM format:\n&quot; + privateKeyPem);

            // Save the key pair in binary format to a file (optional)
            String privateKeyFilePath = &quot;private_key.bin&quot;;
            saveKeyToBinaryFile(keyPairBytes, privateKeyFilePath);

        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    // Convert a KeyPair into ASN.1 encoded PrivateKeyInfo compatible with Safari.
    private static byte[] encodeKeyPair(KeyPair keyPair) throws IOException {
        PrivateKeyInfo originalKeyInfo = PrivateKeyInfo.getInstance(keyPair.getPrivate().getEncoded());

        ASN1Sequence oldPrivateKeySequence = DERSequence
                .getInstance(originalKeyInfo.getPrivateKey().getOctets());
        DERSequence newPrivateKeySequence = new DERSequence(new ASN1Encodable[] {
                // Version (1).
                oldPrivateKeySequence.getObjectAt(0),

                // Private key bytes.
                oldPrivateKeySequence.getObjectAt(1),

                // Public key algorithm. Accepted by Firefox but not Safari, so must be skipped.
                // oldPrivateKeySequence.getObjectAt(2),

                // Public key bytes, tagged [1].
                oldPrivateKeySequence.getObjectAt(3),
        });

        // Re-create PrivateKeyInfo with only the structures we want.
        ASN1EncodableVector v = new ASN1EncodableVector();

        // Version fixed to zero.
        v.add(new ASN1Integer(BigIntegers.ZERO));
        v.add(originalKeyInfo.getPrivateKeyAlgorithm());
        v.add(new DEROctetString(newPrivateKeySequence));

        return new DERSequence(v).getEncoded();
    }

    // Convert private key to PEM format
    private static String convertToPem(byte[] privateKey) {
        String base64Key = Base64.getEncoder().encodeToString(privateKey);
        return &quot;-----BEGIN PRIVATE KEY-----\n&quot; +
                base64Key +
                &quot;\n-----END PRIVATE KEY-----&quot;;
    }

    // Save the private key in binary format
    private static void saveKeyToBinaryFile(byte[] privateKey, String filePath) {
        try (FileOutputStream fos = new FileOutputStream(filePath)) {
            fos.write(privateKey);
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

</code></pre>
<p>Finally, here's an example of the encoded keypair that this code generates:</p>
<pre><code>-----BEGIN PRIVATE KEY-----
MIG2AgEAMBAGByqGSM49AgEGBSuBBAAiBIGeMIGbAgEBBDBzsru70B3wapVJZsFj4hUHxAGO4B5fJypfAvGyKEyRc2ZdjaVWIOd+vfhgfKFIqe6hZANiAAR7f1ZbUKI2lLAgZ4dnHVHGTQ7D9E2yMxwT5gYiGKdc8+AHGBzoYauI4YTOMVBYHwNrqYT1oO0ruH2sI53U+iy1KnbUAPAP9z0lHi8HONJZ8D+FbKTQa5LWihLTJLihFJw=
-----END PRIVATE KEY-----
</code></pre>
<p>You can see how <a href=""https://lapo.it/asn1js/#MIG2AgEAMBAGByqGSM49AgEGBSuBBAAiBIGeMIGbAgEBBDA0RFt-G5zun-sk00t-2IKoGnh2P30OctNC_nR594Cr__7YVfOSPDcrld0gHdu-xcehZANiAASubhPuEy9tI1hm1V6WgEcrvc5JYSLCAYkQNFLHDqil3_XFUAi5LurfeXjZfZBwnwHm_12U-Syvv_ga3MYvm1rKLJrUwSpjuLBc6RMM0xSc3Y-yZoTwwSVjgFw0CKwdets"" rel=""nofollow noreferrer"">it's parsed with the same structure</a> as the first OpenSSL key:</p>
<pre><code>PrivateKeyInfo SEQUENCE (3 elem)

    version Version INTEGER 0
    privateKeyAlgorithm AlgorithmIdentifier SEQUENCE (2 elem)
        algorithm OBJECT IDENTIFIER 1.2.840.10045.2.1 ecPublicKey (ANSI X9.62 public key type)
        parameters ANY OBJECT IDENTIFIER 1.3.132.0.34 secp384r1 (SECG (Certicom) named elliptic curve)
    privateKey PrivateKey OCTET STRING (158 byte) 30819B020101043073B2BBBBD01DF06A954966C163E21507C4018EE01E5F272A5F02F‚Ä¶
        SEQUENCE (3 elem)
            INTEGER 1
            OCTET STRING (48 byte) 73B2BBBBD01DF06A954966C163E21507C4018EE01E5F272A5F02F1B2284C9173665D8D‚Ä¶
            [1] (1 elem)
                BIT STRING (776 bit) 0000010001111011011111110101011001011011010100001010001000110110100101‚Ä¶
</code></pre>
","javascript, java, cryptography, bouncycastle, webcrypto"
Aug-24,Aug-24,"<p>I'm trying to understand why there is a different when I change from <code>y.addAll(x)</code> to <code>x.addAll(y)</code> in code snippet below:</p>
<pre class=""lang-java prettyprint-override""><code>List&lt;Integer&gt; result = List.of(1, 2)
    .parallelStream() 
    .collect(
        ArrayList::new,
        (x, y) -&gt; x.add(y),
        (x, y) -&gt; y.addAll(x)
    );
System.out.println(result);
</code></pre>
<p>I know, when I use <code>parallelStream</code>, there is more than one thread run at a time.</p>
<p><code>collect</code> has three parameters; the first two parameters I understand. With the third parameter, I know x, y are substreams and they are <code>ArrayList</code>s, but I don't understand why the results are different in each case. I expected them to be the same.</p>
<ul>
<li><p><code>(x, y) -&gt; y.addAll(x) // output: [1]</code></p>
</li>
<li><p><code>(x, y) -&gt; x.addAll(y) // output: [1, 2]</code></p>
</li>
</ul>
",23,"<h3>Why one is correct and the other isn't</h3>
<p>From <a href=""https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/Stream.html#collect(java.util.function.Supplier,java.util.function.BiConsumer,java.util.function.BiConsumer)"" rel=""noreferrer"">the Javadocs of <code>Stream#collect</code></a> (specifically the last parameter, emphasis mine):</p>
<blockquote>
<p>combiner - an associative, non-interfering, stateless function that accepts two partial result containers and merges them, which must be compatible with the accumulator function. The combiner function must <strong>fold the elements from the second result container into the first result container</strong>.</p>
</blockquote>
<p>Similarly, <a href=""https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/List.html#addAll(java.util.Collection)"" rel=""noreferrer""><code>a.addAll(b)</code></a> adds all elements from <code>b</code> to <code>a</code> but not the other way round. It takes information from the parameter and modifies the receiver.</p>
<p>So, the contract of that method specifies that you have to merge the second argument of the lambda into the first.</p>
<p>If you do <code>(x, y) -&gt; x.addAll(y)</code>, it will add all elements of <code>y</code> into <code>x</code> adhering to the contract. However, with <code>(x, y) -&gt; y.addAll(x)</code> you are adding it to the second element resulting in the the elements of <code>y</code> not being added to <code>x</code> which are then missing in the result.</p>
<h3>What happens</h3>
<p>This is done that way because parallel streams split processing into chunks where different threads process different chunks. After the processing, it needs to merge the elements together which is done using the combiner (the last lambda expression which is the one you talked about). This combiner needs to be able to <em>combine</em> two elements together and the first argument is then used for further processing while the second is discarded.</p>
<p>Let's say we have the numbers 1 and 2 as in your example and assume one thread processes a chunk containing 1 and the other thread processes a chunk containing 2. When collecting, each thread starts by creating a new <code>ArrayList</code> following the <code>ArrayList::new</code> in your code. The threads then add the elements of their corresponding chunks to the list resulting in two lists with one element each (1 for the first thread and 2 for the other). When both threads are finished, the combiner is called to merge/combine the results. With <code>x.addAll(y)</code>, it adds the second list to the first which is then returned yielding the correct result. However, with <code>y.addAll(x)</code>, it adds the elements of the first list to the second list but Java assumes you want the first list (as that's what you are supposed to modify) so collect returns the first list which doesn't contain the elements processed by the second thread.</p>
","java, java-stream, java-11"
Aug-24,Aug-24,"<p>Why is <code>throw e</code> allowed, but not <code>throw a</code>, in the following case?</p>
<pre><code>  void test() {
    try {
      System.out.println();
    } catch (Error | RuntimeException e) {
      var a = e;
      //throw a; unreported exception Throwable; must be caught or declared to be thrown
      throw e;
    }
  }
</code></pre>
<p>All of this intuitively makes sense, but from <a href=""https://docs.oracle.com/javase/specs/jls/se17/html/jls-14.html#jls-14.20"" rel=""nofollow noreferrer"">JLS 14.20</a></p>
<blockquote>
<p>A multi-catch clause can be thought of as a sequence of uni-catch clauses. That is, a catch clause where the type of the exception parameter is denoted as a union <code>D1|D2|...|Dn</code> is equivalent to a sequence of <em>n</em> catch clauses where the types of the exception parameters are class types <code>D1, D2, ..., Dn</code> respectively.
In the Block of each of the <em>n</em> catch clauses, the declared type of the exception parameter is <code>lub(D1, D2, ..., Dn)</code>.</p>
</blockquote>
<p>Since <code>lub(Error,RuntimeException)</code> is <code>Throwable</code>, the code above should be equivalent to:</p>
<pre><code>    try {
      System.out.println();
    } catch (Error e) {
      Throwable lub = e;
      throw lub;
    } catch (RuntimeException e) {
      Throwable lub = e;
      throw lub;
    }
</code></pre>
<p>(which obviously doesn't compile)</p>
<p>Moreover, the type of the <code>a</code> is the type of <code>e</code> &quot;when treated as if it did not appear in an assignment context&quot; (<a href=""https://docs.oracle.com/javase/specs/jls/se17/html/jls-14.html#jls-14.4.1"" rel=""nofollow noreferrer"">JLS 14.4.1</a>), but as shown above it's not the same as the type of <code>e</code>.</p>
<p>Is there anything I've overlooked?</p>
<hr>
<p><em>Edit</em>: this is not a duplicate of <a href=""https://stackoverflow.com/questions/23581611"">Why is it legal to re-throw a Throwable in certain cases, without declaring it?</a> because this question is specific to multi-catch (which isn't discussed there) and arises due to a misunderstanding of a specific fragment of the JLS that addresses multi-catch. The answers provided in this question helped me to connect the dots :)</p>
",7,"<p>This is described in <a href=""https://docs.oracle.com/javase/specs/jls/se17/html/jls-11.html#jls-11.2.2"" rel=""noreferrer"">11.2.2</a>. This basically boils down to &quot;exception parameters in <code>catch (...)</code> are a special case&quot;.</p>
<p>Our goal is to show <code>throw e;</code> compiles. We start with this line in 11.2.3:</p>
<blockquote>
<p>It is a compile-time error if a method or constructor body can throw some exception class E when E is a checked exception class and E is not a subclass of some class declared in the throws clause of the method or constructor.</p>
</blockquote>
<p>So we want to show that the <code>try</code> statement in <code>test</code> cannot throw <code>Throwable</code>. Note that &quot;can throw&quot; in this context is a rigorously defined term. According to 11.2.2,</p>
<blockquote>
<p>A try statement can throw an exception class E iff either:</p>
<ul>
<li><p>The try block can throw E, [...]</p>
</li>
<li><p>Some catch block of the try statement can throw E and either no finally block is present or the finally block can complete normally;
or</p>
</li>
<li><p>A finally block is present and can throw E.</p>
</li>
</ul>
</blockquote>
<p>Only the second point is relevant here. Let's show that the <code>catch</code> block cannot throw <code>Throwable</code>. Namely, <code>throw e;</code> cannot throw <code>Throwable</code>.</p>
<blockquote>
<p>A throw statement whose thrown expression is a final or effectively
final exception parameter of a catch clause C can throw an exception
class E iff:</p>
<ul>
<li><p>E is an exception class that the try block of the try statement which declares C can throw; and</p>
</li>
<li><p>E is assignment compatible with any of C's catchable exception classes; and</p>
</li>
<li><p>E is not assignment compatible with any of the catchable exception classes of the catch clauses declared to the left of C in the same try
statement.</p>
</li>
</ul>
</blockquote>
<p><code>throw e;</code> here immediately fails the first bullet point, so we can conclude that <code>throw e;</code> cannot throw <code>Throwable</code>.</p>
<p>If it were <code>throw a;</code>, then the above doesn't apply, but another clause does:</p>
<blockquote>
<p>A throw statement whose thrown expression has static type E and is not a final or effectively final exception parameter can throw E or any exception class that the thrown expression can throw.</p>
</blockquote>
","java, jls"
Sep-24,Sep-24,"<p>I have a dataframe like:</p>
<pre><code>data = {
    &quot;a&quot;: [[1], [2], [3, 4], [5, 6, 7]],
    &quot;b&quot;: [[], [8], [9, 10], [11, 12]],
}
df = pl.DataFrame(data)
&quot;&quot;&quot;
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ a         ‚îÜ b         ‚îÇ
‚îÇ ---       ‚îÜ ---       ‚îÇ
‚îÇ list[i64] ‚îÜ list[i64] ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ [1]       ‚îÜ []        ‚îÇ
‚îÇ [2]       ‚îÜ [8]       ‚îÇ
‚îÇ [3, 4]    ‚îÜ [9, 10]   ‚îÇ
‚îÇ [5, 6, 7] ‚îÜ [11, 12]  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
&quot;&quot;&quot;
</code></pre>
<p>Each pair of lists may not have the same length, and I want to &quot;truncate&quot; the explode to the shortest of both lists:</p>
<pre><code>&quot;&quot;&quot;
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ a   ‚îÜ b   ‚îÇ
‚îÇ --- ‚îÜ --- ‚îÇ
‚îÇ i64 ‚îÜ i64 ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ 2   ‚îÜ 8   ‚îÇ
‚îÇ 3   ‚îÜ 9   ‚îÇ
‚îÇ 4   ‚îÜ 10  ‚îÇ
‚îÇ 5   ‚îÜ 11  ‚îÇ
‚îÇ 6   ‚îÜ 12  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
&quot;&quot;&quot;
</code></pre>
<p>I was thinking that maybe I'd have to fill the shortest of both lists with <code>None</code> to match both lengths, and then <code>drop_nulls</code>. But I was wondering if there was a more direct approach to this?</p>
",6,"<p>Here's one approach:</p>
<pre class=""lang-py prettyprint-override""><code>min_length = pl.min_horizontal(pl.col('a', 'b').list.len())

out = (df.filter(min_length != 0)
       .with_columns(
           pl.col('a', 'b').list.head(min_length)
           )
       .explode('a', 'b')
       )
</code></pre>
<p>Output:</p>
<pre class=""lang-py prettyprint-override""><code>shape: (5, 2)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ a   ‚îÜ b   ‚îÇ
‚îÇ --- ‚îÜ --- ‚îÇ
‚îÇ i64 ‚îÜ i64 ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ 2   ‚îÜ 8   ‚îÇ
‚îÇ 3   ‚îÜ 9   ‚îÇ
‚îÇ 4   ‚îÜ 10  ‚îÇ
‚îÇ 5   ‚îÜ 11  ‚îÇ
‚îÇ 6   ‚îÜ 12  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<p><strong>Explanation</strong></p>
<ul>
<li>Get the length for the lists in both columns with <a href=""https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.len.html#polars.Expr.list.len"" rel=""noreferrer""><code>Expr.list.len</code></a> and get the shortest for each row with <a href=""https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.min_horizontal.html"" rel=""noreferrer""><code>pl.min_horizontal</code></a>.</li>
<li>Now, filter out the rows where <code>min_length == 0</code> (<a href=""https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.filter.html"" rel=""noreferrer""><code>df.filter</code></a>) and inside <a href=""https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.with_columns.html"" rel=""noreferrer""><code>df.with_columns</code></a> select the first n values of each list with <a href=""https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.head.html#polars.Expr.list.head"" rel=""noreferrer""><code>Expr.list.head</code></a>.</li>
<li>Finally, apply <a href=""https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.explode.html"" rel=""noreferrer""><code>df.explode</code></a>.</li>
</ul>
","python, dataframe, python-polars"
Sep-24,Sep-24,"<p>I have a piece of code that was working fine until last week, but now it's failing with the following error:</p>
<p>AttributeError: module 'fiona' has no attribute 'path'</p>
<p>I‚Äôve ensured that all the necessary libraries are installed and imported. Does anyone have any ideas on what might be going wrong or how I can resolve this issue?</p>
<p>Thanks!</p>
<pre><code> pip install geopandas
 pip install fiona

 import geopandas as gpd
 import fiona

 countries = gpd.read_file(gpd.datasets.get_path(&quot;naturalearth_lowres&quot;))
</code></pre>
",16,"<p>TL;DR update to <code>geopandas==0.14.4</code> OR pin <code>fiona</code> to version <code>1.9.6</code></p>
<p>--</p>
<p>It seems <code>fiona</code> <a href=""https://pypi.org/project/fiona/1.10.0/"" rel=""noreferrer"">recently upgraded</a> to <code>1.10.0</code> (as of <code>2024-09-04 01:14 UTC</code>) and that may have broken some older versions of <code>geopandas</code>, which only depend on <code>fiona</code> being <strong>higher</strong> than some version, not <strong>lower</strong> than.</p>
<p>Upon closer look, <code>geopandas</code> up to <a href=""https://github.com/geopandas/geopandas/blob/v0.14.3/geopandas/io/file.py"" rel=""noreferrer"">version 0.14.3</a> still calls <code>fiona.path</code>, but in <a href=""https://github.com/geopandas/geopandas/blob/v0.14.4/geopandas/io/file.py"" rel=""noreferrer"">version 0.14.4</a> it no longer does.</p>
<p>So upgrading <code>geopandas</code> to <code>0.14.4</code> should fix it.</p>
<p>Alternatively, forcing <code>fiona</code> to stay on version <code>1.9.6</code> should also work.</p>
<p>NOTE: upgrading <code>geopandas</code> to <code>&gt;=1.0</code> seems to remove <code>fiona</code> as a dependency altogether, so it will also solve this issue. But it opens up a whole new can of worms by removing <code>geopandas.dataset</code>. For details on that one, see <a href=""https://stackoverflow.com/questions/76548222/how-to-get-maps-to-geopandas-after-datasets-are-removed"">How to get maps to geopandas after datasets are removed?</a></p>
","python, dataframe, fiona, geopandas, databricks"
Sep-24,Sep-24,"<p>I just read <a href=""https://peps.python.org/pep-0393/"" rel=""noreferrer"">PEP 393</a> and learned that Python's <code>str</code> type uses different internal representations, depending on the content. So, I experimented a little bit and was a bit surprised by the results:</p>
<pre><code>&gt;&gt;&gt; sys.getsizeof('')
41
&gt;&gt;&gt; sys.getsizeof('H')
42
&gt;&gt;&gt; sys.getsizeof('Hi')
43
&gt;&gt;&gt; sys.getsizeof('√ñ')
61
&gt;&gt;&gt; sys.getsizeof('√ñl')
59
</code></pre>
<p>I understand that in the first three cases, the strings don't contain any non-ASCII characters, so an encoding with 1 byte per char can be used. Putting a non-ASCII character like <code>√ñ</code> in a string forces the interpreter to use a different encoding. Therefore, I'm not surprised that <code>'√ñ'</code> takes more space than <code>'H'</code>.</p>
<p>However, why does <code>'√ñl'</code> take less space than <code>'√ñ'</code>? I assumed that whatever internal representation is used for <code>'√ñl'</code> allows for an even shorter representation of <code>'√ñ'</code>.</p>
<p>I'm using Python 3.12, apparently it is not reproducible in earlier versions.</p>
",19,"<p>This test code (the structures are only correct according to 3.12.4 source, and even so I didn't quite double-check them)</p>
<pre><code>import ctypes
import sys


class PyUnicodeObject(ctypes.Structure):
    _fields_ = [
        (&quot;ob_refcnt&quot;, ctypes.c_ssize_t),
        (&quot;ob_type&quot;, ctypes.c_void_p),
        (&quot;length&quot;, ctypes.c_ssize_t),
        (&quot;hash&quot;, ctypes.c_ssize_t),
        (&quot;state&quot;, ctypes.c_uint64),
    ]


class StateBitField(ctypes.LittleEndianStructure):
    _fields_ = [
        (&quot;interned&quot;, ctypes.c_uint, 2),
        (&quot;kind&quot;, ctypes.c_uint, 3),
        (&quot;compact&quot;, ctypes.c_uint, 1),
        (&quot;ascii&quot;, ctypes.c_uint, 1),
        (&quot;statically_allocated&quot;, ctypes.c_uint, 1),
        (&quot;_padding&quot;, ctypes.c_uint, 24),
    ]

    def __repr__(self):
        return &quot;, &quot;.join(f&quot;{k}: {getattr(self, k)}&quot; for k, *_ in self._fields_ if not k.startswith(&quot;_&quot;))


def dump_s(s: str):
    o = PyUnicodeObject.from_address(id(s))
    state_int = o.state
    state = StateBitField.from_buffer(ctypes.c_uint64(state_int))
    print(f&quot;{s!r}&quot;.ljust(8), f&quot;{o.length=}, {sys.getsizeof(s)=}, {state}&quot;)


dump_s('5')
dump_s('a')
dump_s('√§')
dump_s('vvv')
dump_s('√ñ√ñ√ñ')
dump_s(str(chr(214)))  # avoid the string having been interned into module source
dump_s(str(chr(214) + chr(108)))  # avoid the string having been interned into module source
</code></pre>
<p>prints out</p>
<pre><code>'5'      o.length=1, sys.getsizeof(s)=42, interned: 3, kind: 1, compact: 1, ascii: 1, statically_allocated: 1
'a'      o.length=1, sys.getsizeof(s)=42, interned: 3, kind: 1, compact: 1, ascii: 1, statically_allocated: 1
'√§'      o.length=1, sys.getsizeof(s)=61, interned: 0, kind: 1, compact: 1, ascii: 0, statically_allocated: 1
'vvv'    o.length=3, sys.getsizeof(s)=44, interned: 2, kind: 1, compact: 1, ascii: 1, statically_allocated: 0
'√ñ√ñ√ñ'    o.length=3, sys.getsizeof(s)=60, interned: 0, kind: 1, compact: 1, ascii: 0, statically_allocated: 0
'√ñ'      o.length=1, sys.getsizeof(s)=61, interned: 0, kind: 1, compact: 1, ascii: 0, statically_allocated: 1
'√ñl'     o.length=2, sys.getsizeof(s)=59, interned: 0, kind: 1, compact: 1, ascii: 0, statically_allocated: 0
'√ñ'      o.length=1, sys.getsizeof(s)=61, interned: 0, kind: 1, compact: 1, ascii: 0, statically_allocated: 1
</code></pre>
<p>‚Äì the smoking gun seems to be <code>statically_allocated</code> on <code>√ñ</code> etc..</p>
<p>I think that stems from <a href=""https://github.com/python/cpython/blame/v3.12.4/Include/internal/pycore_runtime_init_generated.h#L1478"" rel=""noreferrer"">this line in <code>pycore_runtime_init_generated</code></a> where it looks like the runtime statically objects for all Latin-1 strings (among others). As discussed in the comments, <a href=""https://github.com/python/cpython/pull/96481/files"" rel=""noreferrer"">this CPython PR</a> added UTF-8 representations of all of these statically allocated strings, so <code>√ñ</code> is statically stored as both Latin-1 (1 character) and UTF-8 (2 characters).</p>
<p>Also, I should note <code>getsizeof()</code> actually forwards to <a href=""https://github.com/python/cpython/blame/v3.12.4/Objects/unicodeobject.c#L13356-L13382"" rel=""noreferrer""><code>unicode_sizeof_impl</code></a>, it's not just measuring memory.</p>
","python, string, python-internals, python-3.12"
Sep-24,Sep-24,"<p>I'm digging into a codebase containing thousands of occurrences of <code>foo in list(bar)</code>, e.g.:</p>
<ul>
<li><p>as a boolean expression:</p>
<pre class=""lang-py prettyprint-override""><code>if foo in list(bar) or ...:
   ...
</code></pre>
</li>
<li><p>in a for loop:</p>
<pre class=""lang-py prettyprint-override""><code>for foo in list(bar):
    ...
</code></pre>
</li>
<li><p>in a generator expression:</p>
<pre class=""lang-py prettyprint-override""><code>&quot;,&quot;.join(str(foo) for foo in list(bar))
</code></pre>
</li>
</ul>
<p>Is there a scenario (like a given version of Python, a known behavior with a type checker, etc.) where <code>foo in list(bar)</code> is not just a memory-expensive version of <code>foo in bar</code>? What am I missing here?</p>
",11,"<p>I've sometimes done/seen that when <code>bar</code> got modified in the loop, e.g.:</p>
<pre class=""lang-py prettyprint-override""><code>bar = {1, 2, 3}
for foo in list(bar):
    bar.add(foo + 1)
</code></pre>
<p>With your replacement, that raises <code>RuntimeError: Set changed size during iteration</code>.</p>
<p><a href=""https://ato.pxeger.com/run?1=m72soLIkIz9vwYKlpSVpuhY3C5ISixRsFaoNdRSMdBSMa7nS8osU0vLzFTLzFHIyi0s0gPKaVlwKQABk6SWmpGiAZLUVDDW5uPDoBUph1wWxF2o9zBkA"" rel=""noreferrer"">Attempt This Online!</a></p>
<p>An example from Python's <a href=""https://github.com/python/cpython/blob/40bdb0deee746e51c71c56329df21e5172fd8aa0/Lib/_osx_support.py#L139-L141"" rel=""noreferrer"">standard library</a></p>
<pre><code>    for k in list(_config_vars):
        if k.startswith(_INITPRE):
            del _config_vars[k]
</code></pre>
<p><a href=""https://github.com/search?q=repo%3Apython%2Fcpython%20%2Ffor%20%5Cw%2B%20in%20list%5C%28%2F&amp;type=code"" rel=""noreferrer"">Dozens more</a> (many done for the above reason, though not all).</p>
",python
Sep-24,Sep-24,"<p>In GNU awk, there is a four argument version of <a href=""https://www.gnu.org/software/gawk/manual/html_node/String-Functions.html#index-split_0028_0029-function"" rel=""noreferrer"">split</a> that can optionally keep all the separators from the split in a second array. This is useful if you <a href=""https://stackoverflow.com/a/70641933/298607"">want to reconstruct</a> a select subset of columns from a file where the delimiter may be more complicated than just a single character.</p>
<p>Suppose I have the following file:</p>
<pre><code># sed makes the invisibles visible...
# ‚àô is a space; \t is a literal tab; $ is line end
$ sed -E 's/\t/\\t/g; s/ /‚àô/g; s/$/\$/' f.txt
a\t‚àô‚àôb‚àôc\td‚àô_‚àôe$
a‚àô‚àô‚àôb‚àôc\td‚àô_‚àôe$
‚àô‚àô‚àôa‚àô‚àô‚àôb‚àôc\td‚àô_‚àôe$
a‚àô‚àô‚àôb_c\td‚àô_‚àôe\t$
abcd$
</code></pre>
<p>Here I have a field comprised of anything other than the delimiter character set, and
a delimiter of one or more characters of the set <code>[\s_]</code>.</p>
<p>With gawk, you can do:</p>
<pre><code>gawk '{
    printf &quot;[&quot;
    n=split($0, flds, /[[:space:]_]+/, seps)
    for(i=1; i&lt;=n; i++) 
           printf &quot;[\&quot;%s\&quot;, \&quot;%s\&quot;]%s&quot;, flds[i], seps[i], i&lt;n ? &quot;, &quot; : &quot;]&quot; ORS
    }
' f.txt
</code></pre>
<p>Prints (where the first element is the field, the second is the match to the delimiter regexp):</p>
<pre><code>[[&quot;a&quot;, &quot;      &quot;], [&quot;b&quot;, &quot; &quot;], [&quot;c&quot;, &quot;   &quot;], [&quot;d&quot;, &quot; _ &quot;], [&quot;e&quot;, &quot;&quot;]]
[[&quot;a&quot;, &quot;   &quot;], [&quot;b&quot;, &quot; &quot;], [&quot;c&quot;, &quot;  &quot;], [&quot;d&quot;, &quot; _ &quot;], [&quot;e&quot;, &quot;&quot;]]
[[&quot;&quot;, &quot;   &quot;], [&quot;a&quot;, &quot;   &quot;], [&quot;b&quot;, &quot; &quot;], [&quot;c&quot;, &quot; &quot;], [&quot;d&quot;, &quot; _ &quot;], [&quot;e&quot;, &quot;&quot;]]
[[&quot;a&quot;, &quot;   &quot;], [&quot;b&quot;, &quot;_&quot;], [&quot;c&quot;, &quot;  &quot;], [&quot;d&quot;, &quot; _ &quot;], [&quot;e&quot;, &quot;   &quot;], [&quot;&quot;, &quot;&quot;]]
[[&quot;abcd&quot;, &quot;&quot;]]
</code></pre>
<p>Ruby's <a href=""https://ruby-doc.org/3.3.5/String.html#method-i-split"" rel=""noreferrer"">str.split</a>, unfortunately, does not have the same functionality. (Neither does <a href=""https://docs.python.org/3/library/re.html#re.split"" rel=""noreferrer"">Python's</a> or <a href=""https://perldoc.perl.org/functions/split"" rel=""noreferrer"">Perl's</a>.)</p>
<p>What you <em>can</em> do is capture the match string from the delimiter regexp:</p>
<pre><code>irb(main):053&gt; s=&quot;a   b c    d _ e&quot;
=&gt; &quot;a   b c    d _ e&quot;
irb(main):054&gt; s.split(/([\s_]+)/)
=&gt; [&quot;a&quot;, &quot;   &quot;, &quot;b&quot;, &quot; &quot;, &quot;c&quot;, &quot;    &quot;, &quot;d&quot;, &quot; _ &quot;, &quot;e&quot;]
</code></pre>
<p>Then use that result with <code>.each_slice(2)</code> and replace the <code>nil</code>'s with <code>''</code>:</p>
<pre><code>irb(main):055&gt; s.split(/([\s_]+)/).each_slice(2).map{|a,b| [a,b]}
=&gt; [[&quot;a&quot;, &quot;   &quot;], [&quot;b&quot;, &quot; &quot;], [&quot;c&quot;, &quot;    &quot;], [&quot;d&quot;, &quot; _ &quot;], [&quot;e&quot;, nil]]
irb(main):056&gt; s.split(/([\s_]+)/).each_slice(2).map{|a,b| [a,b]}.map{|sa| sa.map{|e| e.nil? ? &quot;&quot; : e} }
=&gt; [[&quot;a&quot;, &quot;   &quot;], [&quot;b&quot;, &quot; &quot;], [&quot;c&quot;, &quot;    &quot;], [&quot;d&quot;, &quot; _ &quot;], [&quot;e&quot;, &quot;&quot;]]
</code></pre>
<p>Which allows gawk's version of split to be replicated:</p>
<pre><code>ruby -ne 'p $_.gsub(/\r?\n$/,&quot;&quot;).split(/([\s_]+)/).each_slice(2).
                map{|a,b| [a,b]}.map{|sa| sa.map{|e| e.nil? ? &quot;&quot; : e} }' f.txt
</code></pre>
<p>Prints:</p>
<pre><code>[[&quot;a&quot;, &quot;\t  &quot;], [&quot;b&quot;, &quot; &quot;], [&quot;c&quot;, &quot;\t&quot;], [&quot;d&quot;, &quot; _ &quot;], [&quot;e&quot;, &quot;&quot;]]
[[&quot;a&quot;, &quot;   &quot;], [&quot;b&quot;, &quot; &quot;], [&quot;c&quot;, &quot;\t&quot;], [&quot;d&quot;, &quot; _ &quot;], [&quot;e&quot;, &quot;&quot;]]
[[&quot;&quot;, &quot;   &quot;], [&quot;a&quot;, &quot;   &quot;], [&quot;b&quot;, &quot; &quot;], [&quot;c&quot;, &quot;\t&quot;], [&quot;d&quot;, &quot; _ &quot;], [&quot;e&quot;, &quot;&quot;]]
[[&quot;a&quot;, &quot;   &quot;], [&quot;b&quot;, &quot;_&quot;], [&quot;c&quot;, &quot;\t&quot;], [&quot;d&quot;, &quot; _ &quot;], [&quot;e&quot;, &quot;\t&quot;]]
[[&quot;abcd&quot;, &quot;&quot;]]
</code></pre>
<p>So the same output (other than the line with trailing <code>\t</code> which gawk has as an empty field, delimiter combination.)</p>
<p>In Python, roughly the same method also works:</p>
<pre><code>python3 -c '
import sys, re 
from itertools import zip_longest
with open(sys.argv[1]) as f:
    for line in f:
        lp=re.split(r&quot;([\s_]+)&quot;, line.rstrip(&quot;\r\n&quot;))
        print(list(zip_longest(*[iter(lp)]*2, fillvalue=&quot;&quot;)) )
' f.txt   
</code></pre>
<p>I am looking for a <strong>general algorithm</strong> to replicate the functionality of gawk's four argument split in Ruby/Python/Perl/etc. The Ruby and Python I have here works.</p>
<p>Most of solutions (other than for gawk) to <em>I want to split on this delimiter and keep the delimiter?</em> involve a unique regex more complex than simply matching the delimiter. Most seem to be either  scanning for a field, delimiter combination or use lookarounds. I am specifically trying to use a <em>simple</em> regexp that matches the delimiter only without lookarounds. With roughly the same regexp I would have used with GNU awk.</p>
<p>So stated generally:</p>
<ol>
<li>Take a regexp matching the delimiter fields (without having to think much about the data fields) and put inside a capturing group;</li>
<li>Take the resulting array of <code>[field1, delimiter1, field2, delimiter2, ...]</code> and create array of <code>[[field1, delimiter1], [field2, delimiter2], ...]</code></li>
</ol>
<p>That method is easily used in Ruby (see above) and Python (see above) and Perl (I was too lazy to write that one...)</p>
<p>Is this the best way to do this?</p>
",7,"<p>With splitting you always have one more field than the delimiters, which is why you have to fill in an empty string as the delimiter for the last field. A simpler way to achieve the filling would be to always append an empty string to the list returned by the split so that you can use the <code>itertools.batched</code> function (available since Python 3.12, or as a recipe beforehand) to produce easy pairings:</p>
<pre><code>import re
from io import StringIO
from itertools import batched

file = StringIO('''a\t  b c\td _ e
a   b c\td _ e
   a   b c\td _ e
a   b_c\td _ e\t
abcd''')

for line in file:
    print(list(batched(re.split(r&quot;([\s_]+)&quot;, line.rstrip('\r\n')) + [''], 2)))
</code></pre>
<p>This outputs:</p>
<pre><code>[('a', '\t  '), ('b', ' '), ('c', '\t'), ('d', ' _ '), ('e', '')]
[('a', '   '), ('b', ' '), ('c', '\t'), ('d', ' _ '), ('e', '')]
[('', '   '), ('a', '   '), ('b', ' '), ('c', '\t'), ('d', ' _ '), ('e', '')]
[('a', '   '), ('b', '_'), ('c', '\t'), ('d', ' _ '), ('e', '\t'), ('', '')]
[('abcd', '')]
</code></pre>
<p>Demo <a href=""https://ato.pxeger.com/run?1=XVA7bgIxFExan2JEY1tsKKiiSDlAqhQpMVrtxxssGdt6filyFppt4FCcBgO7SEk58958NIdT-uVdDON4_OHh5fX8_OT2KRKDrBgo7uEiJuaLyYXvj8-JZ0sco8_zuW2429leiMF5i_fHu5JSNoaBFp3hHjWsaPAHFvSPucF6hoZF03Z9MdLFPhK8CxYu4Br1dpUjlTBW3mVWUxFFdpWTd6xooTYm19ulXlQ36YpyKZeUNGSC1BpLbKTcVlhrre9DTHvMu1wA"" rel=""noreferrer"">here</a></p>
","ruby, python, regex, algorithm, split"